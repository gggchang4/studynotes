# 算法设计与分析 - 开卷考试复习资料

> 📚 本资料基于课程课件整理，用于期末开卷考试快速查阅
> 
> 🎯 每一讲包含：算法思路 → 算法步骤 → 考试重点 → 与其他算法对比 → 经典例题详解

---

# 第一讲：算法绪论

## 一、算法的基本概念

### 1.1 什么是算法？

**定义**：算法是解决特定问题的一系列**有限**、**确定**、**有效**的步骤。

**算法的五大特性**：
| 特性 | 含义 | 说明 |
|------|------|------|
| **有穷性** | 算法必须在有限步骤后终止 | 不能无限循环 |
| **确定性** | 每一步都有明确的定义 | 无歧义，相同输入产生相同输出 |
| **可行性** | 每一步都是可执行的基本操作 | 能在有限时间内完成 |
| **输入** | 有零个或多个输入 | 从外界获取数据 |
| **输出** | 有一个或多个输出 | 产生结果 |

### 1.2 算法与程序的区别

| 对比项 | 算法 | 程序 |
|--------|------|------|
| 有穷性 | 必须有穷 | 可以无穷（如操作系统） |
| 表示形式 | 伪代码、流程图、自然语言 | 特定编程语言 |
| 抽象层次 | 高层次抽象 | 具体实现 |

---

## 二、算法复杂度分析（⭐考试重点）

### 2.1 为什么要分析复杂度？

- 评估算法效率的**客观标准**
- 比较不同算法的**优劣**
- 预测算法在**大规模数据**下的表现
- **与具体机器无关**的度量方式

### 2.2 渐近符号（Asymptotic Notation）

#### 2.2.1 大O符号 - O(g(n))：渐近上界

**定义**：如果存在正常数 c 和 n₀，使得对所有 n ≥ n₀，有 f(n) ≤ c·g(n)，则 f(n) = O(g(n))

**通俗理解**：f(n) 的增长速度**不会超过** g(n)，即 g(n) 是 f(n) 的上界

**数学表示**：
```
O(g(n)) = { f(n) : 存在正常数 c 和 n₀，使得 0 ≤ f(n) ≤ c·g(n)，对所有 n ≥ n₀ }
```

**例子**：
- 3n² + 2n + 1 = O(n²)  （取 c=6, n₀=1 即可证明）
- n = O(n²)  （低阶是高阶的上界）
- n² ≠ O(n)  （高阶不是低阶的上界）

#### 2.2.2 大Ω符号 - Ω(g(n))：渐近下界

**定义**：如果存在正常数 c 和 n₀，使得对所有 n ≥ n₀，有 f(n) ≥ c·g(n)，则 f(n) = Ω(g(n))

**通俗理解**：f(n) 的增长速度**至少是** g(n)，即 g(n) 是 f(n) 的下界

**例子**：
- 3n² + 2n + 1 = Ω(n²)
- n² = Ω(n)
- n ≠ Ω(n²)

#### 2.2.3 大Θ符号 - Θ(g(n))：渐近紧确界

**定义**：如果存在正常数 c₁、c₂ 和 n₀，使得对所有 n ≥ n₀，有 c₁·g(n) ≤ f(n) ≤ c₂·g(n)，则 f(n) = Θ(g(n))

**通俗理解**：f(n) 和 g(n) 的增长速度**相同**（同阶）

**重要关系**：f(n) = Θ(g(n)) 当且仅当 f(n) = O(g(n)) 且 f(n) = Ω(g(n))

**例子**：
- 3n² + 2n + 1 = Θ(n²)
- n² ≠ Θ(n)

#### 2.2.4 小o符号和小ω符号

| 符号 | 定义 | 含义 |
|------|------|------|
| o(g(n)) | lim(n→∞) f(n)/g(n) = 0 | f(n) 增长**严格慢于** g(n) |
| ω(g(n)) | lim(n→∞) f(n)/g(n) = ∞ | f(n) 增长**严格快于** g(n) |

**例子**：
- n = o(n²)  因为 lim(n→∞) n/n² = 0
- n² = ω(n)  因为 lim(n→∞) n²/n = ∞

### 2.3 常见复杂度比较

**从低到高排序**：
```
O(1) < O(log n) < O(√n) < O(n) < O(n log n) < O(n²) < O(n³) < O(2ⁿ) < O(n!) < O(nⁿ)
```

**记忆口诀**：常对根线，线对平方立方，指数阶乘最可怕

| 复杂度 | 名称 | n=10 | n=100 | n=1000 | 典型算法 |
|--------|------|------|-------|--------|----------|
| O(1) | 常数 | 1 | 1 | 1 | 数组访问 |
| O(log n) | 对数 | 3 | 7 | 10 | 二分查找 |
| O(n) | 线性 | 10 | 100 | 1000 | 线性查找 |
| O(n log n) | 线性对数 | 33 | 664 | 9966 | 归并排序 |
| O(n²) | 平方 | 100 | 10000 | 10⁶ | 冒泡排序 |
| O(2ⁿ) | 指数 | 1024 | 10³⁰ | 巨大 | 穷举子集 |

---

## 三、时间复杂度的计算方法（⭐⭐⭐核心考点）

### 3.1 基本规则

#### 规则1：加法规则（顺序结构）
```
T(n) = T₁(n) + T₂(n) = O(f(n)) + O(g(n)) = O(max(f(n), g(n)))
```
**解释**：顺序执行的代码段，取复杂度最大的那个

#### 规则2：乘法规则（嵌套结构）
```
T(n) = T₁(n) × T₂(n) = O(f(n)) × O(g(n)) = O(f(n) × g(n))
```
**解释**：嵌套循环的复杂度是各层循环复杂度的乘积

#### 规则3：常数忽略
```
O(c·f(n)) = O(f(n))，其中 c 是常数
```

#### 规则4：低阶项忽略
```
O(f(n) + g(n)) = O(f(n))，当 g(n) = o(f(n)) 时
```

### 3.2 循环结构的复杂度分析

#### 3.2.1 简单循环

```pseudo
for i = 1 to n do
    简单操作  // O(1)
end for
```
**复杂度**：O(n)

#### 3.2.2 嵌套循环

```pseudo
for i = 1 to n do
    for j = 1 to n do
        简单操作  // O(1)
    end for
end for
```
**复杂度**：O(n²)

#### 3.2.3 变化步长的循环

**例1：步长翻倍**
```pseudo
i = 1
while i <= n do
    简单操作
    i = i * 2
end while
```
**分析**：循环执行次数 k 满足 2^k ≤ n，即 k ≤ log₂n
**复杂度**：O(log n)

**例2：步长减半**
```pseudo
i = n
while i >= 1 do
    简单操作
    i = i / 2
end while
```
**复杂度**：O(log n)

#### 3.2.4 内层循环依赖外层

**例1：三角形循环**
```pseudo
for i = 1 to n do
    for j = 1 to i do
        简单操作
    end for
end for
```
**分析**：总执行次数 = 1 + 2 + 3 + ... + n = n(n+1)/2
**复杂度**：O(n²)

**例2：特殊依赖**
```pseudo
for i = 1 to n do
    for j = 1 to i*i do
        简单操作
    end for
end for
```
**分析**：总执行次数 = 1² + 2² + 3² + ... + n² = n(n+1)(2n+1)/6
**复杂度**：O(n³)

### 3.3 递归算法的复杂度分析

#### 3.3.1 递推方程法

**步骤**：
1. 写出递归方程 T(n)
2. 展开递推式
3. 找出规律，求通项
4. 用渐近符号表示

**例子：阶乘**
```pseudo
function Factorial(n)
    if n == 1 then
        return 1
    else
        return n * Factorial(n-1)
    end if
end function
```

**分析**：
- T(1) = O(1)
- T(n) = T(n-1) + O(1)
- 展开：T(n) = T(n-1) + c = T(n-2) + 2c = ... = T(1) + (n-1)c
- **复杂度**：O(n)

---

## 四、主定理（Master Theorem）（⭐⭐⭐必考）

### 4.1 主定理的适用形式

主定理用于求解形如以下递归式的时间复杂度：

$$T(n) = aT(n/b) + f(n)$$

其中：
- **a ≥ 1**：子问题的个数
- **b > 1**：子问题规模缩小的倍数
- **f(n)**：分解和合并的代价

### 4.2 主定理的三种情况

设 $n^{\log_b a}$ 为**临界函数**（分水岭）

#### 情况1：f(n) 多项式地小于临界函数

如果 $f(n) = O(n^{\log_b a - \epsilon})$，其中 ε > 0，则：
$$T(n) = \Theta(n^{\log_b a})$$

**通俗理解**：递归树的叶子层主导，复杂度由子问题数量决定

#### 情况2：f(n) 与临界函数同阶

如果 $f(n) = \Theta(n^{\log_b a} \cdot \log^k n)$，其中 k ≥ 0，则：
$$T(n) = \Theta(n^{\log_b a} \cdot \log^{k+1} n)$$

**特别地**，当 k = 0 时：
$$T(n) = \Theta(n^{\log_b a} \cdot \log n)$$

**通俗理解**：每层的工作量相当，复杂度是层数乘以每层工作量

#### 情况3：f(n) 多项式地大于临界函数

如果 $f(n) = \Omega(n^{\log_b a + \epsilon})$，其中 ε > 0，且满足**正则条件** af(n/b) ≤ cf(n)（c < 1），则：
$$T(n) = \Theta(f(n))$$

**通俗理解**：根节点层主导，复杂度由分解合并代价决定

### 4.3 主定理使用步骤（⭐解题模板）

```
步骤1：识别 a, b, f(n)
步骤2：计算临界函数 n^(log_b a)
步骤3：比较 f(n) 与 n^(log_b a) 的大小关系
步骤4：套用对应情况得出结论
```

### 4.4 主定理经典例题详解

#### 例题1：归并排序

**递归式**：T(n) = 2T(n/2) + Θ(n)

**解答**：
- a = 2, b = 2, f(n) = n
- 临界函数：n^(log₂2) = n¹ = n
- 比较：f(n) = n = Θ(n) = Θ(n^(log₂2))
- 属于**情况2**（k=0）
- **结论**：T(n) = Θ(n log n)

#### 例题2：二分查找

**递归式**：T(n) = T(n/2) + Θ(1)

**解答**：
- a = 1, b = 2, f(n) = 1
- 临界函数：n^(log₂1) = n⁰ = 1
- 比较：f(n) = 1 = Θ(1) = Θ(n^(log₂1))
- 属于**情况2**（k=0）
- **结论**：T(n) = Θ(log n)

#### 例题3：某分治算法

**递归式**：T(n) = 4T(n/2) + n

**解答**：
- a = 4, b = 2, f(n) = n
- 临界函数：n^(log₂4) = n²
- 比较：f(n) = n = O(n^(2-1)) = O(n^(log₂4 - ε))，取 ε = 1
- 属于**情况1**
- **结论**：T(n) = Θ(n²)

#### 例题4：Strassen矩阵乘法

**递归式**：T(n) = 7T(n/2) + Θ(n²)

**解答**：
- a = 7, b = 2, f(n) = n²
- 临界函数：n^(log₂7) ≈ n^2.807
- 比较：f(n) = n² = O(n^(2.807-0.807)) = O(n^(log₂7 - ε))，取 ε ≈ 0.807
- 属于**情况1**
- **结论**：T(n) = Θ(n^(log₂7)) ≈ Θ(n^2.807)

#### 例题5：某特殊递归

**递归式**：T(n) = 2T(n/2) + n log n

**解答**：
- a = 2, b = 2, f(n) = n log n
- 临界函数：n^(log₂2) = n
- 比较：f(n) = n log n = Θ(n · log n) = Θ(n^(log₂2) · log n)
- 属于**情况2**（k=1）
- **结论**：T(n) = Θ(n log² n)

#### 例题6：不能用主定理的情况

**递归式**：T(n) = 2T(n/2) + n/log n

**分析**：
- a = 2, b = 2, f(n) = n/log n
- 临界函数：n
- f(n) = n/log n 与 n 的比值为 1/log n
- 这**不是多项式关系**（log n 不是 n 的某个幂次）
- **主定理不适用**，需要用其他方法（如递归树法）

### 4.5 主定理速查表

| 递归式 | a | b | 临界函数 | f(n) | 情况 | 复杂度 |
|--------|---|---|----------|------|------|--------|
| T(n)=T(n/2)+1 | 1 | 2 | 1 | 1 | 2 | Θ(log n) |
| T(n)=2T(n/2)+n | 2 | 2 | n | n | 2 | Θ(n log n) |
| T(n)=2T(n/2)+1 | 2 | 2 | n | 1 | 1 | Θ(n) |
| T(n)=4T(n/2)+n | 4 | 2 | n² | n | 1 | Θ(n²) |
| T(n)=4T(n/2)+n² | 4 | 2 | n² | n² | 2 | Θ(n² log n) |
| T(n)=4T(n/2)+n³ | 4 | 2 | n² | n³ | 3 | Θ(n³) |
| T(n)=3T(n/4)+n log n | 3 | 4 | n^0.79 | n log n | 3 | Θ(n log n) |
| T(n)=9T(n/3)+n | 9 | 3 | n² | n | 1 | Θ(n²) |

---

## 五、空间复杂度分析

### 5.1 定义

空间复杂度 S(n) 是算法运行过程中**临时占用存储空间**大小的度量。

**注意**：不包括输入数据本身占用的空间，只计算算法额外需要的空间。

### 5.2 组成部分

1. **固定部分**：与输入规模无关的空间（常量、简单变量）
2. **可变部分**：与输入规模相关的空间（动态数组、递归栈）

### 5.3 常见情况分析

#### 情况1：常数空间 O(1)

```pseudo
function Swap(a, b)
    temp = a
    a = b
    b = temp
end function
```
只用了一个临时变量，S(n) = O(1)

#### 情况2：线性空间 O(n)

```pseudo
function CopyArray(A, n)
    B = new array[n]
    for i = 1 to n do
        B[i] = A[i]
    end for
    return B
end function
```
创建了大小为 n 的数组，S(n) = O(n)

#### 情况3：递归调用的空间

```pseudo
function Factorial(n)
    if n == 1 then
        return 1
    else
        return n * Factorial(n-1)
    end if
end function
```
递归深度为 n，每层需要常数空间，S(n) = O(n)

### 5.4 递归算法空间复杂度公式

$$S(n) = O(递归深度 \times 每层额外空间)$$

| 算法 | 递归深度 | 每层空间 | 空间复杂度 |
|------|----------|----------|------------|
| 线性递归（如阶乘） | n | O(1) | O(n) |
| 二分查找 | log n | O(1) | O(log n) |
| 归并排序 | log n | O(n) | O(n) |
| 快速排序（最好） | log n | O(1) | O(log n) |
| 快速排序（最坏） | n | O(1) | O(n) |

---

## 六、期末考试重点与考法

### 6.1 常见题型

| 题型 | 考查内容 | 分值估计 |
|------|----------|----------|
| 选择/填空 | 渐近符号定义、复杂度比较 | 10-20分 |
| 计算题 | 分析给定代码的时间复杂度 | 15-25分 |
| 计算题 | 用主定理求解递归式 | 15-20分 |
| 证明题 | 证明某函数的渐近界 | 10-15分 |

### 6.2 易错点提醒

1. **主定理三种情况的判断**：必须是**多项式**关系，log 因子不算
2. **大O、大Ω、大Θ的区别**：上界、下界、紧确界
3. **递归空间复杂度**：别忘了递归栈的开销
4. **最好/最坏/平均情况**：题目问的是哪种情况要看清

### 6.3 解题技巧

1. **看到递归式**：先判断能否用主定理
2. **看到循环**：数循环次数，注意变量变化规律
3. **看到嵌套循环**：用求和公式
4. **证明渐近界**：找 c 和 n₀ 的具体值

---

## 七、本讲核心公式速查

### 渐近符号定义
| 符号 | 定义 |
|------|------|
| f(n) = O(g(n)) | ∃c>0, n₀>0, ∀n≥n₀: f(n) ≤ c·g(n) |
| f(n) = Ω(g(n)) | ∃c>0, n₀>0, ∀n≥n₀: f(n) ≥ c·g(n) |
| f(n) = Θ(g(n)) | f(n) = O(g(n)) 且 f(n) = Ω(g(n)) |

### 主定理
对于 T(n) = aT(n/b) + f(n)：
| 条件 | 结论 |
|------|------|
| f(n) = O(n^(log_b a - ε)) | T(n) = Θ(n^(log_b a)) |
| f(n) = Θ(n^(log_b a) · log^k n) | T(n) = Θ(n^(log_b a) · log^(k+1) n) |
| f(n) = Ω(n^(log_b a + ε)) 且正则 | T(n) = Θ(f(n)) |

### 常用求和公式
| 公式 | 结果 |
|------|------|
| 1+2+...+n | n(n+1)/2 = Θ(n²) |
| 1²+2²+...+n² | n(n+1)(2n+1)/6 = Θ(n³) |
| 1+2+4+...+2^n | 2^(n+1)-1 = Θ(2^n) |
| 1+1/2+1/4+...+1/2^n | 2-1/2^n = Θ(1) |
| log1+log2+...+logn | log(n!) = Θ(n log n) |

---

---

# 第二讲：归纳法（Induction）

## 一、归纳法概述

### 1.1 什么是归纳法？

**归纳法**是一种重要的算法设计思想，其核心理念是：
> 如果我们能解决规模为 n-1 的问题，就能利用这个解来构造规模为 n 的问题的解。

**与数学归纳法的联系**：
- 数学归纳法用于**证明**命题对所有自然数成立
- 算法中的归纳法用于**设计**算法，通过递归实现

### 1.2 归纳法的基本思想

```
归纳法设计算法的核心思路：

1. 基础情况（Base Case）：直接解决最小规模的问题
2. 归纳假设（Inductive Hypothesis）：假设规模较小的问题已经解决
3. 归纳步骤（Inductive Step）：利用较小规模的解构造当前规模的解
```

### 1.3 归纳法与递归的关系

| 概念 | 含义 | 角色 |
|------|------|------|
| 归纳法 | 算法设计思想 | 设计方法论 |
| 递归 | 程序实现方式 | 具体实现手段 |

**关系**：归纳法设计的算法通常用递归来实现

---

## 二、归纳法设计算法的步骤（⭐核心方法）

### 2.1 标准步骤

```
步骤1：定义问题 P(n)
        明确问题的输入、输出和规模参数 n

步骤2：确定基础情况
        找出最小规模（通常 n=0 或 n=1）的解

步骤3：建立归纳假设
        假设 P(k) 对所有 k < n 都已解决

步骤4：设计归纳步骤
        利用 P(k) 的解（k < n）构造 P(n) 的解

步骤5：验证正确性
        确保归纳步骤正确地从小问题推导出大问题
```

### 2.2 归纳法的两种形式

#### 弱归纳（Simple Induction）
- 只利用 P(n-1) 的解来构造 P(n) 的解
- 适用于问题具有**线性递推**关系

#### 强归纳（Strong Induction）
- 可以利用 P(1), P(2), ..., P(n-1) 中的**任意一个或多个**解
- 适用于问题需要**多个子问题**的结果

---

## 三、经典例题详解

### 3.1 例题1：求最大元素

#### 问题描述
给定数组 A[1..n]，找出其中的最大元素。

#### 归纳法分析

**定义问题**：P(n) = 找出 A[1..n] 中的最大元素

**基础情况**：P(1) = A[1]（只有一个元素，它就是最大的）

**归纳假设**：假设我们已经能找出 A[1..n-1] 中的最大元素 max_{n-1}

**归纳步骤**：
- 比较 max_{n-1} 和 A[n]
- P(n) = max(max_{n-1}, A[n])

#### 伪代码

```pseudo
function FindMax(A, n)
    // 基础情况
    if n == 1 then
        return A[1]
    end if
    
    // 归纳步骤
    max_prev = FindMax(A, n-1)    // 归纳假设：能解决规模 n-1 的问题
    
    if A[n] > max_prev then
        return A[n]
    else
        return max_prev
    end if
end function
```

#### 复杂度分析
- **时间复杂度**：T(n) = T(n-1) + O(1) = O(n)
- **空间复杂度**：S(n) = O(n)（递归栈深度）

#### 注意事项
- 这个问题用迭代更高效（空间 O(1)）
- 此例主要展示归纳法思想，实际中不推荐递归实现

---

### 3.2 例题2：整数幂运算

#### 问题描述
计算 x^n，其中 x 是实数，n 是非负整数。

#### 方法一：简单归纳（线性时间）

**归纳思路**：x^n = x^(n-1) × x

```pseudo
function Power_Simple(x, n)
    // 基础情况
    if n == 0 then
        return 1
    end if
    
    // 归纳步骤
    return x * Power_Simple(x, n-1)
end function
```

**复杂度**：T(n) = O(n)

#### 方法二：快速幂（对数时间）⭐重要

**归纳思路**（强归纳）：
- 如果 n 是偶数：x^n = (x^(n/2))²
- 如果 n 是奇数：x^n = x × x^(n-1)

```pseudo
function Power_Fast(x, n)
    // 基础情况
    if n == 0 then
        return 1
    end if
    
    // 归纳步骤
    if n 是偶数 then
        half = Power_Fast(x, n/2)
        return half * half
    else
        return x * Power_Fast(x, n-1)
    end if
end function
```

#### 复杂度分析

**递归式**：T(n) = T(n/2) + O(1)

**用主定理**：
- a = 1, b = 2, f(n) = 1
- 临界函数：n^(log₂1) = 1
- f(n) = Θ(1) = Θ(n^0)，属于情况2
- **T(n) = O(log n)**

#### 迭代版本（推荐实现）

```pseudo
function Power_Iterative(x, n)
    result = 1
    while n > 0 do
        if n 是奇数 then
            result = result * x
        end if
        x = x * x
        n = n / 2  // 整数除法
    end while
    return result
end function
```

**空间复杂度**：O(1)

#### 注意事项
- 计算 half × half 时只调用一次递归，不要写成 Power_Fast(x, n/2) × Power_Fast(x, n/2)
- 后者会导致 T(n) = 2T(n/2) + O(1) = O(n)，失去优化效果

---

### 3.3 例题3：多项式求值（Horner法则）

#### 问题描述
计算多项式 P(x) = aₙxⁿ + aₙ₋₁xⁿ⁻¹ + ... + a₁x + a₀ 在 x = x₀ 处的值。

#### 朴素方法
分别计算每一项再求和，需要 O(n²) 次乘法。

#### Horner法则（归纳法）⭐

**关键观察**：
$$P(x) = a_0 + x(a_1 + x(a_2 + ... + x(a_{n-1} + x \cdot a_n)...))$$

**归纳思路**：
- 定义 P_k(x) = aₙxᵏ + aₙ₋₁xᵏ⁻¹ + ... + aₙ₋ₖ
- P_0(x) = aₙ
- P_k(x) = x × P_{k-1}(x) + aₙ₋ₖ

```pseudo
function Horner(A, n, x)
    // A[0..n] 存储系数 a₀, a₁, ..., aₙ
    // 基础情况
    result = A[n]
    
    // 归纳步骤
    for i = n-1 downto 0 do
        result = result * x + A[i]
    end for
    
    return result
end function
```

#### 复杂度分析
- **乘法次数**：n 次
- **加法次数**：n 次
- **时间复杂度**：O(n)
- **空间复杂度**：O(1)

#### 对比

| 方法 | 乘法次数 | 加法次数 | 时间复杂度 |
|------|----------|----------|------------|
| 朴素方法 | n(n+1)/2 | n | O(n²) |
| Horner法则 | n | n | O(n) |

---

### 3.4 例题4：生成全排列

#### 问题描述
生成 {1, 2, ..., n} 的所有排列。

#### 归纳法分析

**基础情况**：n=1 时，只有一个排列 [1]

**归纳假设**：假设已经生成了 {1, 2, ..., n-1} 的所有 (n-1)! 个排列

**归纳步骤**：对于每个 (n-1)! 个排列，将 n 插入到所有可能的位置（n 个位置），得到 n! 个排列

#### 伪代码

```pseudo
function Permutations(n)
    if n == 1 then
        return [[1]]
    end if
    
    // 获取规模 n-1 的所有排列
    prev_perms = Permutations(n-1)
    result = []
    
    // 对每个排列，将 n 插入所有可能位置
    for each perm in prev_perms do
        for i = 0 to n-1 do
            new_perm = Insert(perm, i, n)  // 在位置 i 插入 n
            result.append(new_perm)
        end for
    end for
    
    return result
end function
```

#### 另一种方法：交换法

```pseudo
function Permute(A, l, r)
    // A[l..r] 的全排列
    if l == r then
        print(A)  // 输出一个排列
    else
        for i = l to r do
            Swap(A[l], A[i])      // 选择第 i 个元素放在首位
            Permute(A, l+1, r)    // 递归生成剩余元素的排列
            Swap(A[l], A[i])      // 回溯，恢复原状
        end for
    end if
end function
```

#### 复杂度分析
- **排列数量**：n!
- **时间复杂度**：O(n × n!)（生成每个排列需要 O(n) 时间）
- **空间复杂度**：O(n)（递归深度）

---

### 3.5 例题5：二分查找

#### 问题描述
在有序数组 A[1..n] 中查找元素 x。

#### 归纳法分析（强归纳）

**思路**：将问题规模减半

**归纳步骤**：
1. 取中间元素 A[mid]
2. 如果 x = A[mid]，找到
3. 如果 x < A[mid]，在 A[1..mid-1] 中查找
4. 如果 x > A[mid]，在 A[mid+1..n] 中查找

```pseudo
function BinarySearch(A, low, high, x)
    // 基础情况
    if low > high then
        return -1  // 未找到
    end if
    
    // 归纳步骤
    mid = (low + high) / 2
    
    if A[mid] == x then
        return mid
    else if x < A[mid] then
        return BinarySearch(A, low, mid-1, x)
    else
        return BinarySearch(A, mid+1, high, x)
    end if
end function
```

#### 复杂度分析
- **递归式**：T(n) = T(n/2) + O(1)
- **时间复杂度**：O(log n)
- **空间复杂度**：O(log n)（递归版）或 O(1)（迭代版）

#### 迭代版本

```pseudo
function BinarySearch_Iterative(A, n, x)
    low = 1
    high = n
    
    while low <= high do
        mid = (low + high) / 2
        if A[mid] == x then
            return mid
        else if x < A[mid] then
            high = mid - 1
        else
            low = mid + 1
        end if
    end while
    
    return -1
end function
```

#### 注意事项
1. **循环条件**：low <= high（不是 low < high）
2. **mid 计算**：(low + high) / 2 可能溢出，更安全的写法是 low + (high - low) / 2
3. **边界更新**：mid-1 和 mid+1，不能写成 mid

---

### 3.6 例题6：汉诺塔问题

#### 问题描述
有三根柱子 A、B、C，A 柱上有 n 个大小不同的圆盘（从上到下递增），要求将所有圆盘移到 C 柱，规则：
1. 每次只能移动一个圆盘
2. 大盘不能放在小盘上面

#### 归纳法分析

**基础情况**：n=1 时，直接将圆盘从 A 移到 C

**归纳假设**：假设能够将 n-1 个圆盘从任意柱移到另一柱

**归纳步骤**：
1. 将上面 n-1 个圆盘从 A 移到 B（借助 C）
2. 将最大的圆盘从 A 移到 C
3. 将 n-1 个圆盘从 B 移到 C（借助 A）

#### 伪代码

```pseudo
function Hanoi(n, source, auxiliary, target)
    if n == 1 then
        print("Move disk from " + source + " to " + target)
    else
        // 步骤1：将 n-1 个盘从 source 移到 auxiliary
        Hanoi(n-1, source, target, auxiliary)
        
        // 步骤2：将最大盘从 source 移到 target
        print("Move disk from " + source + " to " + target)
        
        // 步骤3：将 n-1 个盘从 auxiliary 移到 target
        Hanoi(n-1, auxiliary, source, target)
    end if
end function
```

#### 复杂度分析

**递归式**：T(n) = 2T(n-1) + 1

**求解**：
- T(n) = 2T(n-1) + 1
- T(n) = 2[2T(n-2) + 1] + 1 = 4T(n-2) + 2 + 1
- T(n) = 2^k × T(n-k) + 2^(k-1) + ... + 2 + 1
- 当 k = n-1 时：T(n) = 2^(n-1) × T(1) + 2^(n-2) + ... + 1
- T(n) = 2^(n-1) + 2^(n-2) + ... + 1 = 2^n - 1

**时间复杂度**：O(2ⁿ)

#### 移动次数公式
$$M(n) = 2^n - 1$$

这是**最优解**，不可能用更少的步骤完成。

---

## 四、归纳法与其他方法的对比

### 4.1 归纳法 vs 分治法

| 对比项 | 归纳法 | 分治法 |
|--------|--------|--------|
| 子问题数量 | 通常 1 个 | 通常 2 个或更多 |
| 子问题规模 | n-1（减一） | n/2（减半） |
| 典型复杂度 | O(n) 或 O(2ⁿ) | O(n log n) |
| 代表算法 | 阶乘、汉诺塔 | 归并排序、快速排序 |

### 4.2 归纳法 vs 动态规划

| 对比项 | 归纳法（递归） | 动态规划 |
|--------|----------------|----------|
| 计算方向 | 自顶向下 | 自底向上 |
| 重复计算 | 可能有 | 通过表格避免 |
| 空间效率 | 递归栈开销 | 可优化到 O(1) |
| 适用场景 | 子问题不重叠 | 子问题重叠 |

---

## 五、期末考试重点

### 5.1 常见考法

| 题型 | 考查内容 |
|------|----------|
| 设计题 | 用归纳法设计算法解决给定问题 |
| 分析题 | 分析归纳法算法的正确性 |
| 复杂度 | 求解递归式的时间复杂度 |
| 代码填空 | 补全归纳法算法的关键步骤 |

### 5.2 解题模板

```
1. 明确定义问题 P(n)
2. 写出基础情况（边界条件）
3. 写出归纳假设（假设小规模问题已解决）
4. 设计归纳步骤（如何利用小规模的解）
5. 分析复杂度（写递归式并求解）
```

### 5.3 易错点

1. **基础情况遗漏**：忘记处理 n=0 或 n=1 的情况
2. **归纳步骤错误**：没有正确利用归纳假设
3. **无限递归**：递归没有向基础情况收敛
4. **重复计算**：没有意识到需要用动态规划优化

---

## 六、本讲核心公式速查

### 常见递归式及复杂度

| 递归式 | 复杂度 | 典型算法 |
|--------|--------|----------|
| T(n) = T(n-1) + O(1) | O(n) | 线性递归 |
| T(n) = T(n-1) + O(n) | O(n²) | 选择排序递归版 |
| T(n) = T(n/2) + O(1) | O(log n) | 二分查找 |
| T(n) = 2T(n-1) + O(1) | O(2ⁿ) | 汉诺塔 |
| T(n) = T(n-1) + T(n-2) | O(φⁿ) ≈ O(1.618ⁿ) | 斐波那契递归 |

### 排列组合公式

| 公式 | 结果 |
|------|------|
| n 个元素的全排列数 | n! |
| n 个元素取 k 个的排列 | n!/(n-k)! |
| n 个元素取 k 个的组合 | C(n,k) = n!/[k!(n-k)!] |

---

---

# 第三讲：分治法（Divide and Conquer）

## 一、分治法概述

### 1.1 什么是分治法？

**分治法**是一种重要的算法设计范式，其核心思想是：

> **分而治之**：将一个规模为 n 的问题分解成若干个规模较小的**相同类型**的子问题，递归地解决这些子问题，然后合并子问题的解得到原问题的解。

### 1.2 分治法的三个步骤（⭐核心）

```
┌─────────────────────────────────────────────────────────┐
│                    分治法三步曲                          │
├─────────────────────────────────────────────────────────┤
│  1. Divide（分解）：将原问题分解成若干个子问题            │
│  2. Conquer（解决）：递归地解决各个子问题                 │
│  3. Combine（合并）：将子问题的解合并成原问题的解         │
└─────────────────────────────────────────────────────────┘
```

### 1.3 分治法的适用条件

一个问题适合用分治法解决，需要满足以下条件：

| 条件 | 说明 |
|------|------|
| **可分解性** | 问题可以分解成若干个规模较小的相同类型子问题 |
| **子问题独立** | 子问题之间相互独立，没有公共子问题 |
| **可合并性** | 子问题的解可以合并成原问题的解 |
| **基础情况** | 存在可直接求解的最小规模问题 |

### 1.4 分治法的通用框架

```pseudo
function DivideAndConquer(P, n)
    // 基础情况
    if n <= threshold then
        return DirectSolve(P)
    end if
    
    // 分解：将问题 P 分解成 k 个子问题
    (P₁, P₂, ..., Pₖ) = Divide(P)
    
    // 解决：递归求解各子问题
    for i = 1 to k do
        Sᵢ = DivideAndConquer(Pᵢ, n/b)
    end for
    
    // 合并：将子问题的解合并
    S = Combine(S₁, S₂, ..., Sₖ)
    
    return S
end function
```

### 1.5 分治法的时间复杂度

分治法的时间复杂度通常可以用以下递归式表示：

$$T(n) = aT(n/b) + f(n)$$

其中：
- **a**：子问题的个数
- **b**：子问题规模缩小的倍数
- **f(n)**：分解和合并的时间代价

**求解方法**：使用**主定理**（见第一讲）

---

## 二、经典分治算法详解

### 2.1 归并排序（Merge Sort）⭐⭐⭐必考

#### 问题描述
对数组 A[1..n] 进行排序。

#### 分治思想

| 步骤 | 操作 |
|------|------|
| **Divide** | 将数组分成两半：A[1..n/2] 和 A[n/2+1..n] |
| **Conquer** | 递归地对两个子数组排序 |
| **Combine** | 将两个有序子数组合并成一个有序数组 |

#### 算法图示

```
原数组:     [38, 27, 43, 3, 9, 82, 10]
              /                    \
分解:    [38, 27, 43, 3]      [9, 82, 10]
           /        \            /      \
        [38, 27]  [43, 3]    [9, 82]   [10]
         /   \     /   \      /   \      |
       [38] [27] [43] [3]   [9]  [82]  [10]
         \   /     \   /      \   /      |
合并:    [27, 38]  [3, 43]   [9, 82]   [10]
           \        /            \      /
         [3, 27, 38, 43]      [9, 10, 82]
              \                    /
结果:     [3, 9, 10, 27, 38, 43, 82]
```

#### 伪代码

```pseudo
function MergeSort(A, left, right)
    // 基础情况
    if left >= right then
        return
    end if
    
    // Divide：计算中点
    mid = (left + right) / 2
    
    // Conquer：递归排序两个子数组
    MergeSort(A, left, mid)
    MergeSort(A, mid + 1, right)
    
    // Combine：合并两个有序子数组
    Merge(A, left, mid, right)
end function

function Merge(A, left, mid, right)
    // 创建临时数组
    n1 = mid - left + 1
    n2 = right - mid
    L[1..n1] = A[left..mid]
    R[1..n2] = A[mid+1..right]
    
    // 合并过程
    i = 1, j = 1, k = left
    while i <= n1 and j <= n2 do
        if L[i] <= R[j] then
            A[k] = L[i]
            i = i + 1
        else
            A[k] = R[j]
            j = j + 1
        end if
        k = k + 1
    end while
    
    // 复制剩余元素
    while i <= n1 do
        A[k] = L[i]
        i = i + 1
        k = k + 1
    end while
    
    while j <= n2 do
        A[k] = R[j]
        j = j + 1
        k = k + 1
    end while
end function
```

#### 复杂度分析

**递归式**：T(n) = 2T(n/2) + Θ(n)

**用主定理**：
- a = 2, b = 2, f(n) = n
- 临界函数：n^(log₂2) = n
- f(n) = Θ(n)，属于**情况2**
- **T(n) = Θ(n log n)**

| 复杂度 | 最好 | 平均 | 最坏 |
|--------|------|------|------|
| 时间 | O(n log n) | O(n log n) | O(n log n) |
| 空间 | O(n) | O(n) | O(n) |

#### 归并排序的特点

| 特点 | 说明 |
|------|------|
| **稳定性** | ✅ 稳定排序（相等元素保持原有顺序） |
| **时间稳定** | 最好/最坏/平均都是 O(n log n) |
| **空间开销** | 需要 O(n) 额外空间 |
| **适用场景** | 外部排序、链表排序 |

#### 注意事项
1. Merge 函数中 `L[i] <= R[j]` 保证稳定性，若改成 `<` 则不稳定
2. 空间复杂度为 O(n)，无法原地排序
3. 对于小规模数组，可以切换到插入排序提高效率

---

### 2.2 快速排序（Quick Sort）⭐⭐⭐必考

#### 问题描述
对数组 A[1..n] 进行排序。

#### 分治思想

| 步骤 | 操作 |
|------|------|
| **Divide** | 选择基准元素 pivot，将数组划分为两部分：≤pivot 和 >pivot |
| **Conquer** | 递归地对两个子数组排序 |
| **Combine** | 无需合并（原地排序） |

#### 算法图示

```
原数组:     [38, 27, 43, 3, 9, 82, 10]
                     选择 pivot = 38
                          ↓
划分后:     [27, 3, 9, 10] 38 [43, 82]
               ↓                 ↓
递归:      [3, 9, 10] 27      43 [82]
              ↓                    ↓
           [3, 9] 10              82
              ↓
            3 [9]
结果:      [3, 9, 10, 27, 38, 43, 82]
```

#### 伪代码

```pseudo
function QuickSort(A, low, high)
    if low < high then
        // Divide：划分数组
        pivot_index = Partition(A, low, high)
        
        // Conquer：递归排序两个子数组
        QuickSort(A, low, pivot_index - 1)
        QuickSort(A, pivot_index + 1, high)
    end if
end function

function Partition(A, low, high)
    pivot = A[high]  // 选择最后一个元素作为基准
    i = low - 1      // i 指向小于 pivot 的区域的最后一个元素
    
    for j = low to high - 1 do
        if A[j] <= pivot then
            i = i + 1
            Swap(A[i], A[j])
        end if
    end for
    
    Swap(A[i + 1], A[high])
    return i + 1
end function
```

#### Partition 过程详解

```
初始: [38, 27, 43, 3, 9, 82, 10]  pivot=10, i=-1
                                  
j=0: 38>10, 不交换              [38, 27, 43, 3, 9, 82, 10]  i=-1
j=1: 27>10, 不交换              [38, 27, 43, 3, 9, 82, 10]  i=-1
j=2: 43>10, 不交换              [38, 27, 43, 3, 9, 82, 10]  i=-1
j=3: 3<=10, i=0, 交换A[0],A[3]  [3, 27, 43, 38, 9, 82, 10]  i=0
j=4: 9<=10, i=1, 交换A[1],A[4]  [3, 9, 43, 38, 27, 82, 10]  i=1
j=5: 82>10, 不交换              [3, 9, 43, 38, 27, 82, 10]  i=1

最后: 交换A[i+1],A[high]        [3, 9, 10, 38, 27, 82, 43]
返回 pivot_index = 2
```

#### 复杂度分析

**最坏情况**（数组已排序或逆序）：
- 每次划分极不平衡：一边 0 个，一边 n-1 个
- T(n) = T(n-1) + Θ(n) = **O(n²)**

**最好情况**（每次均匀划分）：
- T(n) = 2T(n/2) + Θ(n) = **O(n log n)**

**平均情况**：
- **O(n log n)**

| 复杂度 | 最好 | 平均 | 最坏 |
|--------|------|------|------|
| 时间 | O(n log n) | O(n log n) | O(n²) |
| 空间 | O(log n) | O(log n) | O(n) |

#### 快速排序 vs 归并排序

| 对比项 | 快速排序 | 归并排序 |
|--------|----------|----------|
| 平均时间 | O(n log n) | O(n log n) |
| 最坏时间 | O(n²) | O(n log n) |
| 空间 | O(log n) | O(n) |
| 稳定性 | ❌ 不稳定 | ✅ 稳定 |
| 原地排序 | ✅ 是 | ❌ 否 |
| 实际性能 | 通常更快（常数因子小） | 稳定但常数因子大 |

#### 优化策略

1. **三数取中法**：选择首、中、尾三个元素的中位数作为 pivot
2. **随机化**：随机选择 pivot，避免最坏情况
3. **小规模切换**：当子数组规模小于阈值时，使用插入排序
4. **三路划分**：处理大量重复元素的情况

#### 随机化快速排序

```pseudo
function RandomizedPartition(A, low, high)
    // 随机选择一个元素作为 pivot
    random_index = Random(low, high)
    Swap(A[random_index], A[high])
    return Partition(A, low, high)
end function
```

---

### 2.3 二分查找（Binary Search）

#### 分治思想

| 步骤 | 操作 |
|------|------|
| **Divide** | 取中间元素，将数组分成两半 |
| **Conquer** | 根据比较结果，只在一半中递归查找 |
| **Combine** | 直接返回结果，无需合并 |

#### 伪代码

```pseudo
function BinarySearch(A, low, high, target)
    if low > high then
        return -1  // 未找到
    end if
    
    mid = low + (high - low) / 2  // 防止溢出
    
    if A[mid] == target then
        return mid
    else if A[mid] > target then
        return BinarySearch(A, low, mid - 1, target)
    else
        return BinarySearch(A, mid + 1, high, target)
    end if
end function
```

#### 复杂度
- **时间**：T(n) = T(n/2) + O(1) = **O(log n)**
- **空间**：O(log n)（递归）或 O(1)（迭代）

---

### 2.4 大整数乘法（Karatsuba算法）⭐

#### 问题描述
计算两个 n 位大整数 X 和 Y 的乘积。

#### 朴素方法
逐位相乘再相加，时间复杂度 O(n²)。

#### 分治思想

将 n 位整数分成两半：
- X = A × 10^(n/2) + B
- Y = C × 10^(n/2) + D

其中 A, B, C, D 都是 n/2 位整数。

**朴素分治**：
$$X \times Y = AC \times 10^n + (AD + BC) \times 10^{n/2} + BD$$

需要 4 次 n/2 位乘法，T(n) = 4T(n/2) + O(n) = O(n²)，没有改进。

#### Karatsuba 改进

**关键观察**：
$$AD + BC = (A+B)(C+D) - AC - BD$$

只需要计算 3 次乘法：
1. P₁ = AC
2. P₂ = BD
3. P₃ = (A+B)(C+D)

然后：
$$X \times Y = P_1 \times 10^n + (P_3 - P_1 - P_2) \times 10^{n/2} + P_2$$

#### 伪代码

```pseudo
function Karatsuba(X, Y, n)
    // 基础情况
    if n == 1 then
        return X * Y
    end if
    
    // 分解
    m = n / 2
    A = X / 10^m      // X 的高位
    B = X mod 10^m    // X 的低位
    C = Y / 10^m      // Y 的高位
    D = Y mod 10^m    // Y 的低位
    
    // 递归计算三个乘积
    P1 = Karatsuba(A, C, m)
    P2 = Karatsuba(B, D, m)
    P3 = Karatsuba(A + B, C + D, m + 1)  // 可能有进位
    
    // 合并
    return P1 * 10^n + (P3 - P1 - P2) * 10^m + P2
end function
```

#### 复杂度分析

**递归式**：T(n) = 3T(n/2) + O(n)

**用主定理**：
- a = 3, b = 2, f(n) = n
- 临界函数：n^(log₂3) ≈ n^1.585
- f(n) = n = O(n^(1.585-0.585))，属于**情况1**
- **T(n) = O(n^(log₂3)) ≈ O(n^1.585)**

#### 对比

| 方法 | 时间复杂度 |
|------|------------|
| 朴素乘法 | O(n²) |
| Karatsuba | O(n^1.585) |
| Toom-Cook | O(n^1.465) |
| FFT乘法 | O(n log n log log n) |

---

### 2.5 Strassen 矩阵乘法⭐

#### 问题描述
计算两个 n×n 矩阵 A 和 B 的乘积 C = A × B。

#### 朴素方法

```pseudo
for i = 1 to n do
    for j = 1 to n do
        C[i][j] = 0
        for k = 1 to n do
            C[i][j] = C[i][j] + A[i][k] * B[k][j]
        end for
    end for
end for
```

**时间复杂度**：O(n³)

#### 分治思想

将 n×n 矩阵分成 4 个 (n/2)×(n/2) 的子矩阵：

$$A = \begin{pmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{pmatrix}, \quad B = \begin{pmatrix} B_{11} & B_{12} \\ B_{21} & B_{22} \end{pmatrix}$$

$$C = A \times B = \begin{pmatrix} C_{11} & C_{12} \\ C_{21} & C_{22} \end{pmatrix}$$

**朴素分治**：
- C₁₁ = A₁₁B₁₁ + A₁₂B₂₁
- C₁₂ = A₁₁B₁₂ + A₁₂B₂₂
- C₂₁ = A₂₁B₁₁ + A₂₂B₂₁
- C₂₂ = A₂₁B₁₂ + A₂₂B₂₂

需要 8 次矩阵乘法，T(n) = 8T(n/2) + O(n²) = O(n³)，没有改进。

#### Strassen 改进

**定义 7 个中间矩阵**：
- M₁ = (A₁₁ + A₂₂)(B₁₁ + B₂₂)
- M₂ = (A₂₁ + A₂₂)B₁₁
- M₃ = A₁₁(B₁₂ - B₂₂)
- M₄ = A₂₂(B₂₁ - B₁₁)
- M₅ = (A₁₁ + A₁₂)B₂₂
- M₆ = (A₂₁ - A₁₁)(B₁₁ + B₁₂)
- M₇ = (A₁₂ - A₂₂)(B₂₁ + B₂₂)

**结果**：
- C₁₁ = M₁ + M₄ - M₅ + M₇
- C₁₂ = M₃ + M₅
- C₂₁ = M₂ + M₄
- C₂₂ = M₁ - M₂ + M₃ + M₆

只需要 **7 次**矩阵乘法！

#### 复杂度分析

**递归式**：T(n) = 7T(n/2) + O(n²)

**用主定理**：
- a = 7, b = 2, f(n) = n²
- 临界函数：n^(log₂7) ≈ n^2.807
- f(n) = n² = O(n^(2.807-0.807))，属于**情况1**
- **T(n) = O(n^(log₂7)) ≈ O(n^2.807)**

#### 对比

| 方法 | 时间复杂度 |
|------|------------|
| 朴素乘法 | O(n³) |
| Strassen | O(n^2.807) |
| Coppersmith-Winograd | O(n^2.376) |
| 当前最优 | O(n^2.373) |

#### 注意事项
1. Strassen 算法常数因子大，只有 n 很大时才有优势
2. 实际中 n < 几百时，朴素算法更快
3. 数值稳定性不如朴素算法

---

### 2.6 最近点对问题⭐⭐

#### 问题描述
给定平面上 n 个点，找出距离最近的两个点。

#### 朴素方法
枚举所有点对，时间复杂度 O(n²)。

#### 分治思想

| 步骤 | 操作 |
|------|------|
| **预处理** | 按 x 坐标排序 |
| **Divide** | 用垂直线将点集分成左右两半 |
| **Conquer** | 递归求左半和右半的最近点对 |
| **Combine** | 检查跨越分割线的点对 |

#### 关键优化

设左半最近距离为 d₁，右半最近距离为 d₂，d = min(d₁, d₂)。

**关键观察**：跨越分割线的最近点对，两点必须都在分割线两侧 d 距离内的带状区域中。

**更强的结论**：对于带状区域中的每个点，只需检查按 y 坐标排序后的**最多 7 个**后续点。

#### 伪代码

```pseudo
function ClosestPair(P)
    // 预处理：按 x 坐标排序
    Px = Sort P by x-coordinate
    Py = Sort P by y-coordinate
    return ClosestPairRec(Px, Py)
end function

function ClosestPairRec(Px, Py)
    n = |Px|
    
    // 基础情况
    if n <= 3 then
        return BruteForce(Px)
    end if
    
    // Divide
    mid = n / 2
    midPoint = Px[mid]
    Qx = Px[1..mid]
    Rx = Px[mid+1..n]
    Qy = points in Py that are in Qx
    Ry = points in Py that are in Rx
    
    // Conquer
    (p1, q1) = ClosestPairRec(Qx, Qy)
    (p2, q2) = ClosestPairRec(Rx, Ry)
    
    d = min(dist(p1,q1), dist(p2,q2))
    
    // Combine：检查跨越分割线的点对
    Strip = points in Py within distance d of midPoint.x
    
    for i = 1 to |Strip| do
        for j = i+1 to min(i+7, |Strip|) do
            if dist(Strip[i], Strip[j]) < d then
                d = dist(Strip[i], Strip[j])
                update closest pair
            end if
        end for
    end for
    
    return closest pair
end function
```

#### 复杂度分析

**递归式**：T(n) = 2T(n/2) + O(n)

**用主定理**：
- a = 2, b = 2, f(n) = n
- 属于**情况2**
- **T(n) = O(n log n)**

---

### 2.7 求第 k 小元素（Selection）⭐

#### 问题描述
在无序数组中找到第 k 小的元素。

#### 方法一：排序后取第 k 个
时间复杂度 O(n log n)

#### 方法二：基于快排的选择（QuickSelect）

**思想**：利用 Partition，每次只递归一边

```pseudo
function QuickSelect(A, low, high, k)
    if low == high then
        return A[low]
    end if
    
    pivot_index = Partition(A, low, high)
    rank = pivot_index - low + 1  // pivot 是第几小
    
    if k == rank then
        return A[pivot_index]
    else if k < rank then
        return QuickSelect(A, low, pivot_index - 1, k)
    else
        return QuickSelect(A, pivot_index + 1, high, k - rank)
    end if
end function
```

**复杂度**：
- 平均：O(n)
- 最坏：O(n²)

#### 方法三：中位数的中位数（BFPRT算法）

**保证最坏情况 O(n)**

**步骤**：
1. 将数组分成 ⌈n/5⌉ 组，每组 5 个元素
2. 对每组排序，找出每组的中位数
3. 递归找这些中位数的中位数 M
4. 用 M 作为 pivot 进行划分
5. 递归处理

**为什么选 5？** 保证划分至少 3n/10 : 7n/10

**复杂度**：T(n) = T(n/5) + T(7n/10) + O(n) = **O(n)**

---

## 三、分治法的复杂度分析总结

### 3.1 常见分治算法复杂度

| 算法 | 递归式 | 时间复杂度 |
|------|--------|------------|
| 二分查找 | T(n) = T(n/2) + O(1) | O(log n) |
| 归并排序 | T(n) = 2T(n/2) + O(n) | O(n log n) |
| 快速排序（平均） | T(n) = 2T(n/2) + O(n) | O(n log n) |
| 快速排序（最坏） | T(n) = T(n-1) + O(n) | O(n²) |
| Karatsuba乘法 | T(n) = 3T(n/2) + O(n) | O(n^1.585) |
| Strassen矩阵乘法 | T(n) = 7T(n/2) + O(n²) | O(n^2.807) |
| 最近点对 | T(n) = 2T(n/2) + O(n) | O(n log n) |
| QuickSelect（平均） | T(n) = T(n/2) + O(n) | O(n) |

### 3.2 主定理速查（分治专用）

对于 T(n) = aT(n/b) + f(n)：

| 条件 | 结论 |
|------|------|
| f(n) = O(n^(log_b a - ε)) | T(n) = Θ(n^(log_b a)) |
| f(n) = Θ(n^(log_b a)) | T(n) = Θ(n^(log_b a) · log n) |
| f(n) = Ω(n^(log_b a + ε)) | T(n) = Θ(f(n)) |

---

## 四、分治法与其他方法对比

### 4.1 分治法 vs 归纳法

| 对比项 | 分治法 | 归纳法 |
|--------|--------|--------|
| 子问题数 | 多个（通常 2 个） | 通常 1 个 |
| 规模缩减 | 除法（n/2） | 减法（n-1） |
| 子问题关系 | 独立 | 依赖 |
| 典型复杂度 | O(n log n) | O(n) 或 O(2ⁿ) |

### 4.2 分治法 vs 动态规划

| 对比项 | 分治法 | 动态规划 |
|--------|--------|----------|
| 子问题 | 不重叠 | 重叠 |
| 计算方式 | 自顶向下 | 自底向上（或记忆化） |
| 空间 | 递归栈 | 表格 |
| 适用场景 | 排序、查找 | 最优化问题 |

---

## 五、期末考试重点

### 5.1 必考算法

1. **归并排序**：分治过程、Merge 操作、复杂度分析
2. **快速排序**：Partition 操作、最好/最坏/平均复杂度
3. **主定理应用**：给定递归式求复杂度

### 5.2 常见题型

| 题型 | 内容 |
|------|------|
| 算法设计 | 用分治法解决新问题 |
| 代码填空 | 补全 Partition 或 Merge |
| 复杂度分析 | 写递归式并用主定理求解 |
| 算法比较 | 比较不同排序算法的优缺点 |

### 5.3 易错点

1. **Partition 边界**：i 和 j 的初始值和更新方式
2. **Merge 稳定性**：`<=` 保证稳定，`<` 不稳定
3. **递归终止条件**：`left >= right` 还是 `left > right`
4. **主定理适用条件**：必须是多项式关系

---

## 六、本讲核心公式速查

### 排序算法复杂度对比

| 算法 | 最好 | 平均 | 最坏 | 空间 | 稳定 |
|------|------|------|------|------|------|
| 归并排序 | O(n log n) | O(n log n) | O(n log n) | O(n) | ✅ |
| 快速排序 | O(n log n) | O(n log n) | O(n²) | O(log n) | ❌ |
| 堆排序 | O(n log n) | O(n log n) | O(n log n) | O(1) | ❌ |

### 分治递归式模板

| 问题类型 | 递归式 | 复杂度 |
|----------|--------|--------|
| 减半只取一边 | T(n) = T(n/2) + O(1) | O(log n) |
| 减半两边都取 | T(n) = 2T(n/2) + O(n) | O(n log n) |
| 减半两边+线性合并 | T(n) = 2T(n/2) + O(n) | O(n log n) |
| 三分递归 | T(n) = 3T(n/2) + O(n) | O(n^1.585) |

---

---

# 第四讲：动态规划（Dynamic Programming）

## 一、动态规划概述

### 1.1 什么是动态规划？

**动态规划（DP）** 是一种通过把原问题分解为相对简单的子问题的方式来求解复杂问题的方法。

> **核心思想**：将问题分解成**重叠的子问题**，通过**保存子问题的解**（记忆化）来避免重复计算，从而提高效率。

### 1.2 动态规划的两个关键性质

| 性质 | 含义 | 说明 |
|------|------|------|
| **最优子结构** | 问题的最优解包含子问题的最优解 | 可以通过子问题的最优解构造原问题的最优解 |
| **重叠子问题** | 不同的子问题之间有公共的子子问题 | 同一子问题会被多次求解 |

### 1.3 动态规划 vs 分治法

| 对比项 | 动态规划 | 分治法 |
|--------|----------|--------|
| 子问题关系 | **重叠**（有公共子问题） | **独立**（无公共子问题） |
| 解决方式 | 保存子问题的解，避免重复计算 | 递归求解，可能重复计算 |
| 计算方向 | 自底向上（或记忆化自顶向下） | 自顶向下 |
| 典型应用 | 最优化问题 | 排序、查找 |

### 1.4 动态规划的两种实现方式

#### 方式一：自底向上（Bottom-Up）- 递推

```pseudo
// 从最小子问题开始，逐步构建更大问题的解
for i = 0 to n do
    dp[i] = 根据 dp[0..i-1] 计算
end for
return dp[n]
```

#### 方式二：自顶向下（Top-Down）- 记忆化递归

```pseudo
function Solve(n)
    if memo[n] 已计算 then
        return memo[n]
    end if
    
    result = 递归计算
    memo[n] = result
    return result
end function
```

---

## 二、动态规划解题四步法（⭐核心方法）

```
┌─────────────────────────────────────────────────────────────┐
│                    动态规划解题四步法                         │
├─────────────────────────────────────────────────────────────┤
│  Step 1：定义状态                                            │
│          明确 dp[i] 或 dp[i][j] 代表什么含义                  │
├─────────────────────────────────────────────────────────────┤
│  Step 2：确定状态转移方程                                     │
│          找出 dp[i] 与 dp[i-1]... 之间的递推关系              │
├─────────────────────────────────────────────────────────────┤
│  Step 3：确定初始条件和边界                                   │
│          dp[0] 或 dp[0][0] 等基础情况的值                     │
├─────────────────────────────────────────────────────────────┤
│  Step 4：确定计算顺序                                         │
│          确保计算 dp[i] 时，所依赖的状态已经计算完成           │
└─────────────────────────────────────────────────────────────┘
```

---

## 三、经典动态规划问题详解

### 3.1 斐波那契数列（入门示例）

#### 问题描述
计算斐波那契数列第 n 项：F(n) = F(n-1) + F(n-2)，F(0)=0, F(1)=1

#### 方法一：朴素递归（反面教材）

```pseudo
function Fib_Naive(n)
    if n <= 1 then
        return n
    end if
    return Fib_Naive(n-1) + Fib_Naive(n-2)
end function
```

**问题**：大量重复计算
```
                    F(5)
                   /    \
                F(4)    F(3)
               /   \    /   \
            F(3)  F(2) F(2) F(1)
            /  \
         F(2) F(1)
```

**时间复杂度**：O(2ⁿ)（指数级）

#### 方法二：记忆化递归

```pseudo
function Fib_Memo(n, memo)
    if n <= 1 then
        return n
    end if
    if memo[n] != -1 then
        return memo[n]
    end if
    memo[n] = Fib_Memo(n-1, memo) + Fib_Memo(n-2, memo)
    return memo[n]
end function
```

**时间复杂度**：O(n)
**空间复杂度**：O(n)

#### 方法三：自底向上 DP

```pseudo
function Fib_DP(n)
    if n <= 1 then
        return n
    end if
    
    dp[0] = 0
    dp[1] = 1
    
    for i = 2 to n do
        dp[i] = dp[i-1] + dp[i-2]
    end for
    
    return dp[n]
end function
```

**时间复杂度**：O(n)
**空间复杂度**：O(n)

#### 方法四：空间优化

```pseudo
function Fib_Optimized(n)
    if n <= 1 then
        return n
    end if
    
    prev2 = 0  // F(i-2)
    prev1 = 1  // F(i-1)
    
    for i = 2 to n do
        curr = prev1 + prev2
        prev2 = prev1
        prev1 = curr
    end for
    
    return prev1
end function
```

**时间复杂度**：O(n)
**空间复杂度**：O(1)

---

### 3.2 最长公共子序列（LCS）⭐⭐⭐必考

#### 问题描述
给定两个序列 X = (x₁, x₂, ..., xₘ) 和 Y = (y₁, y₂, ..., yₙ)，找出它们的最长公共子序列的长度。

**注意**：子序列不要求连续，但要保持相对顺序。

**例子**：
- X = "ABCBDAB"
- Y = "BDCABA"
- LCS = "BCBA" 或 "BDAB"，长度为 4

#### 动态规划分析

**Step 1：定义状态**
$$dp[i][j] = X[1..i] 和 Y[1..j] 的最长公共子序列长度$$

**Step 2：状态转移方程**

$$dp[i][j] = \begin{cases} dp[i-1][j-1] + 1 & \text{if } X[i] = Y[j] \\ \max(dp[i-1][j], dp[i][j-1]) & \text{if } X[i] \neq Y[j] \end{cases}$$

**直观理解**：
- 如果 X[i] = Y[j]：这两个字符可以作为 LCS 的一部分
- 如果 X[i] ≠ Y[j]：LCS 要么不包含 X[i]，要么不包含 Y[j]

**Step 3：初始条件**
$$dp[0][j] = 0, \quad dp[i][0] = 0$$

**Step 4：计算顺序**
从左到右，从上到下填表

#### 伪代码

```pseudo
function LCS_Length(X, Y, m, n)
    // 初始化
    for i = 0 to m do
        dp[i][0] = 0
    end for
    for j = 0 to n do
        dp[0][j] = 0
    end for
    
    // 填表
    for i = 1 to m do
        for j = 1 to n do
            if X[i] == Y[j] then
                dp[i][j] = dp[i-1][j-1] + 1
            else
                dp[i][j] = max(dp[i-1][j], dp[i][j-1])
            end if
        end for
    end for
    
    return dp[m][n]
end function
```

#### 示例演算

X = "ABCB", Y = "BDCAB"

|   | ∅ | B | D | C | A | B |
|---|---|---|---|---|---|---|
| ∅ | 0 | 0 | 0 | 0 | 0 | 0 |
| A | 0 | 0 | 0 | 0 | **1** | 1 |
| B | 0 | **1** | 1 | 1 | 1 | **2** |
| C | 0 | 1 | 1 | **2** | 2 | 2 |
| B | 0 | 1 | 1 | 2 | 2 | **3** |

**结果**：LCS 长度 = 3

#### 回溯构造 LCS

```pseudo
function Print_LCS(X, Y, dp, i, j)
    if i == 0 or j == 0 then
        return
    end if
    
    if X[i] == Y[j] then
        Print_LCS(X, Y, dp, i-1, j-1)
        print(X[i])
    else if dp[i-1][j] >= dp[i][j-1] then
        Print_LCS(X, Y, dp, i-1, j)
    else
        Print_LCS(X, Y, dp, i, j-1)
    end if
end function
```

#### 复杂度分析
- **时间复杂度**：O(mn)
- **空间复杂度**：O(mn)，可优化到 O(min(m,n))

---

### 3.3 最长递增子序列（LIS）⭐⭐

#### 问题描述
给定序列 A = (a₁, a₂, ..., aₙ)，找出最长的严格递增子序列的长度。

**例子**：A = [10, 9, 2, 5, 3, 7, 101, 18]，LIS = [2, 3, 7, 101] 或 [2, 5, 7, 101]，长度为 4

#### 方法一：O(n²) DP

**状态定义**：dp[i] = 以 A[i] 结尾的最长递增子序列长度

**状态转移**：
$$dp[i] = \max_{j < i, A[j] < A[i]}(dp[j]) + 1$$

```pseudo
function LIS_DP(A, n)
    for i = 1 to n do
        dp[i] = 1  // 至少包含自己
        for j = 1 to i-1 do
            if A[j] < A[i] then
                dp[i] = max(dp[i], dp[j] + 1)
            end if
        end for
    end for
    
    return max(dp[1..n])
end function
```

**时间复杂度**：O(n²)

#### 方法二：O(n log n) 优化

**思想**：维护一个数组 tail，tail[k] 表示长度为 k 的递增子序列的最小末尾元素

```pseudo
function LIS_Binary(A, n)
    tail = []
    for i = 1 to n do
        if tail 为空 or A[i] > tail.last then
            tail.append(A[i])
        else
            // 二分查找第一个 >= A[i] 的位置并替换
            pos = BinarySearch(tail, A[i])
            tail[pos] = A[i]
        end if
    end for
    return length(tail)
end function
```

**时间复杂度**：O(n log n)

---

### 3.4 0-1 背包问题⭐⭐⭐必考

#### 问题描述
有 n 个物品，第 i 个物品重量为 wᵢ，价值为 vᵢ。背包容量为 W。每个物品只能选择**放或不放**，求能装入背包的最大价值。

#### 动态规划分析

**Step 1：定义状态**
$$dp[i][j] = 前 i 个物品，背包容量为 j 时的最大价值$$

**Step 2：状态转移方程**

对于第 i 个物品，有两种选择：
- **不放**：dp[i][j] = dp[i-1][j]
- **放**（前提 j ≥ wᵢ）：dp[i][j] = dp[i-1][j-wᵢ] + vᵢ

$$dp[i][j] = \begin{cases} dp[i-1][j] & \text{if } j < w_i \\ \max(dp[i-1][j], dp[i-1][j-w_i] + v_i) & \text{if } j \geq w_i \end{cases}$$

**Step 3：初始条件**
$$dp[0][j] = 0 \quad (没有物品)$$
$$dp[i][0] = 0 \quad (容量为0)$$

**Step 4：计算顺序**
从上到下，从左到右

#### 伪代码

```pseudo
function Knapsack_01(w, v, n, W)
    // 初始化
    for j = 0 to W do
        dp[0][j] = 0
    end for
    
    // 填表
    for i = 1 to n do
        for j = 0 to W do
            if j < w[i] then
                dp[i][j] = dp[i-1][j]
            else
                dp[i][j] = max(dp[i-1][j], dp[i-1][j-w[i]] + v[i])
            end if
        end for
    end for
    
    return dp[n][W]
end function
```

#### 示例演算

物品：w = [2, 3, 4, 5], v = [3, 4, 5, 6], W = 8

|   | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |
|---|---|---|---|---|---|---|---|---|---|
| 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |
| 1 | 0 | 0 | 3 | 3 | 3 | 3 | 3 | 3 | 3 |
| 2 | 0 | 0 | 3 | 4 | 4 | 7 | 7 | 7 | 7 |
| 3 | 0 | 0 | 3 | 4 | 5 | 7 | 8 | 9 | 9 |
| 4 | 0 | 0 | 3 | 4 | 5 | 7 | 8 | 9 | 10 |

**结果**：最大价值 = 10（选物品 2 和 4，或物品 1、2、3）

#### 空间优化（一维数组）

**关键观察**：dp[i][j] 只依赖于 dp[i-1][...] 这一行

**优化**：使用一维数组，**从右向左**更新

```pseudo
function Knapsack_01_Optimized(w, v, n, W)
    dp[0..W] = 0
    
    for i = 1 to n do
        for j = W downto w[i] do  // 必须从右向左！
            dp[j] = max(dp[j], dp[j-w[i]] + v[i])
        end for
    end for
    
    return dp[W]
end function
```

**为什么从右向左？**
- 从左向右会导致同一物品被多次使用（变成完全背包）
- 从右向左保证使用的是上一行的值

**时间复杂度**：O(nW)
**空间复杂度**：O(W)

---

### 3.5 完全背包问题

#### 问题描述
与 0-1 背包类似，但每种物品可以**无限次**选取。

#### 状态转移方程

$$dp[i][j] = \max(dp[i-1][j], dp[i][j-w_i] + v_i)$$

**注意**：是 dp[**i**][j-wᵢ] 而不是 dp[i-1][j-wᵢ]

#### 一维优化

```pseudo
function Knapsack_Complete(w, v, n, W)
    dp[0..W] = 0
    
    for i = 1 to n do
        for j = w[i] to W do  // 从左向右！
            dp[j] = max(dp[j], dp[j-w[i]] + v[i])
        end for
    end for
    
    return dp[W]
end function
```

**从左向右**：允许同一物品多次选取

---

### 3.6 矩阵链乘法⭐⭐⭐必考

#### 问题描述
给定 n 个矩阵 A₁, A₂, ..., Aₙ，其中 Aᵢ 的维度是 pᵢ₋₁ × pᵢ。求计算乘积 A₁A₂...Aₙ 的最少标量乘法次数。

**矩阵乘法代价**：计算 (p×q) × (q×r) 的矩阵乘法需要 p×q×r 次标量乘法。

**例子**：
- A₁: 10×30, A₂: 30×5, A₃: 5×60
- (A₁A₂)A₃: 10×30×5 + 10×5×60 = 1500 + 3000 = 4500
- A₁(A₂A₃): 30×5×60 + 10×30×60 = 9000 + 18000 = 27000
- 差距巨大！

#### 动态规划分析

**Step 1：定义状态**
$$m[i][j] = 计算 A_i A_{i+1} ... A_j 的最少乘法次数$$

**Step 2：状态转移方程**

在位置 k 处分割：(Aᵢ...Aₖ)(Aₖ₊₁...Aⱼ)

$$m[i][j] = \min_{i \leq k < j}\{m[i][k] + m[k+1][j] + p_{i-1} \times p_k \times p_j\}$$

**Step 3：初始条件**
$$m[i][i] = 0 \quad (单个矩阵无需乘法)$$

**Step 4：计算顺序**
按**链长度**从小到大计算

#### 伪代码

```pseudo
function MatrixChainOrder(p, n)
    // p[0..n] 存储矩阵维度，共 n 个矩阵
    // 矩阵 Aᵢ 的维度是 p[i-1] × p[i]
    
    // 初始化：单个矩阵
    for i = 1 to n do
        m[i][i] = 0
    end for
    
    // 按链长度 L 从 2 到 n 计算
    for L = 2 to n do
        for i = 1 to n - L + 1 do
            j = i + L - 1
            m[i][j] = ∞
            
            // 尝试所有分割点
            for k = i to j - 1 do
                cost = m[i][k] + m[k+1][j] + p[i-1] * p[k] * p[j]
                if cost < m[i][j] then
                    m[i][j] = cost
                    s[i][j] = k  // 记录最优分割点
                end if
            end for
        end for
    end for
    
    return m[1][n]
end function
```

#### 示例演算

矩阵维度：p = [30, 35, 15, 5, 10, 20, 25]
即 6 个矩阵：A₁(30×35), A₂(35×15), A₃(15×5), A₄(5×10), A₅(10×20), A₆(20×25)

**填表过程**（对角线方式）：

| m[i][j] | 1 | 2 | 3 | 4 | 5 | 6 |
|---------|---|---|---|---|---|---|
| 1 | 0 | 15750 | 7875 | 9375 | 11875 | **15125** |
| 2 | - | 0 | 2625 | 4375 | 7125 | 10500 |
| 3 | - | - | 0 | 750 | 2500 | 5375 |
| 4 | - | - | - | 0 | 1000 | 3500 |
| 5 | - | - | - | - | 0 | 5000 |
| 6 | - | - | - | - | - | 0 |

**结果**：最少乘法次数 = 15125

#### 打印最优括号化方案

```pseudo
function PrintOptimalParens(s, i, j)
    if i == j then
        print("A" + i)
    else
        print("(")
        PrintOptimalParens(s, i, s[i][j])
        PrintOptimalParens(s, s[i][j] + 1, j)
        print(")")
    end if
end function
```

#### 复杂度分析
- **时间复杂度**：O(n³)
- **空间复杂度**：O(n²)

---

### 3.7 最优二叉搜索树⭐⭐

#### 问题描述
给定 n 个键 k₁ < k₂ < ... < kₙ，每个键的搜索概率为 pᵢ。构造一棵二叉搜索树，使得搜索的期望代价最小。

**搜索代价**：depth(kᵢ) + 1（根节点深度为 0）

**期望代价**：
$$E[搜索代价] = \sum_{i=1}^{n} p_i \cdot (depth(k_i) + 1)$$

#### 动态规划分析

**状态定义**：
$$e[i][j] = 包含键 k_i, ..., k_j 的最优 BST 的期望搜索代价$$

**状态转移**：
选择 kᵣ 作为根（i ≤ r ≤ j）：
$$e[i][j] = \min_{i \leq r \leq j}\{e[i][r-1] + e[r+1][j] + w[i][j]\}$$

其中 w[i][j] = pᵢ + pᵢ₊₁ + ... + pⱼ（子树提升一层的代价）

#### 伪代码

```pseudo
function OptimalBST(p, n)
    // 初始化
    for i = 1 to n + 1 do
        e[i][i-1] = 0
        w[i][i-1] = 0
    end for
    
    // 按链长度计算
    for L = 1 to n do
        for i = 1 to n - L + 1 do
            j = i + L - 1
            e[i][j] = ∞
            w[i][j] = w[i][j-1] + p[j]
            
            for r = i to j do
                cost = e[i][r-1] + e[r+1][j] + w[i][j]
                if cost < e[i][j] then
                    e[i][j] = cost
                    root[i][j] = r
                end if
            end for
        end for
    end for
    
    return e[1][n]
end function
```

#### 复杂度
- **时间复杂度**：O(n³)
- **空间复杂度**：O(n²)

---

### 3.8 编辑距离（Edit Distance）⭐⭐

#### 问题描述
给定两个字符串 X 和 Y，计算将 X 转换为 Y 所需的最少操作次数。

**允许的操作**：
1. 插入一个字符
2. 删除一个字符
3. 替换一个字符

**例子**：X = "kitten", Y = "sitting"
- kitten → sitten（替换 k→s）
- sitten → sittin（替换 e→i）
- sittin → sitting（插入 g）
- 编辑距离 = 3

#### 动态规划分析

**状态定义**：
$$dp[i][j] = X[1..i] 转换为 Y[1..j] 的最小编辑距离$$

**状态转移**：
$$dp[i][j] = \begin{cases} dp[i-1][j-1] & \text{if } X[i] = Y[j] \\ 1 + \min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1]) & \text{if } X[i] \neq Y[j] \end{cases}$$

**三种操作对应**：
- dp[i-1][j] + 1：删除 X[i]
- dp[i][j-1] + 1：插入 Y[j]
- dp[i-1][j-1] + 1：替换 X[i] 为 Y[j]

**初始条件**：
$$dp[i][0] = i \quad (删除 i 个字符)$$
$$dp[0][j] = j \quad (插入 j 个字符)$$

#### 伪代码

```pseudo
function EditDistance(X, Y, m, n)
    // 初始化
    for i = 0 to m do
        dp[i][0] = i
    end for
    for j = 0 to n do
        dp[0][j] = j
    end for
    
    // 填表
    for i = 1 to m do
        for j = 1 to n do
            if X[i] == Y[j] then
                dp[i][j] = dp[i-1][j-1]
            else
                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])
            end if
        end for
    end for
    
    return dp[m][n]
end function
```

#### 复杂度
- **时间复杂度**：O(mn)
- **空间复杂度**：O(mn)，可优化到 O(min(m,n))

---

### 3.9 最大子数组和（Kadane算法）

#### 问题描述
给定数组 A[1..n]，找出和最大的连续子数组。

**例子**：A = [-2, 1, -3, 4, -1, 2, 1, -5, 4]
最大子数组：[4, -1, 2, 1]，和 = 6

#### 动态规划分析

**状态定义**：dp[i] = 以 A[i] 结尾的最大子数组和

**状态转移**：
$$dp[i] = \max(dp[i-1] + A[i], A[i])$$

**解释**：要么延续前面的子数组，要么从当前位置重新开始

#### 伪代码

```pseudo
function MaxSubArray(A, n)
    dp[1] = A[1]
    max_sum = A[1]
    
    for i = 2 to n do
        dp[i] = max(dp[i-1] + A[i], A[i])
        max_sum = max(max_sum, dp[i])
    end for
    
    return max_sum
end function
```

#### 空间优化（Kadane算法）

```pseudo
function Kadane(A, n)
    current_sum = A[1]
    max_sum = A[1]
    
    for i = 2 to n do
        current_sum = max(current_sum + A[i], A[i])
        max_sum = max(max_sum, current_sum)
    end for
    
    return max_sum
end function
```

**时间复杂度**：O(n)
**空间复杂度**：O(1)

---

## 四、动态规划问题分类

### 4.1 按状态维度分类

| 类型 | 状态 | 典型问题 |
|------|------|----------|
| 一维 DP | dp[i] | 斐波那契、LIS、最大子数组 |
| 二维 DP | dp[i][j] | LCS、编辑距离、0-1背包 |
| 区间 DP | dp[i][j] 表示区间 | 矩阵链乘法、最优BST |
| 树形 DP | dp[node] | 树的最大独立集 |
| 状态压缩 DP | dp[mask] | 旅行商问题、集合覆盖 |

### 4.2 按问题类型分类

| 类型 | 特点 | 典型问题 |
|------|------|----------|
| 线性 DP | 状态沿一个维度递推 | LIS、最大子数组 |
| 背包 DP | 选择物品，满足约束 | 0-1背包、完全背包 |
| 区间 DP | 在区间上做决策 | 矩阵链乘法、石子合并 |
| 序列 DP | 两个序列的匹配 | LCS、编辑距离 |

---

## 五、动态规划优化技巧

### 5.1 空间优化

| 原始 | 优化后 | 方法 |
|------|--------|------|
| O(n²) | O(n) | 滚动数组（只保留两行） |
| O(n) | O(1) | 只保留必要的几个变量 |

### 5.2 时间优化

| 技巧 | 适用场景 | 优化效果 |
|------|----------|----------|
| 单调队列 | 滑动窗口最值 | O(n²) → O(n) |
| 单调栈 | 最近更大/更小元素 | O(n²) → O(n) |
| 二分查找 | LIS 等 | O(n²) → O(n log n) |
| 斜率优化 | 特定形式的转移 | O(n²) → O(n) |
| 四边形不等式 | 区间 DP | O(n³) → O(n²) |

---

## 六、期末考试重点

### 6.1 必考问题

1. **LCS**：状态转移方程、填表过程、回溯构造
2. **0-1 背包**：二维和一维解法、为什么逆序遍历
3. **矩阵链乘法**：区间 DP 的典型、按链长度计算

### 6.2 常见题型

| 题型 | 内容 |
|------|------|
| 填空/选择 | 给定状态转移方程，求 dp 表某个值 |
| 算法设计 | 定义状态、写状态转移方程 |
| 代码填空 | 补全 DP 算法的关键部分 |
| 综合题 | 分析问题 + 设计 DP + 复杂度分析 |

### 6.3 解题技巧

1. **明确状态定义**：dp[i] 或 dp[i][j] 到底代表什么
2. **画表格**：手动模拟填表过程，验证转移方程
3. **检查边界**：初始条件是否正确
4. **检查顺序**：计算 dp[i] 时依赖的状态是否已计算

### 6.4 易错点

1. **下标从 0 还是 1 开始**：保持一致
2. **初始化遗漏**：边界条件要完整
3. **转移方程方向**：0-1 背包逆序，完全背包正序
4. **最优解回溯**：需要额外记录决策

---

## 七、本讲核心公式速查

### 经典 DP 状态转移方程

| 问题 | 状态转移方程 |
|------|--------------|
| 斐波那契 | dp[i] = dp[i-1] + dp[i-2] |
| LCS | dp[i][j] = dp[i-1][j-1]+1 (相等) 或 max(dp[i-1][j], dp[i][j-1]) |
| LIS | dp[i] = max(dp[j]) + 1，其中 j < i 且 A[j] < A[i] |
| 0-1背包 | dp[i][j] = max(dp[i-1][j], dp[i-1][j-w]+v) |
| 完全背包 | dp[i][j] = max(dp[i-1][j], dp[i][j-w]+v) |
| 编辑距离 | dp[i][j] = dp[i-1][j-1] (相等) 或 1+min(三个方向) |
| 矩阵链乘 | m[i][j] = min{m[i][k] + m[k+1][j] + p_{i-1}p_k p_j} |
| 最大子数组 | dp[i] = max(dp[i-1] + A[i], A[i]) |

### 复杂度汇总

| 问题 | 时间复杂度 | 空间复杂度 |
|------|------------|------------|
| 斐波那契 | O(n) | O(1) |
| LCS | O(mn) | O(mn) / O(n) |
| LIS | O(n²) / O(n log n) | O(n) |
| 0-1背包 | O(nW) | O(nW) / O(W) |
| 矩阵链乘法 | O(n³) | O(n²) |
| 编辑距离 | O(mn) | O(mn) / O(n) |

---

---

# 第五讲：贪心算法（Greedy Algorithm）

## 一、贪心算法概述

### 1.1 什么是贪心算法？

**贪心算法**是一种在每一步选择中都采取**当前状态下最优**的选择，从而希望导致结果是**全局最优**的算法策略。

> **核心思想**：不从整体最优考虑，而是做出**局部最优**的选择，期望通过一系列局部最优选择达到全局最优。

### 1.2 贪心算法的特点

| 特点 | 说明 |
|------|------|
| **局部最优** | 每一步都选择当前看起来最好的选项 |
| **不可回退** | 一旦做出选择，不会撤销或修改 |
| **高效性** | 通常时间复杂度较低 |
| **不保证全局最优** | 只有满足贪心选择性质时才能得到最优解 |

### 1.3 贪心算法的两个关键性质

#### 性质1：贪心选择性质（Greedy Choice Property）

> 通过做出**局部最优选择**，可以得到**全局最优解**。

即：存在一个最优解，它的第一步选择就是贪心选择。

#### 性质2：最优子结构（Optimal Substructure）

> 问题的最优解包含其子问题的最优解。

即：做出贪心选择后，剩余子问题的最优解与原问题的最优解一致。

### 1.4 贪心算法 vs 动态规划

| 对比项 | 贪心算法 | 动态规划 |
|--------|----------|----------|
| 选择方式 | 每步做局部最优选择 | 考虑所有可能的选择 |
| 子问题 | 只产生一个子问题 | 可能产生多个子问题 |
| 回溯 | 不回溯 | 可能需要回溯比较 |
| 效率 | 通常更高效 | 相对较慢 |
| 正确性 | 需要证明贪心选择性质 | 只需证明最优子结构 |
| 适用范围 | 较窄（需满足贪心性质） | 较广 |

---

## 二、贪心算法设计步骤

```
┌─────────────────────────────────────────────────────────────┐
│                    贪心算法设计步骤                          │
├─────────────────────────────────────────────────────────────┤
│  Step 1：分析问题，确定贪心策略                              │
│          找出局部最优的选择标准                              │
├─────────────────────────────────────────────────────────────┤
│  Step 2：证明贪心选择性质                                    │
│          证明局部最优能导致全局最优                          │
├─────────────────────────────────────────────────────────────┤
│  Step 3：证明最优子结构                                      │
│          证明子问题的最优解是原问题最优解的一部分            │
├─────────────────────────────────────────────────────────────┤
│  Step 4：设计算法                                            │
│          按贪心策略迭代求解                                  │
└─────────────────────────────────────────────────────────────┘
```

---

## 三、经典贪心算法详解

### 3.1 活动选择问题（Activity Selection）⭐⭐⭐必考

#### 问题描述
有 n 个活动，每个活动 i 有开始时间 sᵢ 和结束时间 fᵢ。同一时间只能进行一个活动。求最多能选择多少个**互不冲突**的活动。

**例子**：

| 活动 | 1 | 2 | 3 | 4 | 5 | 6 |
|------|---|---|---|---|---|---|
| 开始 | 1 | 3 | 0 | 5 | 3 | 5 |
| 结束 | 4 | 5 | 6 | 7 | 9 | 9 |

#### 贪心策略

**策略**：每次选择**结束时间最早**的活动

**为什么？** 结束越早，给后续活动留的时间越多

#### 贪心选择性质证明

**定理**：设 A 是活动集合 S 的一个最优解，a₁ 是 S 中结束时间最早的活动。则存在最优解 A' 包含 a₁。

**证明**：
1. 如果 A 包含 a₁，则 A' = A，证毕
2. 如果 A 不包含 a₁，设 A 中第一个活动是 aₖ
3. 因为 a₁ 结束最早，所以 f₁ ≤ fₖ
4. 用 a₁ 替换 aₖ 得到 A' = (A - {aₖ}) ∪ {a₁}
5. A' 仍然是可行解（活动不冲突），且 |A'| = |A|
6. 所以 A' 也是最优解，且包含 a₁ ∎

#### 伪代码

```pseudo
function ActivitySelection(s, f, n)
    // 假设活动已按结束时间排序：f[1] ≤ f[2] ≤ ... ≤ f[n]
    
    selected = [1]        // 选择第一个活动
    last_finish = f[1]    // 上一个选中活动的结束时间
    
    for i = 2 to n do
        if s[i] >= last_finish then  // 活动 i 与已选活动不冲突
            selected.append(i)
            last_finish = f[i]
        end if
    end for
    
    return selected
end function
```

#### 示例演算

活动按结束时间排序后：

| 活动 | 1 | 2 | 3 | 4 | 5 | 6 |
|------|---|---|---|---|---|---|
| 开始 | 1 | 3 | 0 | 5 | 3 | 5 |
| 结束 | 4 | 5 | 6 | 7 | 9 | 9 |

```
选择活动 1：结束时间 4
活动 2：开始 3 < 4，冲突，跳过
活动 3：开始 0 < 4，冲突，跳过
活动 4：开始 5 ≥ 4，选择！结束时间 7
活动 5：开始 3 < 7，冲突，跳过
活动 6：开始 5 < 7，冲突，跳过

结果：选择活动 {1, 4}，共 2 个
```

等等，让我重新按结束时间排序：

| 活动 | a | b | c | d | e | f |
|------|---|---|---|---|---|---|
| 开始 | 1 | 3 | 0 | 5 | 3 | 5 |
| 结束 | 4 | 5 | 6 | 7 | 9 | 9 |

```
选择 a (1,4)
b: 3 < 4，跳过
c: 0 < 4，跳过
选择 d (5,7)：5 ≥ 4
e: 3 < 7，跳过
f: 5 < 7，跳过

最终：{a, d}，共 2 个活动
```

#### 复杂度分析
- **排序**：O(n log n)
- **选择**：O(n)
- **总时间复杂度**：O(n log n)
- **空间复杂度**：O(1)（不计输出）

---

### 3.2 分数背包问题（Fractional Knapsack）⭐⭐

#### 问题描述
有 n 个物品，第 i 个物品重量 wᵢ，价值 vᵢ。背包容量为 W。物品可以**分割**（取一部分）。求能装入背包的最大价值。

**与 0-1 背包的区别**：物品可以分割！

#### 贪心策略

**策略**：按**单位重量价值**（vᵢ/wᵢ）从高到低选择

**为什么？** 单位价值越高，同样重量能获得更多价值

#### 贪心选择性质证明

**定理**：设物品按单位价值降序排列。存在最优解，其中单位价值最高的物品被尽可能多地选取。

**证明**（交换论证）：
1. 设最优解中单位价值最高的物品 1 只取了 x₁ < min(w₁, W)
2. 必然存在某个物品 k（单位价值更低）被取了 xₖ > 0
3. 将物品 k 换成等量的物品 1，总价值会增加
4. 这与最优解矛盾，所以物品 1 必须尽可能多取 ∎

#### 伪代码

```pseudo
function FractionalKnapsack(w, v, n, W)
    // 计算单位价值并排序
    for i = 1 to n do
        ratio[i] = v[i] / w[i]
    end for
    按 ratio 降序排列物品
    
    total_value = 0
    remaining = W
    
    for i = 1 to n do
        if w[i] <= remaining then
            // 整个物品都能装下
            total_value = total_value + v[i]
            remaining = remaining - w[i]
        else
            // 只能装一部分
            total_value = total_value + ratio[i] * remaining
            remaining = 0
            break
        end if
    end for
    
    return total_value
end function
```

#### 示例演算

物品：w = [10, 20, 30], v = [60, 100, 120], W = 50

单位价值：[6, 5, 4]

排序后：物品 1 (6) > 物品 2 (5) > 物品 3 (4)

```
选择物品 1：全部装入，价值 60，剩余容量 40
选择物品 2：全部装入，价值 100，剩余容量 20
选择物品 3：装入 20/30，价值 120 × (20/30) = 80

总价值：60 + 100 + 80 = 240
```

#### 复杂度分析
- **时间复杂度**：O(n log n)（排序）
- **空间复杂度**：O(n)

#### 分数背包 vs 0-1 背包

| 对比项 | 分数背包 | 0-1 背包 |
|--------|----------|----------|
| 物品分割 | 可以 | 不可以 |
| 算法 | 贪心 | 动态规划 |
| 时间复杂度 | O(n log n) | O(nW) |
| 贪心策略 | 有效 | 无效（反例见下） |

**0-1 背包贪心失效的反例**：
- 物品：w = [10, 20], v = [60, 100], W = 20
- 按单位价值贪心选物品 1：价值 60
- 最优解选物品 2：价值 100

---

### 3.3 哈夫曼编码（Huffman Coding）⭐⭐⭐必考

#### 问题描述
给定 n 个字符及其出现频率，构造一种**前缀编码**，使得编码后的总长度最小。

**前缀编码**：任何字符的编码都不是另一个字符编码的前缀。

**例子**：
| 字符 | a | b | c | d | e | f |
|------|---|---|---|---|---|---|
| 频率 | 45 | 13 | 12 | 16 | 9 | 5 |

#### 贪心策略

**策略**：每次选择**频率最低**的两个节点合并

**为什么？** 频率低的字符应该有更长的编码（放在树的更深处）

#### 哈夫曼算法步骤

```
1. 将每个字符作为一个叶子节点，权值为其频率
2. 从所有节点中选出权值最小的两个节点
3. 创建一个新节点作为它们的父节点，权值为两者之和
4. 将新节点加入节点集合，移除原来的两个节点
5. 重复 2-4，直到只剩一个节点（根节点）
```

#### 伪代码

```pseudo
function Huffman(C, freq, n)
    // C: 字符集，freq: 频率数组
    
    // 创建最小堆，每个元素是 (频率, 节点)
    Q = MinHeap()
    for i = 1 to n do
        node = CreateLeaf(C[i], freq[i])
        Q.insert(node)
    end for
    
    // 合并节点
    for i = 1 to n - 1 do
        left = Q.extractMin()
        right = Q.extractMin()
        
        // 创建新的内部节点
        parent = CreateNode()
        parent.left = left
        parent.right = right
        parent.freq = left.freq + right.freq
        
        Q.insert(parent)
    end for
    
    return Q.extractMin()  // 返回根节点
end function
```

#### 示例演算

字符频率：a:45, b:13, c:12, d:16, e:9, f:5

**构建过程**：

```
初始：[5:f, 9:e, 12:c, 13:b, 16:d, 45:a]

Step 1：合并 f(5) 和 e(9) → 14
        [12:c, 13:b, 14:(f,e), 16:d, 45:a]

Step 2：合并 c(12) 和 b(13) → 25
        [14:(f,e), 16:d, 25:(c,b), 45:a]

Step 3：合并 14 和 d(16) → 30
        [25:(c,b), 30:((f,e),d), 45:a]

Step 4：合并 25 和 30 → 55
        [45:a, 55:((c,b),((f,e),d))]

Step 5：合并 45 和 55 → 100（根节点）
```

**最终哈夫曼树**：

```
           100
          /    \
        a:45   55
              /    \
            25      30
           /  \    /  \
         c:12 b:13 14  d:16
                  /  \
                f:5  e:9
```

**编码结果**：

| 字符 | 编码 | 长度 |
|------|------|------|
| a | 0 | 1 |
| c | 100 | 3 |
| b | 101 | 3 |
| f | 1100 | 4 |
| e | 1101 | 4 |
| d | 111 | 3 |

**总编码长度**：45×1 + 12×3 + 13×3 + 5×4 + 9×4 + 16×3 = 45 + 36 + 39 + 20 + 36 + 48 = 224

#### 贪心选择性质证明

**定理**：设 x 和 y 是频率最低的两个字符，则存在最优前缀编码，其中 x 和 y 的编码长度相同且仅最后一位不同（即它们是兄弟节点）。

**证明思路**：
1. 在任何最优树中，最深的两个叶子必是兄弟
2. 将 x, y 与最深的两个叶子交换，总代价不会增加
3. 因此存在最优解，x 和 y 是最深的兄弟节点 ∎

#### 复杂度分析
- **时间复杂度**：O(n log n)（使用最小堆）
- **空间复杂度**：O(n)

---

### 3.4 最小生成树 - Prim 算法⭐⭐

#### 问题描述
给定连通无向图 G = (V, E)，每条边有权重。找一棵包含所有顶点的树，使得边权之和最小。

#### Prim 算法思想

**策略**：从一个顶点开始，每次选择**连接已选顶点和未选顶点的最小权边**

#### 伪代码

```pseudo
function Prim(G, w, r)
    // G: 图，w: 权重，r: 起始顶点
    
    for each u in V do
        key[u] = ∞
        parent[u] = NIL
        inMST[u] = false
    end for
    
    key[r] = 0
    Q = MinHeap(V, key)  // 按 key 值的最小堆
    
    while Q is not empty do
        u = Q.extractMin()
        inMST[u] = true
        
        for each v adjacent to u do
            if not inMST[v] and w(u,v) < key[v] then
                parent[v] = u
                key[v] = w(u,v)
                Q.decreaseKey(v, key[v])
            end if
        end for
    end while
    
    return parent  // MST 由 parent 数组表示
end function
```

#### 复杂度分析
- 使用二叉堆：O(E log V)
- 使用斐波那契堆：O(E + V log V)

---

### 3.5 最小生成树 - Kruskal 算法⭐⭐

#### 算法思想

**策略**：将所有边按权重排序，每次选择**不会形成环的最小权边**

#### 伪代码

```pseudo
function Kruskal(G, w)
    MST = []
    
    // 初始化并查集：每个顶点是一个集合
    for each v in V do
        MakeSet(v)
    end for
    
    // 按权重排序所有边
    edges = Sort(E, by weight)
    
    for each (u, v) in edges do
        if Find(u) != Find(v) then  // u 和 v 不在同一集合（不会成环）
            MST.append((u, v))
            Union(u, v)
        end if
    end for
    
    return MST
end function
```

#### 并查集操作

```pseudo
function MakeSet(x)
    parent[x] = x
    rank[x] = 0
end function

function Find(x)  // 路径压缩
    if parent[x] != x then
        parent[x] = Find(parent[x])
    end if
    return parent[x]
end function

function Union(x, y)  // 按秩合并
    px = Find(x)
    py = Find(y)
    
    if rank[px] < rank[py] then
        parent[px] = py
    else if rank[px] > rank[py] then
        parent[py] = px
    else
        parent[py] = px
        rank[px] = rank[px] + 1
    end if
end function
```

#### 复杂度分析
- **排序**：O(E log E) = O(E log V)
- **并查集操作**：O(E α(V))，其中 α 是反阿克曼函数，几乎是常数
- **总时间复杂度**：O(E log E)

#### Prim vs Kruskal

| 对比项 | Prim | Kruskal |
|--------|------|---------|
| 思想 | 从顶点扩展 | 从边选择 |
| 数据结构 | 最小堆 | 并查集 |
| 适用场景 | 稠密图 | 稀疏图 |
| 时间复杂度 | O(E log V) | O(E log E) |

---

### 3.6 单源最短路径 - Dijkstra 算法⭐⭐⭐必考

#### 问题描述
给定带权有向图 G = (V, E)，边权**非负**，求从源点 s 到所有其他顶点的最短路径。

#### 贪心策略

**策略**：每次选择**距离源点最近的未访问顶点**，更新其邻居的距离

#### 伪代码

```pseudo
function Dijkstra(G, w, s)
    // 初始化
    for each v in V do
        dist[v] = ∞
        parent[v] = NIL
        visited[v] = false
    end for
    
    dist[s] = 0
    Q = MinHeap(V, dist)
    
    while Q is not empty do
        u = Q.extractMin()
        visited[u] = true
        
        for each v adjacent to u do
            if not visited[v] and dist[u] + w(u,v) < dist[v] then
                dist[v] = dist[u] + w(u,v)
                parent[v] = u
                Q.decreaseKey(v, dist[v])
            end if
        end for
    end while
    
    return dist, parent
end function
```

#### 示例演算

```
图：
    A --1-- B
    |       |
    4       2
    |       |
    C --3-- D

从 A 出发：

初始：dist = [A:0, B:∞, C:∞, D:∞]

Step 1：选 A，更新邻居
        dist = [A:0, B:1, C:4, D:∞]

Step 2：选 B（最小），更新邻居
        dist = [A:0, B:1, C:4, D:3]

Step 3：选 D，更新邻居
        C: min(4, 3+3) = 4，不更新

Step 4：选 C，无更新

最短距离：A→A:0, A→B:1, A→C:4, A→D:3
```

#### 复杂度分析
- 使用二叉堆：O((V + E) log V)
- 使用斐波那契堆：O(E + V log V)
- 使用数组（朴素）：O(V²)

#### 为什么边权必须非负？

**反例**：
```
A --1-- B
 \     /
  2   -2
   \ /
    C
```
- Dijkstra 会先确定 dist[B] = 1
- 但实际 A→C→B = 2 + (-2) = 0 < 1
- 负权边会导致已确定的最短距离被更新

---

### 3.7 区间调度问题变体

#### 3.7.1 区间覆盖问题

**问题**：给定区间 [L, R] 和若干小区间，选择最少的小区间覆盖 [L, R]。

**贪心策略**：每次选择**左端点 ≤ 当前位置**且**右端点最远**的区间

#### 3.7.2 区间不相交问题（等同于活动选择）

**贪心策略**：按结束时间排序，选择不冲突的

#### 3.7.3 区间分组问题

**问题**：将区间分成最少的组，使得每组内区间不重叠。

**贪心策略**：按开始时间排序，每个区间分配到能容纳它的编号最小的组

---

### 3.8 任务调度问题

#### 问题描述
有 n 个任务，每个任务有截止时间 dᵢ 和惩罚 wᵢ。每个任务需要单位时间完成。求最小化总惩罚的调度。

#### 贪心策略

**策略**：按惩罚从大到小排序，尽量在截止时间前完成高惩罚任务

```pseudo
function TaskScheduling(d, w, n)
    // 按惩罚降序排序
    tasks = Sort by w descending
    
    schedule = array of size max(d)
    
    for each task in tasks do
        // 尝试在截止时间或之前找空闲时间槽
        for t = d[task] downto 1 do
            if schedule[t] is empty then
                schedule[t] = task
                break
            end if
        end for
        // 如果找不到，任务被放弃，计入惩罚
    end for
    
    return schedule
end function
```

---

## 四、贪心算法的正确性证明方法

### 4.1 交换论证（Exchange Argument）

**思路**：证明可以将任意最优解逐步转换为贪心解，且不会变差。

**步骤**：
1. 假设存在最优解 OPT 与贪心解 GREEDY 不同
2. 找到第一个不同的选择
3. 证明可以用贪心的选择替换 OPT 中的选择
4. 证明替换后解不会变差

### 4.2 归纳法

**思路**：证明每一步贪心选择后，剩余问题的最优解加上当前选择就是原问题的最优解。

### 4.3 反证法

**思路**：假设贪心解不是最优的，推导出矛盾。

---

## 五、贪心算法失效的情况

### 5.1 0-1 背包问题

**贪心失效**：按单位价值选择不一定最优

**反例**：w = [10, 20], v = [60, 100], W = 20
- 贪心（单位价值）：选物品 1，价值 60
- 最优：选物品 2，价值 100

### 5.2 硬币找零（某些面值组合）

**面值 [1, 3, 4]，找零 6**：
- 贪心：4 + 1 + 1 = 3 枚硬币
- 最优：3 + 3 = 2 枚硬币

### 5.3 旅行商问题（TSP）

每次选择最近的城市不能保证总路程最短。

---

## 六、贪心算法总结

### 6.1 经典贪心问题汇总

| 问题 | 贪心策略 | 时间复杂度 |
|------|----------|------------|
| 活动选择 | 结束时间最早 | O(n log n) |
| 分数背包 | 单位价值最高 | O(n log n) |
| 哈夫曼编码 | 频率最低的合并 | O(n log n) |
| Prim MST | 最小权边扩展 | O(E log V) |
| Kruskal MST | 最小权边不成环 | O(E log E) |
| Dijkstra | 最近未访问顶点 | O((V+E) log V) |

### 6.2 贪心策略选择指南

| 问题特征 | 常用贪心策略 |
|----------|--------------|
| 区间问题 | 按结束时间/开始时间排序 |
| 背包问题（可分割） | 按单位价值排序 |
| 编码问题 | 频率低的深度大 |
| 图问题 | 选择最小/最大权边 |

---

## 七、期末考试重点

### 7.1 必考内容

1. **活动选择问题**：贪心策略、正确性证明
2. **哈夫曼编码**：构建过程、编码结果
3. **Dijkstra 算法**：执行过程、为什么不能有负权边

### 7.2 常见题型

| 题型 | 内容 |
|------|------|
| 算法设计 | 给定问题，设计贪心策略 |
| 正确性证明 | 证明贪心选择性质 |
| 模拟执行 | 手动执行贪心算法过程 |
| 判断题 | 判断某贪心策略是否正确 |

### 7.3 易错点

1. **贪心不一定最优**：需要证明贪心选择性质
2. **排序标准**：活动选择按结束时间，不是开始时间
3. **Dijkstra 限制**：只适用于非负权边
4. **0-1 背包**：贪心无效，必须用 DP

---

## 八、本讲核心公式速查

### 算法复杂度

| 算法 | 时间复杂度 | 空间复杂度 |
|------|------------|------------|
| 活动选择 | O(n log n) | O(1) |
| 分数背包 | O(n log n) | O(n) |
| 哈夫曼编码 | O(n log n) | O(n) |
| Prim | O(E log V) | O(V) |
| Kruskal | O(E log E) | O(V) |
| Dijkstra | O((V+E) log V) | O(V) |

### 贪心 vs DP 适用性

| 问题 | 贪心 | DP |
|------|------|-----|
| 活动选择 | ✅ | ✅ |
| 分数背包 | ✅ | ✅ |
| 0-1 背包 | ❌ | ✅ |
| 最短路径（非负权） | ✅ | ✅ |
| 最短路径（有负权） | ❌ | ✅ |

---

---

# 第六讲：图的遍历（Graph Traversal）

## 一、图的基本概念

### 1.1 图的定义

**图** G = (V, E)，其中：
- **V**：顶点（Vertex）集合
- **E**：边（Edge）集合，E ⊆ V × V

### 1.2 图的分类

| 类型 | 说明 |
|------|------|
| **有向图** | 边有方向，(u, v) ≠ (v, u) |
| **无向图** | 边无方向，(u, v) = (v, u) |
| **加权图** | 边有权重 |
| **连通图** | 任意两点间有路径（无向图） |
| **强连通图** | 任意两点间有双向路径（有向图） |
| **稀疏图** | E ≈ O(V) |
| **稠密图** | E ≈ O(V²) |

### 1.3 图的存储方式

#### 邻接矩阵（Adjacency Matrix）

```
    A  B  C  D
A [ 0  1  1  0 ]
B [ 1  0  1  1 ]
C [ 1  1  0  1 ]
D [ 0  1  1  0 ]
```

| 特点 | 说明 |
|------|------|
| 空间 | O(V²) |
| 查询边 (u,v) | O(1) |
| 遍历邻居 | O(V) |
| 适用场景 | 稠密图 |

#### 邻接表（Adjacency List）

```
A → [B, C]
B → [A, C, D]
C → [A, B, D]
D → [B, C]
```

| 特点 | 说明 |
|------|------|
| 空间 | O(V + E) |
| 查询边 (u,v) | O(degree(u)) |
| 遍历邻居 | O(degree(u)) |
| 适用场景 | 稀疏图 |

---

## 二、深度优先搜索（DFS）⭐⭐⭐必考

### 2.1 DFS 基本思想

**策略**：从起点出发，沿着一条路径尽可能深入，直到无法继续，然后**回溯**到上一个节点，尝试其他路径。

**类比**：走迷宫时，一直走到死胡同再回头

### 2.2 DFS 伪代码

#### 递归版本

```pseudo
function DFS(G)
    for each vertex u in V do
        color[u] = WHITE    // 未访问
        parent[u] = NIL
    end for
    time = 0
    
    for each vertex u in V do
        if color[u] == WHITE then
            DFS_Visit(G, u)
        end if
    end for
end function

function DFS_Visit(G, u)
    time = time + 1
    discover[u] = time      // 发现时间
    color[u] = GRAY         // 正在访问
    
    for each v adjacent to u do
        if color[v] == WHITE then
            parent[v] = u
            DFS_Visit(G, v)
        end if
    end for
    
    color[u] = BLACK        // 访问完成
    time = time + 1
    finish[u] = time        // 完成时间
end function
```

#### 迭代版本（使用栈）

```pseudo
function DFS_Iterative(G, s)
    for each vertex u in V do
        visited[u] = false
    end for
    
    Stack S
    S.push(s)
    
    while S is not empty do
        u = S.pop()
        if not visited[u] then
            visited[u] = true
            process(u)
            
            for each v adjacent to u do
                if not visited[v] then
                    S.push(v)
                end if
            end for
        end if
    end while
end function
```

### 2.3 DFS 示例

```
图：
    A --- B
    |     |
    C --- D --- E

从 A 开始 DFS（假设邻接表顺序：A→[B,C], B→[A,D], C→[A,D], D→[B,C,E], E→[D]）

访问顺序：A → B → D → C → E（回溯过程省略）

时间戳：
顶点    发现时间    完成时间
A         1           10
B         2            9
D         3            8
C         4            5
E         6            7
```

### 2.4 DFS 的时间戳性质

#### 括号定理（Parenthesis Theorem）

对于任意两个顶点 u 和 v，以下三种情况**恰好有一个**成立：
1. [discover[u], finish[u]] 和 [discover[v], finish[v]] **完全分离**
2. [discover[u], finish[u]] **完全包含** [discover[v], finish[v]]（u 是 v 的祖先）
3. [discover[v], finish[v]] **完全包含** [discover[u], finish[u]]（v 是 u 的祖先）

**图示**：
```
u: [  [v:  ]  ]     v 是 u 的后代
u: [    ]  v:[  ]   u 和 v 分离
```

#### 白色路径定理

在 DFS 森林中，v 是 u 的后代 **当且仅当** 在发现 u 时，存在一条从 u 到 v 的全白色路径。

### 2.5 DFS 边的分类⭐⭐

| 边类型 | 定义 | 判断条件 |
|--------|------|----------|
| **树边（Tree Edge）** | DFS 树中的边 | parent[v] = u |
| **后向边（Back Edge）** | 指向祖先的边 | v 是灰色（正在访问） |
| **前向边（Forward Edge）** | 指向后代的非树边 | v 是黑色且 discover[u] < discover[v] |
| **交叉边（Cross Edge）** | 其他边 | v 是黑色且 discover[u] > discover[v] |

**重要结论**：
- **无向图**只有树边和后向边
- **有向图**四种边都可能有
- **图有环 ⟺ DFS 存在后向边**

### 2.6 DFS 复杂度

- **时间复杂度**：O(V + E)
- **空间复杂度**：O(V)（递归栈或显式栈）

---

## 三、广度优先搜索（BFS）⭐⭐⭐必考

### 3.1 BFS 基本思想

**策略**：从起点出发，先访问所有距离为 1 的顶点，再访问距离为 2 的顶点，依此类推。

**类比**：水波扩散，一层一层向外

### 3.2 BFS 伪代码

```pseudo
function BFS(G, s)
    for each vertex u in V - {s} do
        color[u] = WHITE
        dist[u] = ∞
        parent[u] = NIL
    end for
    
    color[s] = GRAY
    dist[s] = 0
    parent[s] = NIL
    
    Queue Q
    Q.enqueue(s)
    
    while Q is not empty do
        u = Q.dequeue()
        
        for each v adjacent to u do
            if color[v] == WHITE then
                color[v] = GRAY
                dist[v] = dist[u] + 1
                parent[v] = u
                Q.enqueue(v)
            end if
        end for
        
        color[u] = BLACK
    end while
end function
```

### 3.3 BFS 示例

```
图：
    A --- B
    |     |
    C --- D --- E

从 A 开始 BFS：

层次 0：A
层次 1：B, C（A 的邻居）
层次 2：D（B 和 C 的邻居，去重）
层次 3：E（D 的邻居）

访问顺序：A → B → C → D → E

距离：
A: 0, B: 1, C: 1, D: 2, E: 3
```

### 3.4 BFS 的性质

#### 最短路径性质（无权图）

**定理**：BFS 计算的 dist[v] 是从源点 s 到 v 的**最短距离**（边数）。

**证明思路**：
1. BFS 按层次访问，第 k 层的顶点距离 s 恰好是 k
2. 每个顶点只入队一次，第一次入队时的距离就是最短距离

#### 最短路径树

BFS 构建的 parent 数组形成一棵以 s 为根的树，树中从 s 到任意顶点 v 的路径就是最短路径。

### 3.5 BFS 复杂度

- **时间复杂度**：O(V + E)
- **空间复杂度**：O(V)

---

## 四、DFS vs BFS 对比⭐

| 对比项 | DFS | BFS |
|--------|-----|-----|
| 数据结构 | 栈（递归/显式） | 队列 |
| 搜索方式 | 深入优先 | 层次优先 |
| 空间复杂度 | O(V)（最坏 O(V)） | O(V)（最坏 O(V)） |
| 时间复杂度 | O(V + E) | O(V + E) |
| 最短路径 | ❌ 不保证 | ✅ 无权图最短路径 |
| 完备性 | ✅ 能找到解（如果存在） | ✅ 能找到解 |
| 应用 | 拓扑排序、强连通分量、环检测 | 最短路径、层次遍历 |

### 搜索树形态对比

```
      A                    A
     /|\                  /|\
    B C D      DFS       B C D      BFS
    |                   /|   |\
    E                  E F   G H
    |
    F
   深度优先               广度优先
```

---

## 五、DFS 的应用

### 5.1 拓扑排序（Topological Sort）⭐⭐⭐必考

#### 问题描述

给定**有向无环图（DAG）**，将所有顶点排成线性序列，使得对于每条边 (u, v)，u 在序列中出现在 v 之前。

**应用场景**：任务调度、课程安排、编译依赖

#### 方法一：基于 DFS 的拓扑排序

**思想**：按 DFS 完成时间**逆序**排列

```pseudo
function TopologicalSort_DFS(G)
    调用 DFS(G) 计算所有顶点的完成时间
    按 finish 时间降序排列顶点
    return 排列结果
end function
```

**正确性**：对于边 (u, v)，v 必在 u 之前完成（finish[v] < finish[u]），所以逆序后 u 在 v 之前。

#### 方法二：Kahn 算法（基于入度）

```pseudo
function TopologicalSort_Kahn(G)
    // 计算所有顶点的入度
    for each vertex u in V do
        indegree[u] = 0
    end for
    for each edge (u, v) in E do
        indegree[v] = indegree[v] + 1
    end for
    
    // 将入度为 0 的顶点入队
    Queue Q
    for each vertex u in V do
        if indegree[u] == 0 then
            Q.enqueue(u)
        end if
    end for
    
    result = []
    while Q is not empty do
        u = Q.dequeue()
        result.append(u)
        
        for each v adjacent to u do
            indegree[v] = indegree[v] - 1
            if indegree[v] == 0 then
                Q.enqueue(v)
            end if
        end for
    end while
    
    if |result| != |V| then
        return "图中有环，无法拓扑排序"
    end if
    
    return result
end function
```

#### 示例

```
图：
    A → B → D
    ↓   ↓
    C → E

入度：A:0, B:1, C:1, D:1, E:2

Kahn 算法过程：
1. 入度为 0：A，输出 A
2. 更新：B 入度变 0，C 入度变 0
3. 输出 B（或 C），假设 B
4. 更新：D 入度变 0，E 入度变 1
5. 输出 C
6. 更新：E 入度变 0
7. 输出 D, E

拓扑序列：A → B → C → D → E（不唯一）
```

#### 复杂度
- **时间复杂度**：O(V + E)
- **空间复杂度**：O(V)

---

### 5.2 环检测（Cycle Detection）

#### 无向图环检测

**方法**：DFS 中遇到已访问的非父节点 → 有环

```pseudo
function HasCycle_Undirected(G, u, parent)
    visited[u] = true
    
    for each v adjacent to u do
        if not visited[v] then
            if HasCycle_Undirected(G, v, u) then
                return true
            end if
        else if v != parent then
            return true  // 遇到已访问的非父节点，有环
        end if
    end for
    
    return false
end function
```

#### 有向图环检测

**方法**：DFS 中遇到**灰色节点**（后向边）→ 有环

```pseudo
function HasCycle_Directed(G)
    for each vertex u in V do
        color[u] = WHITE
    end for
    
    for each vertex u in V do
        if color[u] == WHITE then
            if DFS_Cycle(G, u) then
                return true
            end if
        end if
    end for
    
    return false
end function

function DFS_Cycle(G, u)
    color[u] = GRAY
    
    for each v adjacent to u do
        if color[v] == GRAY then
            return true  // 后向边，有环
        end if
        if color[v] == WHITE then
            if DFS_Cycle(G, v) then
                return true
            end if
        end if
    end for
    
    color[u] = BLACK
    return false
end function
```

---

### 5.3 强连通分量（Strongly Connected Components）⭐⭐

#### 定义

**强连通分量（SCC）**：有向图中的最大顶点集合，其中任意两个顶点都**互相可达**。

#### Kosaraju 算法

**步骤**：
1. 对原图 G 进行 DFS，记录完成时间
2. 构建反向图 Gᵀ
3. 按完成时间**降序**对 Gᵀ 进行 DFS
4. 每次 DFS 得到一个 SCC

```pseudo
function Kosaraju(G)
    // Step 1: 对 G 进行 DFS，记录完成顺序
    Stack S
    visited = all false
    for each vertex u in V do
        if not visited[u] then
            DFS1(G, u, S)
        end if
    end for
    
    // Step 2: 构建反向图
    G_T = Transpose(G)
    
    // Step 3: 按完成时间降序对 G_T 进行 DFS
    visited = all false
    SCCs = []
    while S is not empty do
        u = S.pop()
        if not visited[u] then
            SCC = []
            DFS2(G_T, u, SCC)
            SCCs.append(SCC)
        end if
    end while
    
    return SCCs
end function

function DFS1(G, u, S)
    visited[u] = true
    for each v adjacent to u do
        if not visited[v] then
            DFS1(G, v, S)
        end if
    end for
    S.push(u)  // 完成时入栈
end function

function DFS2(G, u, SCC)
    visited[u] = true
    SCC.append(u)
    for each v adjacent to u do
        if not visited[v] then
            DFS2(G, v, SCC)
        end if
    end for
end function
```

#### 示例

```
图：
    A → B → C
    ↑   ↓   ↓
    D ← E → F
    
Step 1: DFS 完成顺序（假设）：F, C, E, B, D, A

Step 2: 反向图 G_T

Step 3: 按 A, D, B, E, C, F 顺序 DFS G_T
        SCC1: {A, B, E, D}
        SCC2: {C}
        SCC3: {F}
```

#### Tarjan 算法（更高效）

使用单次 DFS，维护：
- **dfn[u]**：发现时间
- **low[u]**：u 能到达的最小发现时间

```pseudo
function Tarjan(G)
    index = 0
    Stack S
    for each vertex u in V do
        if dfn[u] is undefined then
            StrongConnect(u)
        end if
    end for
end function

function StrongConnect(u)
    dfn[u] = low[u] = index
    index = index + 1
    S.push(u)
    onStack[u] = true
    
    for each v adjacent to u do
        if dfn[v] is undefined then
            StrongConnect(v)
            low[u] = min(low[u], low[v])
        else if onStack[v] then
            low[u] = min(low[u], dfn[v])
        end if
    end for
    
    // 如果 u 是 SCC 的根
    if low[u] == dfn[u] then
        SCC = []
        repeat
            v = S.pop()
            onStack[v] = false
            SCC.append(v)
        until v == u
        output SCC
    end if
end function
```

#### 复杂度
- **时间复杂度**：O(V + E)
- **空间复杂度**：O(V)

---

### 5.4 割点与桥（Cut Vertices and Bridges）

#### 定义

- **割点（Cut Vertex/Articulation Point）**：删除后图不再连通的顶点
- **桥（Bridge）**：删除后图不再连通的边

#### Tarjan 算法求割点

```pseudo
function FindArticulationPoints(G)
    index = 0
    for each vertex u in V do
        if dfn[u] is undefined then
            DFS_AP(u, NIL)
        end if
    end for
end function

function DFS_AP(u, parent)
    dfn[u] = low[u] = index
    index = index + 1
    children = 0
    
    for each v adjacent to u do
        if dfn[v] is undefined then
            children = children + 1
            DFS_AP(v, u)
            low[u] = min(low[u], low[v])
            
            // 判断割点
            if parent == NIL and children > 1 then
                u 是割点（根节点有多个子树）
            end if
            if parent != NIL and low[v] >= dfn[u] then
                u 是割点（非根节点）
            end if
        else if v != parent then
            low[u] = min(low[u], dfn[v])
        end if
    end for
end function
```

#### 桥的判断

边 (u, v) 是桥 **当且仅当** low[v] > dfn[u]

---

## 六、BFS 的应用

### 6.1 无权图最短路径

BFS 天然求解无权图的单源最短路径。

### 6.2 二分图判定

**定义**：图的顶点可以分成两个集合，所有边都连接不同集合的顶点。

**方法**：BFS 染色，相邻顶点颜色不同

```pseudo
function IsBipartite(G)
    for each vertex u in V do
        color[u] = -1  // 未染色
    end for
    
    for each vertex s in V do
        if color[s] == -1 then
            Queue Q
            Q.enqueue(s)
            color[s] = 0
            
            while Q is not empty do
                u = Q.dequeue()
                for each v adjacent to u do
                    if color[v] == -1 then
                        color[v] = 1 - color[u]  // 染相反颜色
                        Q.enqueue(v)
                    else if color[v] == color[u] then
                        return false  // 相邻同色，非二分图
                    end if
                end for
            end while
        end if
    end for
    
    return true
end function
```

### 6.3 连通分量

**无向图**：每次 BFS/DFS 从未访问顶点开始，得到一个连通分量

**有向图**：使用 Kosaraju 或 Tarjan 算法求强连通分量

---

## 七、图遍历应用总结

| 应用 | 算法 | 复杂度 |
|------|------|--------|
| 遍历所有顶点 | DFS / BFS | O(V + E) |
| 无权最短路径 | BFS | O(V + E) |
| 拓扑排序 | DFS / Kahn | O(V + E) |
| 环检测 | DFS | O(V + E) |
| 强连通分量 | Kosaraju / Tarjan | O(V + E) |
| 割点与桥 | Tarjan | O(V + E) |
| 二分图判定 | BFS 染色 | O(V + E) |
| 连通分量 | DFS / BFS | O(V + E) |

---

## 八、期末考试重点

### 8.1 必考内容

1. **DFS 和 BFS 的过程**：给定图，写出遍历顺序
2. **时间戳**：发现时间、完成时间、括号定理
3. **边分类**：树边、后向边、前向边、交叉边
4. **拓扑排序**：两种方法（DFS 逆序、Kahn 算法）
5. **强连通分量**：Kosaraju 算法步骤

### 8.2 常见题型

| 题型 | 内容 |
|------|------|
| 模拟题 | 手动执行 DFS/BFS，写出访问顺序 |
| 分析题 | 分析边的类型、判断是否有环 |
| 应用题 | 用图遍历解决实际问题 |
| 算法设计 | 基于 DFS/BFS 设计新算法 |

### 8.3 易错点

1. **DFS 递归栈溢出**：大图需要迭代版本
2. **BFS 最短路径**：只适用于无权图
3. **拓扑排序前提**：必须是 DAG
4. **有向图 vs 无向图**：边分类不同
5. **时间戳更新时机**：发现时 +1，完成时 +1

---

## 九、本讲核心公式速查

### DFS 时间戳性质

| 性质 | 描述 |
|------|------|
| 括号定理 | 区间要么分离，要么包含 |
| 白色路径定理 | v 是 u 后代 ⟺ 发现 u 时存在到 v 的白色路径 |
| 后向边判断 | 目标是灰色节点 |
| 有环判断 | 存在后向边 |

### 边分类判断

| 边 (u, v) | color[v] | 时间戳关系 |
|-----------|----------|------------|
| 树边 | WHITE | - |
| 后向边 | GRAY | discover[v] < discover[u] |
| 前向边 | BLACK | discover[u] < discover[v] |
| 交叉边 | BLACK | discover[u] > discover[v] |

### 复杂度汇总

| 算法 | 时间 | 空间 |
|------|------|------|
| DFS | O(V + E) | O(V) |
| BFS | O(V + E) | O(V) |
| 拓扑排序 | O(V + E) | O(V) |
| Kosaraju | O(V + E) | O(V) |
| Tarjan | O(V + E) | O(V) |

---

---

# 第七讲：计算复杂性理论（Computational Complexity Theory）

## 一、计算复杂性理论概述

### 1.1 为什么需要复杂性理论？

在算法设计中，我们经常遇到一些问题：
- 为什么有些问题找不到高效算法？
- 这些问题是**本质上困难**还是我们**还没找到好算法**？
- 如何对问题的**难度**进行分类？

**计算复杂性理论**就是研究这些问题的学科。

### 1.2 核心问题

> **P = NP ?**
> 
> 这是计算机科学中最重要的未解决问题之一，被列为千禧年七大数学难题。

---

## 二、基本概念

### 2.1 判定问题（Decision Problem）

**定义**：输出为**是/否**（Yes/No）的问题。

**例子**：
- 给定图 G，G 是否有哈密顿回路？（Yes/No）
- 给定整数 n，n 是否是素数？（Yes/No）
- 给定 CNF 公式，它是否可满足？（Yes/No）

**为什么关注判定问题？**
- 优化问题可以转化为判定问题
- 例：最短路径长度是多少？→ 是否存在长度 ≤ k 的路径？

### 2.2 编码与问题规模

**编码**：将问题实例表示为字符串（通常是二进制串）

**问题规模 n**：输入编码的长度

**例子**：
- 图的编码：邻接矩阵需要 O(V²) 位
- 整数 N 的编码：需要 O(log N) 位

### 2.3 算法的时间复杂度

**多项式时间**：存在常数 k，算法在 O(nᵏ) 时间内完成

**指数时间**：算法需要 O(2^(n^c)) 时间

**为什么多项式时间重要？**
- 多项式时间被认为是"高效"的
- 指数时间在实际中通常不可接受

---

## 三、复杂性类 P⭐⭐⭐

### 3.1 P 类的定义

**P（Polynomial Time）**：所有可以在**多项式时间**内被**确定性图灵机**解决的判定问题的集合。

$$P = \{L : 存在多项式时间算法 A，对于输入 x，A(x) = 1 \Leftrightarrow x \in L\}$$

### 3.2 P 类问题的特点

| 特点 | 说明 |
|------|------|
| 高效可解 | 存在多项式时间算法 |
| 实际可行 | 在合理时间内可以求解 |
| 封闭性 | P 类在补运算下封闭（P = co-P） |

### 3.3 P 类问题举例

| 问题 | 时间复杂度 | 算法 |
|------|------------|------|
| 排序 | O(n log n) | 归并排序 |
| 最短路径 | O(V² 或 E log V) | Dijkstra |
| 最小生成树 | O(E log V) | Kruskal |
| 最大流 | O(VE²) | Edmonds-Karp |
| 线性规划 | 多项式 | 内点法 |
| 素数判定 | O(log⁶ n) | AKS 算法 |
| 2-SAT | O(n + m) | 强连通分量 |

---

## 四、复杂性类 NP⭐⭐⭐

### 4.1 NP 类的定义

**NP（Nondeterministic Polynomial Time）**：所有可以在**多项式时间**内**验证**解的判定问题的集合。

**等价定义**：可以被**非确定性图灵机**在多项式时间内解决的问题。

$$NP = \{L : 存在多项式时间验证算法 V 和多项式 p，对于 x \in L，存在证书 c（|c| \leq p(|x|)），使得 V(x, c) = 1\}$$

### 4.2 理解 NP：验证 vs 求解

**关键区别**：
- **求解**：从头计算出答案
- **验证**：给定一个"证书"（候选答案），检验它是否正确

**例子：哈密顿回路问题**
- **求解**：找出一条哈密顿回路（可能很难）
- **验证**：给定一条路径，检验它是否是哈密顿回路（容易，O(n)）

### 4.3 NP 类问题举例

| 问题 | 证书 | 验证时间 |
|------|------|----------|
| SAT（可满足性） | 变量赋值 | O(n) |
| 哈密顿回路 | 一条回路 | O(n) |
| 团问题（Clique） | 一个顶点子集 | O(k²) |
| 子集和 | 一个子集 | O(n) |
| 图着色 | 一种着色方案 | O(V + E) |
| 旅行商判定版 | 一条路径 | O(n) |

### 4.4 P 与 NP 的关系

**定理**：P ⊆ NP

**证明**：如果问题可以在多项式时间内**求解**，那么显然可以在多项式时间内**验证**（直接求解并比较）。

**核心问题**：P = NP 还是 P ≠ NP？

```
┌─────────────────────────────────────┐
│                NP                   │
│    ┌───────────────────────┐        │
│    │          P            │        │
│    │   （高效可解问题）      │        │
│    └───────────────────────┘        │
│         NP - P（如果 P ≠ NP）        │
│      （可验证但可能难以求解）         │
└─────────────────────────────────────┘
```

---

## 五、NP 完全问题（NP-Complete）⭐⭐⭐必考

### 5.1 归约（Reduction）

**定义**：如果问题 A 可以**多项式时间归约**到问题 B（记作 A ≤ₚ B），则：
- 存在多项式时间函数 f，使得 x ∈ A ⟺ f(x) ∈ B

**直观理解**：
- 如果 B 能高效解决，则 A 也能高效解决
- A 不比 B 难
- B 至少和 A 一样难

### 5.2 NP 完全的定义

问题 L 是 **NP 完全（NP-Complete, NPC）** 的，当且仅当：
1. L ∈ NP（可以多项式时间验证）
2. 对于所有 L' ∈ NP，有 L' ≤ₚ L（NP 中所有问题都可归约到 L）

**NP 完全问题是 NP 中"最难"的问题**

### 5.3 NP 完全问题的意义

**定理**：如果任何一个 NPC 问题有多项式时间算法，则 P = NP。

**逆否命题**：如果 P ≠ NP，则所有 NPC 问题都没有多项式时间算法。

### 5.4 证明 NP 完全的方法⭐⭐

```
┌─────────────────────────────────────────────────────────────┐
│              证明问题 L 是 NP 完全的步骤                      │
├─────────────────────────────────────────────────────────────┤
│  Step 1：证明 L ∈ NP                                        │
│          给出证书和多项式时间验证算法                         │
├─────────────────────────────────────────────────────────────┤
│  Step 2：选择一个已知的 NPC 问题 L'                          │
├─────────────────────────────────────────────────────────────┤
│  Step 3：构造从 L' 到 L 的多项式时间归约                     │
│          设计函数 f，使得 x ∈ L' ⟺ f(x) ∈ L                │
├─────────────────────────────────────────────────────────────┤
│  Step 4：证明归约的正确性                                    │
│          证明 x ∈ L' ⟹ f(x) ∈ L                            │
│          证明 f(x) ∈ L ⟹ x ∈ L'                            │
├─────────────────────────────────────────────────────────────┤
│  Step 5：证明归约是多项式时间的                              │
└─────────────────────────────────────────────────────────────┘
```

---

## 六、经典 NP 完全问题⭐⭐⭐

### 6.1 SAT 问题（可满足性问题）

#### 问题描述

给定布尔公式（CNF 形式），判断是否存在变量赋值使公式为真。

**CNF（合取范式）**：子句的合取（AND），每个子句是文字的析取（OR）

**例子**：
$$\phi = (x_1 \vee \neg x_2) \wedge (\neg x_1 \vee x_3) \wedge (x_2 \vee \neg x_3)$$

**SAT 是第一个被证明的 NP 完全问题**（Cook-Levin 定理，1971）

#### 验证

- **证书**：变量的一组赋值
- **验证**：代入计算公式值，O(n)

### 6.2 3-SAT 问题

#### 问题描述

SAT 的特殊情况：每个子句**恰好 3 个文字**。

**例子**：
$$\phi = (x_1 \vee x_2 \vee \neg x_3) \wedge (\neg x_1 \vee x_2 \vee x_4)$$

#### NP 完全性证明思路

**SAT ≤ₚ 3-SAT**：将任意子句转换为等价的 3-文字子句

- 1 个文字 (a)：(a ∨ y₁ ∨ y₂) ∧ (a ∨ y₁ ∨ ¬y₂) ∧ (a ∨ ¬y₁ ∨ y₂) ∧ (a ∨ ¬y₁ ∨ ¬y₂)
- 2 个文字 (a ∨ b)：(a ∨ b ∨ y) ∧ (a ∨ b ∨ ¬y)
- k > 3 个文字：引入辅助变量拆分

### 6.3 团问题（Clique）

#### 问题描述

给定无向图 G = (V, E) 和整数 k，判断 G 是否包含大小为 k 的**团**（完全子图）。

**团**：顶点子集 S，其中任意两点之间都有边。

#### NP 完全性

- **证书**：k 个顶点的集合
- **验证**：检查是否两两有边，O(k²)
- **归约**：3-SAT ≤ₚ CLIQUE

### 6.4 顶点覆盖问题（Vertex Cover）

#### 问题描述

给定无向图 G = (V, E) 和整数 k，判断是否存在大小 ≤ k 的顶点子集 S，使得每条边至少有一个端点在 S 中。

#### NP 完全性

- **证书**：顶点子集 S
- **验证**：检查每条边是否被覆盖，O(E)
- **归约**：CLIQUE ≤ₚ VERTEX-COVER

**关键观察**：S 是 G 的团 ⟺ V - S 是补图 Ḡ 的顶点覆盖

### 6.5 哈密顿回路问题（Hamiltonian Cycle）

#### 问题描述

给定图 G，判断是否存在经过每个顶点**恰好一次**的回路。

#### NP 完全性

- **证书**：顶点序列
- **验证**：检查是否形成回路且每点恰好一次，O(V)
- **归约**：3-SAT ≤ₚ HAM-CYCLE（复杂构造）

### 6.6 旅行商问题（TSP）- 判定版

#### 问题描述

给定 n 个城市、城市间距离和预算 B，判断是否存在总距离 ≤ B 的旅行路线（访问每个城市恰好一次并返回起点）。

#### NP 完全性

- **证书**：城市访问顺序
- **验证**：计算总距离并与 B 比较，O(n)
- **归约**：HAM-CYCLE ≤ₚ TSP

### 6.7 子集和问题（Subset Sum）

#### 问题描述

给定整数集合 S = {s₁, s₂, ..., sₙ} 和目标值 t，判断是否存在子集 S' ⊆ S 使得 ∑S' = t。

#### 例子

S = {1, 4, 16, 64, 256, 1040, 1041, 1093, 1284, 1344}，t = 3754

存在子集：{1, 16, 64, 256, 1040, 1093, 1284} 和为 3754 ✓

#### NP 完全性

- **证书**：子集 S'
- **验证**：计算和，O(n)
- **归约**：3-SAT ≤ₚ SUBSET-SUM

### 6.8 图着色问题（Graph Coloring）

#### 问题描述

给定无向图 G 和整数 k，判断是否可以用 k 种颜色对顶点着色，使得相邻顶点颜色不同。

#### NP 完全性

- k = 2：多项式时间（二分图判定）
- k ≥ 3：NP 完全

---

## 七、NP 完全问题归约关系图

```
                    SAT
                     │
                     ▼
                   3-SAT
                  /  |  \
                 /   |   \
                ▼    ▼    ▼
           CLIQUE  3-COLOR  SUBSET-SUM
              │       │         │
              ▼       ▼         ▼
        VERTEX-COVER  k-COLOR   PARTITION
              │                    │
              ▼                    ▼
         INDEPENDENT-SET      KNAPSACK
              │
              ▼
         HAM-CYCLE
              │
              ▼
            TSP
```

---

## 八、NP 难问题（NP-Hard）

### 8.1 定义

问题 L 是 **NP 难（NP-Hard）** 的，当且仅当：
- 对于所有 L' ∈ NP，有 L' ≤ₚ L

**注意**：NP-Hard 问题**不要求**属于 NP！

### 8.2 NP、NPC、NP-Hard 的关系

```
┌─────────────────────────────────────────────┐
│                 NP-Hard                     │
│   ┌─────────────────────────────────────┐   │
│   │               NP                    │   │
│   │    ┌─────────────────────────┐      │   │
│   │    │          P              │      │   │
│   │    └─────────────────────────┘      │   │
│   │         ┌─────────┐                 │   │
│   │         │   NPC   │ = NP ∩ NP-Hard  │   │
│   │         └─────────┘                 │   │
│   └─────────────────────────────────────┘   │
│         NP-Hard but not in NP               │
│         (如停机问题、TSP优化版)              │
└─────────────────────────────────────────────┘
```

### 8.3 NP-Hard 但不在 NP 中的问题

| 问题 | 原因 |
|------|------|
| 停机问题 | 不可判定 |
| TSP 优化版 | 输出是数值，不是 Yes/No |
| 最优调度 | 输出是方案，不是 Yes/No |

---

## 九、co-NP 类

### 9.1 定义

**co-NP**：NP 问题的补问题的集合

$$co\text{-}NP = \{L : \bar{L} \in NP\}$$

### 9.2 例子

| NP 问题 | co-NP 问题 |
|---------|------------|
| SAT（是否可满足） | UNSAT（是否不可满足） |
| HAM-CYCLE（是否有哈密顿回路） | NO-HAM-CYCLE |
| COMPOSITE（是否是合数） | PRIME（是否是素数） |

### 9.3 关系

- P ⊆ NP ∩ co-NP
- 如果 NP ≠ co-NP，则 P ≠ NP
- 目前不知道 NP = co-NP 还是 NP ≠ co-NP

---

## 十、应对 NP 完全问题的策略

当遇到 NPC 问题时，有以下策略：

### 10.1 特殊情况

某些 NPC 问题在特殊输入下可以多项式时间解决：
- 2-SAT 是 P 的（虽然 3-SAT 是 NPC）
- 树上的顶点覆盖是 P 的
- 平面图的着色（4 色）是 P 的

### 10.2 近似算法

接受近似解而非最优解（详见第十讲）

### 10.3 启发式算法

使用启发式方法，不保证最优但实际效果好

### 10.4 参数化算法

当某个参数 k 较小时，复杂度为 f(k) · nᶜ

### 10.5 随机算法

使用随机化，期望时间或高概率得到正确解

### 10.6 指数算法优化

虽然是指数时间，但尽量减小指数基数（如从 O(2ⁿ) 优化到 O(1.5ⁿ)）

---

## 十一、期末考试重点

### 11.1 必考内容

1. **P 和 NP 的定义**：能解释什么是 P、什么是 NP
2. **NP 完全的定义**：两个条件
3. **证明 NP 完全**：证明步骤、归约方法
4. **经典 NPC 问题**：SAT、3-SAT、团、顶点覆盖、哈密顿回路、TSP

### 11.2 常见题型

| 题型 | 内容 |
|------|------|
| 概念题 | P、NP、NPC、NP-Hard 的定义和关系 |
| 判断题 | 判断问题属于哪个复杂性类 |
| 证明题 | 证明某问题是 NP 完全的 |
| 归约题 | 设计从已知 NPC 问题到新问题的归约 |

### 11.3 易错点

1. **NP ≠ 指数时间**：NP 是"可多项式验证"，不是"需要指数时间求解"
2. **归约方向**：证明 L 是 NPC，要从已知 NPC 归约**到** L，不是从 L 归约到已知 NPC
3. **NP-Hard vs NPC**：NP-Hard 不要求在 NP 中
4. **P ⊆ NP**：P 中的问题也在 NP 中

### 11.4 证明 NP 完全的模板

```
证明问题 X 是 NP 完全的：

1. 证明 X ∈ NP：
   - 证书：...（候选解的形式）
   - 验证算法：...（如何在多项式时间验证）
   
2. 证明 X 是 NP-Hard（通过归约）：
   - 选择已知 NPC 问题 Y
   - 构造归约函数 f：将 Y 的实例转换为 X 的实例
   - 证明正确性：y ∈ Y ⟺ f(y) ∈ X
   - 证明 f 是多项式时间可计算的

因此 X 是 NP 完全的。
```

---

## 十二、本讲核心概念速查

### 复杂性类定义

| 类 | 定义 |
|-----|------|
| P | 多项式时间可解 |
| NP | 多项式时间可验证 |
| NPC | NP 且 NP-Hard |
| NP-Hard | NP 中所有问题可归约到它 |
| co-NP | NP 问题的补 |

### 关系图

```
P ⊆ NP
P ⊆ co-NP
NPC = NP ∩ NP-Hard
P ⊆ NP ∩ co-NP
```

### 经典 NPC 问题

| 问题 | 简述 |
|------|------|
| SAT | 布尔公式可满足性 |
| 3-SAT | 每子句 3 个文字的 SAT |
| CLIQUE | 图中是否有 k-团 |
| VERTEX-COVER | 最小顶点覆盖 |
| HAM-CYCLE | 哈密顿回路存在性 |
| TSP | 旅行商问题 |
| SUBSET-SUM | 子集和问题 |
| PARTITION | 集合划分问题 |
| 3-COLOR | 三着色问题 |
| INDEPENDENT-SET | 最大独立集 |

---

---

# 第八讲：回溯法（Backtracking）

## 一、回溯法概述

### 1.1 什么是回溯法？

**回溯法**是一种通过**试探**和**回退**来搜索问题解的算法策略。

> **核心思想**：在解空间树中进行深度优先搜索，当发现当前路径不可能得到解时，**回溯**到上一步，尝试其他选择。

### 1.2 回溯法的基本思想

```
┌─────────────────────────────────────────────────────────────┐
│                     回溯法的核心                             │
├─────────────────────────────────────────────────────────────┤
│  1. 定义解空间：确定问题解的形式和取值范围                    │
│  2. 组织解空间：将解空间组织成树或图的结构                    │
│  3. 深度优先搜索：按深度优先方式遍历解空间树                  │
│  4. 剪枝：利用约束条件和限界函数，剪去不可能产生解的分支      │
└─────────────────────────────────────────────────────────────┘
```

### 1.3 解空间树

**解空间**：问题所有可能解的集合

**解空间树**：将解空间组织成树形结构
- **根节点**：初始状态
- **内部节点**：部分解
- **叶节点**：完整解（可能可行或不可行）

#### 两种常见的解空间树

| 类型 | 特点 | 例子 |
|------|------|------|
| **子集树** | 每个元素选或不选，2ⁿ 个叶节点 | 0-1 背包、子集和 |
| **排列树** | n 个元素的全排列，n! 个叶节点 | TSP、n 皇后 |

```
子集树（n=3）：              排列树（n=3）：
        根                          根
      /    \                    /   |   \
    选1    不选1               1    2    3
    / \    / \               / \  / \  / \
  选2 不选2 ...             2  3 1  3 1  2
  ...                       |  | |  | |  |
                           3  2 3  1 2  1
```

### 1.4 回溯法 vs 穷举法

| 对比项 | 回溯法 | 穷举法 |
|--------|--------|--------|
| 搜索方式 | 有选择地搜索 | 遍历所有可能 |
| 剪枝 | 有（约束函数、限界函数） | 无 |
| 效率 | 通常更高 | 低 |
| 实现 | 递归/栈 | 多重循环 |

---

## 二、回溯法的算法框架⭐⭐

### 2.1 递归框架

```pseudo
function Backtrack(level)
    if level > n then
        // 到达叶节点，找到一个解
        输出或记录解
        return
    end if
    
    for each choice c in choices[level] do
        if IsValid(level, c) then      // 约束函数：剪枝
            solution[level] = c         // 做选择
            Backtrack(level + 1)        // 递归进入下一层
            solution[level] = null      // 撤销选择（回溯）
        end if
    end for
end function
```

### 2.2 迭代框架

```pseudo
function Backtrack_Iterative()
    level = 1
    while level >= 1 do
        if 存在未尝试的选择 c at level then
            if IsValid(level, c) then
                solution[level] = c
                if level == n then
                    输出解
                else
                    level = level + 1  // 进入下一层
                end if
            end if
        else
            solution[level] = null     // 回溯
            level = level - 1
        end if
    end while
end function
```

### 2.3 剪枝策略

| 剪枝类型 | 作用 | 说明 |
|----------|------|------|
| **约束函数** | 可行性剪枝 | 剪去不满足约束条件的分支 |
| **限界函数** | 最优性剪枝 | 剪去不可能产生最优解的分支 |

---

## 三、经典回溯问题详解

### 3.1 n 皇后问题⭐⭐⭐必考

#### 问题描述

在 n×n 的棋盘上放置 n 个皇后，使得任意两个皇后不能互相攻击（不在同一行、同一列、同一对角线）。

#### 解空间分析

- **解的形式**：(x₁, x₂, ..., xₙ)，其中 xᵢ 表示第 i 行皇后所在的列
- **解空间树**：排列树（每行选一列）
- **约束条件**：
  - 不同列：xᵢ ≠ xⱼ
  - 不同对角线：|i - j| ≠ |xᵢ - xⱼ|

#### 伪代码

```pseudo
function NQueens(n)
    solution = array of size n
    Backtrack(1)
end function

function Backtrack(row)
    if row > n then
        输出 solution
        return
    end if
    
    for col = 1 to n do
        if IsValid(row, col) then
            solution[row] = col
            Backtrack(row + 1)
            solution[row] = 0  // 回溯
        end if
    end for
end function

function IsValid(row, col)
    for i = 1 to row - 1 do
        // 检查同列
        if solution[i] == col then
            return false
        end if
        // 检查对角线
        if |row - i| == |col - solution[i]| then
            return false
        end if
    end for
    return true
end function
```

#### 示例：4 皇后问题

```
解空间树搜索过程（部分）：

第1行选列1：
  第2行选列1：冲突（同列）✗
  第2行选列2：冲突（对角线）✗
  第2行选列3：✓
    第3行选列1：冲突（对角线）✗
    第3行选列2：冲突（列2被占？不，检查对角线）冲突 ✗
    第3行选列3：冲突（同列）✗
    第3行选列4：冲突（对角线）✗
    回溯到第2行
  第2行选列4：✓
    第3行选列1：冲突 ✗
    第3行选列2：✓
      第4行选列1：冲突 ✗
      第4行选列2：冲突 ✗
      第4行选列3：冲突 ✗
      第4行选列4：冲突 ✗
      回溯
    ...

最终找到解：(2, 4, 1, 3) 和 (3, 1, 4, 2)

图示（解 2,4,1,3）：
. Q . .
. . . Q
Q . . .
. . Q .
```

#### 复杂度分析

- **时间复杂度**：O(n!)（最坏情况，但剪枝大大减少实际搜索量）
- **空间复杂度**：O(n)

---

### 3.2 子集和问题⭐⭐

#### 问题描述

给定 n 个正整数的集合 S = {s₁, s₂, ..., sₙ} 和目标值 M，找出所有和为 M 的子集。

#### 解空间分析

- **解的形式**：(x₁, x₂, ..., xₙ)，xᵢ ∈ {0, 1}，表示第 i 个元素选或不选
- **解空间树**：子集树
- **约束条件**：当前和 ≤ M
- **限界条件**：当前和 + 剩余元素和 ≥ M

#### 伪代码

```pseudo
function SubsetSum(S, n, M)
    solution = array of size n
    total = sum(S)
    Backtrack(1, 0, total)
end function

function Backtrack(level, current_sum, remaining)
    if current_sum == M then
        输出 solution
        return
    end if
    
    if level > n then
        return
    end if
    
    remaining = remaining - S[level]
    
    // 选择当前元素
    if current_sum + S[level] <= M then  // 约束剪枝
        solution[level] = 1
        Backtrack(level + 1, current_sum + S[level], remaining)
        solution[level] = 0
    end if
    
    // 不选择当前元素
    if current_sum + remaining >= M then  // 限界剪枝
        Backtrack(level + 1, current_sum, remaining)
    end if
end function
```

#### 示例

S = {5, 10, 12, 13, 15, 18}，M = 30

```
搜索过程：
选5 → 选10 → 选12 → 和=27，继续
  选13 → 和=40 > 30，剪枝 ✗
  不选13 → 选15 → 和=42 > 30，剪枝 ✗
  不选15 → 选18 → 和=45 > 30，剪枝 ✗
  不选18 → 和=27 ≠ 30，不是解
  回溯...

找到的解：
{5, 12, 13} = 30 ✓
{5, 10, 15} = 30 ✓
{12, 18} = 30 ✓
...
```

---

### 3.3 0-1 背包问题（回溯法）⭐⭐

#### 问题描述

n 个物品，重量 w[i]，价值 v[i]，背包容量 W，求最大价值。

#### 解空间分析

- **解空间树**：子集树
- **约束函数**：当前重量 ≤ W
- **限界函数**：当前价值 + 剩余物品价值上界 > 当前最优解

#### 限界函数设计

**贪心上界**：将剩余物品按单位价值排序，用分数背包方式计算上界

```pseudo
function Bound(level, current_weight, current_value)
    if current_weight > W then
        return 0
    end if
    
    bound = current_value
    remaining_capacity = W - current_weight
    
    // 按单位价值降序考虑剩余物品
    for i = level to n do
        if w[i] <= remaining_capacity then
            remaining_capacity = remaining_capacity - w[i]
            bound = bound + v[i]
        else
            bound = bound + v[i] * (remaining_capacity / w[i])
            break
        end if
    end for
    
    return bound
end function
```

#### 伪代码

```pseudo
function Knapsack_Backtrack(n, W, w, v)
    // 按单位价值降序排列物品
    Sort items by v[i]/w[i] descending
    
    best_value = 0
    solution = array of size n
    best_solution = array of size n
    
    Backtrack(1, 0, 0)
    return best_value, best_solution
end function

function Backtrack(level, current_weight, current_value)
    if level > n then
        if current_value > best_value then
            best_value = current_value
            best_solution = copy of solution
        end if
        return
    end if
    
    // 选择当前物品
    if current_weight + w[level] <= W then
        solution[level] = 1
        Backtrack(level + 1, current_weight + w[level], current_value + v[level])
        solution[level] = 0
    end if
    
    // 不选择当前物品（限界剪枝）
    if Bound(level + 1, current_weight, current_value) > best_value then
        Backtrack(level + 1, current_weight, current_value)
    end if
end function
```

---

### 3.4 图的着色问题⭐⭐

#### 问题描述

给定无向图 G = (V, E) 和 m 种颜色，判断是否可以用这 m 种颜色对顶点着色，使相邻顶点颜色不同。如果可以，给出一种着色方案。

#### 解空间分析

- **解的形式**：(c₁, c₂, ..., cₙ)，cᵢ ∈ {1, 2, ..., m}
- **解空间树**：m 叉树，共 mⁿ 个叶节点
- **约束条件**：相邻顶点颜色不同

#### 伪代码

```pseudo
function GraphColoring(G, m, n)
    color = array of size n, initialized to 0
    Backtrack(1)
end function

function Backtrack(vertex)
    if vertex > n then
        输出 color
        return true  // 找到一个解
    end if
    
    for c = 1 to m do
        if IsValidColor(vertex, c) then
            color[vertex] = c
            if Backtrack(vertex + 1) then
                return true  // 如果只需要一个解
            end if
            color[vertex] = 0  // 回溯
        end if
    end for
    
    return false
end function

function IsValidColor(vertex, c)
    for each neighbor v of vertex do
        if color[v] == c then
            return false
        end if
    end for
    return true
end function
```

#### 示例

```
图：1 -- 2
    |    |
    3 -- 4

3 种颜色着色：

顶点1选颜色1
  顶点2选颜色1：冲突（与1相邻）✗
  顶点2选颜色2：✓
    顶点3选颜色1：冲突（与1相邻）✗
    顶点3选颜色2：✓
      顶点4选颜色1：✓（与2、3都不冲突）
      找到解：(1, 2, 2, 1)

另一个解：(1, 2, 3, 1)
```

---

### 3.5 旅行商问题（TSP）⭐⭐

#### 问题描述

给定 n 个城市及其两两之间的距离，求访问每个城市恰好一次并返回起点的最短回路。

#### 解空间分析

- **解的形式**：城市的一个排列 (1, π₂, π₃, ..., πₙ, 1)
- **解空间树**：排列树，(n-1)! 个叶节点
- **限界函数**：当前路径长度 + 剩余城市的最短边估计

#### 伪代码

```pseudo
function TSP_Backtrack(dist, n)
    path = [1]  // 从城市 1 出发
    visited = {1}
    best_cost = ∞
    best_path = null
    
    Backtrack(1, 0)
    return best_cost, best_path
end function

function Backtrack(current_city, current_cost)
    if |path| == n then
        // 回到起点
        total_cost = current_cost + dist[current_city][1]
        if total_cost < best_cost then
            best_cost = total_cost
            best_path = copy of path
        end if
        return
    end if
    
    for city = 2 to n do
        if city not in visited then
            new_cost = current_cost + dist[current_city][city]
            
            // 限界剪枝
            if new_cost + LowerBound(visited) < best_cost then
                path.append(city)
                visited.add(city)
                Backtrack(city, new_cost)
                path.remove_last()
                visited.remove(city)
            end if
        end if
    end for
end function

function LowerBound(visited)
    // 简单下界：剩余城市的最小出边之和
    bound = 0
    for each city not in visited do
        min_edge = min distance from city to any unvisited city or city 1
        bound = bound + min_edge
    end for
    return bound
end function
```

---

### 3.6 排列问题

#### 问题描述

生成 {1, 2, ..., n} 的所有排列。

#### 伪代码

```pseudo
function Permutations(n)
    perm = [1, 2, ..., n]
    Backtrack(1)
end function

function Backtrack(level)
    if level > n then
        输出 perm
        return
    end if
    
    for i = level to n do
        Swap(perm[level], perm[i])
        Backtrack(level + 1)
        Swap(perm[level], perm[i])  // 回溯
    end for
end function
```

---

### 3.7 组合问题

#### 问题描述

从 n 个元素中选取 r 个元素的所有组合。

#### 伪代码

```pseudo
function Combinations(n, r)
    combination = []
    Backtrack(1, 0)
end function

function Backtrack(start, count)
    if count == r then
        输出 combination
        return
    end if
    
    // 剪枝：剩余元素不足
    if n - start + 1 < r - count then
        return
    end if
    
    for i = start to n do
        combination.append(i)
        Backtrack(i + 1, count + 1)
        combination.remove_last()  // 回溯
    end for
end function
```

---

## 四、回溯法的优化技巧

### 4.1 剪枝策略

| 策略 | 说明 | 例子 |
|------|------|------|
| **可行性剪枝** | 不满足约束条件的分支 | n皇后：同列/对角线 |
| **最优性剪枝** | 不可能产生更优解的分支 | 背包：上界 ≤ 当前最优 |
| **对称性剪枝** | 利用问题对称性减少搜索 | n皇后：只搜一半 |
| **排序优化** | 先搜索更可能产生解的分支 | 背包：按单位价值排序 |

### 4.2 搜索顺序优化

- **变量选择**：优先选择取值范围小的变量
- **值选择**：优先尝试更可能成功的值

### 4.3 记忆化

对于有重复子问题的情况，可以使用记忆化避免重复计算。

---

## 五、回溯法与其他算法对比

### 5.1 回溯法 vs 动态规划

| 对比项 | 回溯法 | 动态规划 |
|--------|--------|----------|
| 搜索方式 | DFS + 剪枝 | 自底向上/记忆化 |
| 子问题 | 可能重复搜索 | 保存避免重复 |
| 空间 | O(n)（递归栈） | O(n) 到 O(n²) |
| 适用场景 | 求所有解、约束满足 | 求最优解 |
| 时间 | 最坏指数级，剪枝可改善 | 多项式（伪多项式） |

### 5.2 回溯法 vs 分支限界法

| 对比项 | 回溯法 | 分支限界法 |
|--------|--------|------------|
| 搜索方式 | 深度优先（DFS） | 广度优先/最佳优先 |
| 目标 | 找所有解或任一解 | 找最优解 |
| 剪枝 | 约束函数 + 限界函数 | 主要靠限界函数 |
| 数据结构 | 栈（递归） | 队列/优先队列 |

---

## 六、期末考试重点

### 6.1 必考内容

1. **回溯法的基本框架**：递归模板
2. **解空间树**：子集树 vs 排列树
3. **n 皇后问题**：约束条件、搜索过程
4. **剪枝策略**：约束剪枝、限界剪枝

### 6.2 常见题型

| 题型 | 内容 |
|------|------|
| 算法设计 | 用回溯法解决给定问题 |
| 画解空间树 | 画出搜索树，标出剪枝 |
| 模拟执行 | 手动执行回溯过程 |
| 复杂度分析 | 分析最坏情况和剪枝效果 |

### 6.3 易错点

1. **回溯时机**：做选择后要记得撤销
2. **剪枝条件**：约束函数要正确判断
3. **解空间树类型**：子集树和排列树不要混淆
4. **边界条件**：level 从 1 开始还是 0 开始

### 6.4 回溯法解题模板

```
1. 定义解空间
   - 解的形式：(x₁, x₂, ..., xₙ)
   - 每个 xᵢ 的取值范围
   
2. 确定解空间树类型
   - 子集树：每个元素选/不选
   - 排列树：元素的排列
   
3. 设计约束函数
   - 什么情况下当前选择不可行？
   
4. 设计限界函数（最优化问题）
   - 如何估计当前分支的最优可能值？
   
5. 编写回溯算法
   - 递归框架
   - 剪枝条件
```

---

## 七、本讲核心公式速查

### 解空间树规模

| 类型 | 叶节点数 | 内部节点数 |
|------|----------|------------|
| 子集树 | 2ⁿ | 2ⁿ - 1 |
| 排列树 | n! | ≈ e·n! |
| m叉树 | mⁿ | (mⁿ - 1)/(m - 1) |

### 经典问题复杂度

| 问题 | 解空间 | 最坏时间 | 剪枝后 |
|------|--------|----------|--------|
| n 皇后 | n! | O(n!) | 显著减少 |
| 子集和 | 2ⁿ | O(2ⁿ) | 取决于数据 |
| 图着色 | mⁿ | O(mⁿ) | 取决于图结构 |
| TSP | (n-1)! | O(n!) | 取决于限界函数 |

### 回溯法框架

```pseudo
Backtrack(level):
    if level > n:
        处理解
        return
    for each choice c:
        if 约束函数(level, c) and 限界函数():
            做选择
            Backtrack(level + 1)
            撤销选择
```

---

---

# 第九讲：分支限界法（Branch and Bound）

## 一、分支限界法概述

### 1.1 什么是分支限界法？

**分支限界法**是一种在解空间树中搜索问题最优解的算法策略。

> **核心思想**：以**广度优先**或**最佳优先**的方式搜索解空间树，利用**限界函数**剪去不可能产生最优解的分支，从而高效地找到最优解。

### 1.2 分支限界法的基本要素

```
┌─────────────────────────────────────────────────────────────┐
│                   分支限界法三要素                           │
├─────────────────────────────────────────────────────────────┤
│  1. 分支（Branch）：将问题分解为若干子问题（扩展节点）        │
│  2. 限界（Bound）：计算子问题的目标函数界，用于剪枝          │
│  3. 搜索策略：选择下一个要扩展的节点                         │
└─────────────────────────────────────────────────────────────┘
```

### 1.3 分支限界法 vs 回溯法⭐

| 对比项 | 分支限界法 | 回溯法 |
|--------|------------|--------|
| **搜索方式** | BFS / 最佳优先 | DFS |
| **数据结构** | 队列 / 优先队列 | 栈（递归） |
| **目标** | 找**最优解** | 找**所有解**或**任一解** |
| **节点扩展** | 一次性生成所有子节点 | 逐个生成子节点 |
| **存储空间** | 较大（存储活节点表） | 较小（只存路径） |
| **剪枝依据** | 限界函数 | 约束函数 + 限界函数 |

### 1.4 基本概念

| 术语 | 含义 |
|------|------|
| **活节点** | 已生成但未扩展的节点 |
| **死节点** | 已扩展或被剪枝的节点 |
| **扩展节点** | 当前正在扩展的节点 |
| **限界函数** | 估计节点子树中最优解的界 |
| **上界** | 最大化问题中，节点子树最优解的上界 |
| **下界** | 最小化问题中，节点子树最优解的下界 |

---

## 二、分支限界法的搜索策略

### 2.1 队列式分支限界（FIFO）

**策略**：按**先进先出**顺序选择扩展节点（广度优先）

**特点**：
- 简单直观
- 不利用节点的优先级信息
- 可能扩展很多不必要的节点

```pseudo
function FIFO_BranchBound()
    Queue Q
    Q.enqueue(root)
    best = ∞  // 最小化问题
    
    while Q is not empty do
        node = Q.dequeue()
        
        if node 是叶节点 then
            if node.value < best then
                best = node.value
                best_solution = node.solution
            end if
        else
            for each child of node do
                if child.bound < best then  // 限界剪枝
                    Q.enqueue(child)
                end if
            end for
        end if
    end while
    
    return best, best_solution
end function
```

### 2.2 优先队列式分支限界（LC）⭐⭐

**策略**：按**优先级**选择扩展节点（最佳优先）

**优先级设计**：
- 最小化问题：下界小的优先
- 最大化问题：上界大的优先

**特点**：
- 优先扩展最有希望的节点
- 通常比 FIFO 更高效
- 需要优先队列数据结构

```pseudo
function LC_BranchBound()
    PriorityQueue PQ  // 按限界值排序
    PQ.insert(root)
    best = ∞  // 最小化问题
    
    while PQ is not empty do
        node = PQ.extractMin()  // 取下界最小的节点
        
        if node.bound >= best then
            continue  // 剪枝
        end if
        
        if node 是叶节点 then
            if node.value < best then
                best = node.value
                best_solution = node.solution
            end if
        else
            for each child of node do
                计算 child.bound
                if child.bound < best then
                    PQ.insert(child)
                end if
            end for
        end if
    end while
    
    return best, best_solution
end function
```

### 2.3 两种策略对比

| 对比项 | FIFO | 优先队列（LC） |
|--------|------|----------------|
| 搜索顺序 | 广度优先 | 最佳优先 |
| 数据结构 | 普通队列 | 优先队列/堆 |
| 扩展节点数 | 较多 | 较少 |
| 找到最优解速度 | 较慢 | 较快 |
| 实现复杂度 | 简单 | 稍复杂 |

---

## 三、限界函数的设计⭐⭐

### 3.1 限界函数的作用

- **剪枝**：如果节点的界不如当前最优解，则剪去该分支
- **排序**：在优先队列中确定扩展顺序

### 3.2 限界函数的要求

| 要求 | 说明 |
|------|------|
| **有效性** | 界必须是真实最优值的有效估计 |
| **可计算性** | 计算界的时间要尽量短 |
| **紧致性** | 界越紧（越接近真实值），剪枝效果越好 |

### 3.3 常用限界技术

#### 最小化问题的下界

1. **松弛法**：放松约束条件，求解更简单的问题
2. **贪心法**：用贪心策略估计下界
3. **线性规划松弛**：将整数规划松弛为线性规划

#### 最大化问题的上界

1. **放松约束**：如分数背包代替 0-1 背包
2. **贪心上界**：假设剩余选择都是最优的

---

## 四、经典分支限界问题详解

### 4.1 0-1 背包问题⭐⭐⭐必考

#### 问题描述

n 个物品，重量 w[i]，价值 v[i]，背包容量 W，求最大价值。

#### 限界函数设计

**上界计算**：当前价值 + 剩余容量的分数背包最大价值

```pseudo
function UpperBound(node)
    // node 包含：当前层 level，当前重量，当前价值
    bound = node.value
    remaining_capacity = W - node.weight
    
    // 从 level+1 开始，按单位价值降序贪心选择
    for i = node.level + 1 to n do
        if w[i] <= remaining_capacity then
            remaining_capacity = remaining_capacity - w[i]
            bound = bound + v[i]
        else
            bound = bound + v[i] * (remaining_capacity / w[i])
            break
        end if
    end for
    
    return bound
end function
```

#### 分支限界算法

```pseudo
function Knapsack_BranchBound(w, v, n, W)
    // 按单位价值降序排列物品
    Sort items by v[i]/w[i] descending
    
    PriorityQueue PQ  // 最大堆，按上界排序
    
    // 初始化根节点
    root = Node(level=0, weight=0, value=0)
    root.bound = UpperBound(root)
    PQ.insert(root)
    
    best_value = 0
    best_solution = null
    
    while PQ is not empty do
        node = PQ.extractMax()  // 取上界最大的节点
        
        if node.bound <= best_value then
            continue  // 剪枝：上界不超过当前最优
        end if
        
        level = node.level + 1
        
        if level > n then
            continue
        end if
        
        // 分支1：选择物品 level
        if node.weight + w[level] <= W then
            left = Node(level, node.weight + w[level], node.value + v[level])
            left.bound = UpperBound(left)
            
            if left.value > best_value then
                best_value = left.value
                记录解
            end if
            
            if left.bound > best_value then
                PQ.insert(left)
            end if
        end if
        
        // 分支2：不选择物品 level
        right = Node(level, node.weight, node.value)
        right.bound = UpperBound(right)
        
        if right.bound > best_value then
            PQ.insert(right)
        end if
    end while
    
    return best_value
end function
```

#### 示例

物品（已按单位价值排序）：

| 物品 | 重量 | 价值 | 单位价值 |
|------|------|------|----------|
| 1 | 2 | 40 | 20 |
| 2 | 5 | 30 | 6 |
| 3 | 10 | 50 | 5 |
| 4 | 5 | 10 | 2 |

W = 16

```
搜索过程：

根节点：weight=0, value=0
  上界 = 0 + 40 + 30 + 50*(16-2-5)/10 = 0 + 40 + 30 + 45 = 115

扩展根节点：
  选物品1：weight=2, value=40, bound=40+30+50*9/10=40+30+45=115
  不选物品1：weight=0, value=0, bound=0+30+50+10*1/5=92

优先队列：[(115, 选1), (92, 不选1)]

扩展(选1)：
  选物品2：weight=7, value=70, bound=70+50*9/10=115
  不选物品2：weight=2, value=40, bound=40+50+10*4/5=98

优先队列：[(115, 选1选2), (98, 选1不选2), (92, 不选1)]

继续扩展...

最终找到最优解：选物品1、2、4，价值=40+30+10=80
或选物品1、3，价值=40+50=90 ✓
```

---

### 4.2 旅行商问题（TSP）⭐⭐⭐

#### 问题描述

给定 n 个城市及距离矩阵，求访问每个城市恰好一次并返回起点的最短回路。

#### 限界函数设计

**方法1：简单下界**
$$下界 = 当前路径长度 + 剩余城市的最小出边之和$$

**方法2：归约矩阵法（更紧）**

1. 对距离矩阵的每行减去该行最小值
2. 对每列减去该列最小值
3. 下界 = 当前路径长度 + 归约过程中减去的总和

```pseudo
function ReduceMatrix(matrix)
    reduction = 0
    
    // 行归约
    for each row i do
        min_val = min(matrix[i])
        if min_val != ∞ then
            for each column j do
                matrix[i][j] = matrix[i][j] - min_val
            end for
            reduction = reduction + min_val
        end if
    end for
    
    // 列归约
    for each column j do
        min_val = min(matrix[*][j])
        if min_val != ∞ then
            for each row i do
                matrix[i][j] = matrix[i][j] - min_val
            end for
            reduction = reduction + min_val
        end if
    end for
    
    return reduction
end function
```

#### 分支限界算法

```pseudo
function TSP_BranchBound(dist, n)
    PriorityQueue PQ  // 最小堆，按下界排序
    
    // 初始化
    root = Node()
    root.path = [1]
    root.visited = {1}
    root.cost = 0
    root.matrix = copy(dist)
    root.bound = ReduceMatrix(root.matrix)
    
    PQ.insert(root)
    best_cost = ∞
    best_path = null
    
    while PQ is not empty do
        node = PQ.extractMin()
        
        if node.bound >= best_cost then
            continue  // 剪枝
        end if
        
        current = node.path.last()
        
        // 如果访问了所有城市
        if |node.path| == n then
            total = node.cost + dist[current][1]  // 返回起点
            if total < best_cost then
                best_cost = total
                best_path = node.path + [1]
            end if
            continue
        end if
        
        // 扩展：尝试访问每个未访问的城市
        for city = 1 to n do
            if city not in node.visited then
                child = CreateChild(node, current, city)
                if child.bound < best_cost then
                    PQ.insert(child)
                end if
            end if
        end for
    end while
    
    return best_cost, best_path
end function

function CreateChild(parent, from, to)
    child = Node()
    child.path = parent.path + [to]
    child.visited = parent.visited ∪ {to}
    child.cost = parent.cost + dist[from][to]
    
    // 复制并更新归约矩阵
    child.matrix = copy(parent.matrix)
    // 将 from 行和 to 列设为 ∞
    for i = 1 to n do
        child.matrix[from][i] = ∞
        child.matrix[i][to] = ∞
    end for
    child.matrix[to][1] = ∞  // 防止提前返回起点
    
    reduction = ReduceMatrix(child.matrix)
    child.bound = child.cost + reduction
    
    return child
end function
```

#### 示例

距离矩阵：
```
    1    2    3    4
1 [ ∞   10   15   20 ]
2 [ 10   ∞   35   25 ]
3 [ 15  35    ∞   30 ]
4 [ 20  25   30    ∞ ]
```

```
初始归约：
行归约：减去 [10, 10, 15, 20]
    1    2    3    4
1 [ ∞    0    5   10 ]
2 [  0   ∞   25   15 ]
3 [  0  20    ∞   15 ]
4 [  0   5   10    ∞ ]

列归约：减去 [0, 0, 5, 10]
    1    2    3    4
1 [ ∞    0    0    0 ]
2 [  0   ∞   20    5 ]
3 [  0  20    ∞    5 ]
4 [  0   5    5    ∞ ]

初始下界 = 10+10+15+20+5+10 = 70

搜索过程...
最优路径：1 → 2 → 4 → 3 → 1，总距离 = 10+25+30+15 = 80
```

---

### 4.3 单源最短路径问题

#### 问题描述

给定带权有向图，求从源点到目标点的最短路径。

#### 分支限界解法

```pseudo
function ShortestPath_BranchBound(G, source, target)
    PriorityQueue PQ  // 最小堆，按距离排序
    
    PQ.insert((source, 0, [source]))  // (节点, 距离, 路径)
    visited = {}
    
    while PQ is not empty do
        (node, dist, path) = PQ.extractMin()
        
        if node == target then
            return dist, path
        end if
        
        if node in visited then
            continue
        end if
        visited.add(node)
        
        for each neighbor v of node do
            if v not in visited then
                new_dist = dist + weight(node, v)
                PQ.insert((v, new_dist, path + [v]))
            end if
        end for
    end while
    
    return ∞, null  // 无法到达
end function
```

**注意**：这实际上就是 Dijkstra 算法的一种实现方式！

---

### 4.4 任务分配问题⭐⭐

#### 问题描述

n 个任务分配给 n 个人，每人完成一个任务。c[i][j] 表示第 i 个人完成第 j 个任务的代价。求最小总代价的分配方案。

#### 限界函数

**下界**：当前代价 + 剩余每个人的最小任务代价之和

```pseudo
function LowerBound(node, cost_matrix)
    bound = node.cost
    
    for i = node.level + 1 to n do
        min_cost = ∞
        for j = 1 to n do
            if j not in node.assigned then
                min_cost = min(min_cost, cost_matrix[i][j])
            end if
        end for
        bound = bound + min_cost
    end for
    
    return bound
end function
```

#### 分支限界算法

```pseudo
function Assignment_BranchBound(cost, n)
    PriorityQueue PQ
    
    root = Node(level=0, cost=0, assigned={})
    root.bound = LowerBound(root, cost)
    PQ.insert(root)
    
    best_cost = ∞
    best_assignment = null
    
    while PQ is not empty do
        node = PQ.extractMin()
        
        if node.bound >= best_cost then
            continue
        end if
        
        level = node.level + 1
        
        if level > n then
            if node.cost < best_cost then
                best_cost = node.cost
                best_assignment = node.assignment
            end if
            continue
        end if
        
        // 为第 level 个人分配任务
        for task = 1 to n do
            if task not in node.assigned then
                child = Node()
                child.level = level
                child.cost = node.cost + cost[level][task]
                child.assigned = node.assigned ∪ {task}
                child.assignment = node.assignment + [(level, task)]
                child.bound = LowerBound(child, cost)
                
                if child.bound < best_cost then
                    PQ.insert(child)
                end if
            end if
        end for
    end while
    
    return best_cost, best_assignment
end function
```

#### 示例

代价矩阵：
```
任务    1    2    3
人1  [  9   2    7  ]
人2  [  6   4    3  ]
人3  [  5   8    1  ]
```

```
初始下界 = min(9,2,7) + min(6,4,3) + min(5,8,1) = 2 + 3 + 1 = 6

搜索过程：
人1→任务2 (cost=2)：下界 = 2 + 3 + 1 = 6
人1→任务1 (cost=9)：下界 = 9 + 3 + 1 = 13
人1→任务3 (cost=7)：下界 = 7 + 4 + 5 = 16

优先扩展 (人1→任务2)：
  人2→任务1 (cost=2+6=8)：下界 = 8 + 1 = 9
  人2→任务3 (cost=2+3=5)：下界 = 5 + 5 = 10

优先扩展 (人2→任务1)：
  人3→任务3 (cost=8+1=9)：找到解！

最优分配：人1→任务2，人2→任务1，人3→任务3
总代价：2 + 6 + 1 = 9
```

---

### 4.5 布线问题

#### 问题描述

在 n×m 的网格中，从起点 (sx, sy) 到终点 (tx, ty) 找一条最短路径，只能走上下左右，有些格子是障碍物。

#### 分支限界解法（BFS）

```pseudo
function WiringProblem(grid, start, target)
    Queue Q
    Q.enqueue((start, 0))
    visited[start] = true
    parent[start] = null
    
    directions = [(0,1), (0,-1), (1,0), (-1,0)]
    
    while Q is not empty do
        (pos, dist) = Q.dequeue()
        
        if pos == target then
            return dist, ReconstructPath(parent, target)
        end if
        
        for (dx, dy) in directions do
            new_pos = (pos.x + dx, pos.y + dy)
            if IsValid(new_pos) and not visited[new_pos] then
                visited[new_pos] = true
                parent[new_pos] = pos
                Q.enqueue((new_pos, dist + 1))
            end if
        end for
    end while
    
    return -1, null  // 无法到达
end function
```

---

## 五、分支限界法的优化

### 5.1 限界函数优化

| 策略 | 说明 |
|------|------|
| **更紧的界** | 界越紧，剪枝越有效 |
| **快速计算** | 限界函数不能太复杂 |
| **增量更新** | 从父节点的界推导子节点的界 |

### 5.2 搜索策略优化

| 策略 | 说明 |
|------|------|
| **混合策略** | 结合 BFS 和最佳优先 |
| **重启策略** | 定期重新选择扩展方向 |
| **并行搜索** | 多线程同时扩展不同分支 |

### 5.3 存储优化

| 策略 | 说明 |
|------|------|
| **限制队列大小** | 只保留最有希望的节点 |
| **节点压缩** | 减少每个节点的存储空间 |
| **延迟生成** | 需要时才生成子节点信息 |

---

## 六、分支限界法总结

### 6.1 适用场景

- **组合优化问题**：背包、TSP、任务分配
- **求最优解**：而非所有解
- **解空间有限**：可枚举

### 6.2 算法设计要点

```
1. 定义解空间树
   - 节点表示什么状态
   - 如何从父节点生成子节点

2. 设计限界函数
   - 如何估计子树的最优值
   - 平衡计算复杂度和界的紧致性

3. 选择搜索策略
   - FIFO：简单，但可能效率低
   - 优先队列：通常更高效

4. 实现剪枝
   - 界不如当前最优解时剪枝
   - 不满足约束时剪枝
```

### 6.3 经典问题复杂度

| 问题 | 解空间 | 限界函数 | 实际效率 |
|------|--------|----------|----------|
| 0-1 背包 | 2ⁿ | 分数背包上界 | 通常很好 |
| TSP | (n-1)! | 归约矩阵下界 | 中等规模可解 |
| 任务分配 | n! | 行最小值下界 | 较好 |

---

## 七、期末考试重点

### 7.1 必考内容

1. **分支限界法与回溯法的区别**
2. **两种搜索策略**：FIFO vs 优先队列
3. **限界函数的设计**：上界/下界的计算
4. **0-1 背包的分支限界解法**

### 7.2 常见题型

| 题型 | 内容 |
|------|------|
| 概念题 | 活节点、死节点、限界函数 |
| 设计题 | 为给定问题设计限界函数 |
| 模拟题 | 手动执行分支限界过程 |
| 比较题 | 与回溯法的异同 |

### 7.3 易错点

1. **搜索方向**：分支限界是 BFS/最佳优先，不是 DFS
2. **剪枝条件**：最小化问题用下界，最大化问题用上界
3. **限界 vs 实际值**：限界是估计值，不是真实最优值
4. **节点存储**：需要存储完整状态，空间开销大

### 7.4 分支限界法解题模板

```
1. 确定优化目标
   - 最大化 or 最小化
   
2. 定义节点状态
   - 当前选择、当前代价/价值
   
3. 设计限界函数
   - 最大化：计算上界
   - 最小化：计算下界
   
4. 选择搜索策略
   - FIFO 或优先队列
   
5. 实现算法
   - 初始化根节点
   - 循环：取节点、判断、扩展、剪枝
```

---

## 八、本讲核心公式速查

### 分支限界 vs 回溯

| 特性 | 分支限界 | 回溯 |
|------|----------|------|
| 搜索 | BFS/最佳优先 | DFS |
| 目标 | 最优解 | 所有解/任一解 |
| 空间 | O(活节点数) | O(树高) |

### 限界函数设计

| 问题 | 限界函数 |
|------|----------|
| 0-1 背包（最大化） | 当前价值 + 分数背包上界 |
| TSP（最小化） | 当前距离 + 归约矩阵下界 |
| 任务分配（最小化） | 当前代价 + 剩余行最小值和 |

### 剪枝条件

| 问题类型 | 剪枝条件 |
|----------|----------|
| 最大化问题 | 上界 ≤ 当前最优值 |
| 最小化问题 | 下界 ≥ 当前最优值 |

---

---

# 第十讲：近似算法（Approximation Algorithm）

## 一、近似算法概述

### 1.1 为什么需要近似算法？

对于 **NP 难问题**：
- 精确算法需要**指数时间**
- 实际应用中无法接受
- 但我们仍然需要在合理时间内得到**较好的解**

**近似算法**就是在**多项式时间**内求得**近似最优解**的算法。

### 1.2 近似算法的核心思想

> **用时间换精度的妥协**：放弃寻找最优解，转而在多项式时间内找到一个**质量有保证**的近似解。

### 1.3 近似算法 vs 其他方法

| 方法 | 时间复杂度 | 解的质量 | 质量保证 |
|------|------------|----------|----------|
| 精确算法 | 指数级 | 最优 | ✅ 100% |
| 近似算法 | 多项式 | 近似最优 | ✅ 有界 |
| 启发式算法 | 多项式 | 可能好 | ❌ 无保证 |
| 随机算法 | 多项式 | 期望好 | ✅ 概率保证 |

---

## 二、近似比（Approximation Ratio）⭐⭐⭐

### 2.1 定义

设 OPT 为最优解的值，ALG 为近似算法得到的解的值。

**近似比 ρ(n)** 定义为：

$$\rho(n) = \max\left(\frac{ALG}{OPT}, \frac{OPT}{ALG}\right)$$

或者分别定义：
- **最小化问题**：ρ(n) = ALG / OPT ≥ 1
- **最大化问题**：ρ(n) = OPT / ALG ≥ 1

### 2.2 近似比的含义

| 近似比 | 含义 |
|--------|------|
| ρ = 1 | 精确算法，得到最优解 |
| ρ = 2 | 解最多比最优解差 2 倍 |
| ρ = 1 + ε | 可以任意接近最优解（PTAS） |

### 2.3 ρ-近似算法

如果对于所有输入，算法的近似比都不超过 ρ，则称该算法为 **ρ-近似算法**。

**例子**：
- 2-近似算法：ALG ≤ 2·OPT（最小化）或 ALG ≥ OPT/2（最大化）
- (1+ε)-近似算法：ALG ≤ (1+ε)·OPT

---

## 三、近似算法的分类

### 3.1 按近似比分类

| 类型 | 近似比 | 说明 |
|------|--------|------|
| **常数近似** | O(1) | 近似比是常数，如 2-近似 |
| **对数近似** | O(log n) | 近似比随问题规模对数增长 |
| **多项式近似** | O(nᵏ) | 近似比随问题规模多项式增长 |

### 3.2 特殊的近似算法类

#### PTAS（Polynomial Time Approximation Scheme）

对于任意 ε > 0，存在 (1+ε)-近似算法，时间复杂度是 n 的多项式（但可能是 ε 的指数）。

**时间复杂度**：O(n^(1/ε)) 或 O(n^(f(1/ε)))

#### FPTAS（Fully Polynomial Time Approximation Scheme）

对于任意 ε > 0，存在 (1+ε)-近似算法，时间复杂度是 n 和 1/ε 的**多项式**。

**时间复杂度**：O(n² / ε) 或 O(n³ / ε²)

```
精确算法 ⊂ FPTAS ⊂ PTAS ⊂ 常数近似 ⊂ 近似算法
```

---

## 四、经典近似算法详解

### 4.1 顶点覆盖问题的 2-近似算法⭐⭐⭐必考

#### 问题描述

给定无向图 G = (V, E)，找最小的顶点子集 S，使得每条边至少有一个端点在 S 中。

#### 贪心近似算法

**策略**：每次选择一条边，将两个端点都加入覆盖集，然后删除所有与这两点关联的边。

```pseudo
function ApproxVertexCover(G)
    C = ∅  // 覆盖集
    E' = E  // 边的副本
    
    while E' ≠ ∅ do
        选择 E' 中任意一条边 (u, v)
        C = C ∪ {u, v}
        从 E' 中删除所有与 u 或 v 关联的边
    end while
    
    return C
end function
```

#### 示例

```
图：
    A --- B
    |     |
    C --- D --- E

执行过程：
1. 选边 (A, B)，C = {A, B}，删除 (A,B), (A,C), (B,D)
2. 选边 (C, D)，C = {A, B, C, D}，删除 (C,D), (D,E)
3. E' = ∅，结束

结果：C = {A, B, C, D}，大小 4
最优解：{B, C, D} 或 {A, D}，大小 3（实际最优是 {B, C} 或 {A, D}，大小 2）

近似比：4/2 = 2
```

#### 近似比证明⭐

**定理**：该算法是 2-近似算法。

**证明**：
1. 设算法选择的边集为 M（这些边两两不相邻，形成**匹配**）
2. |C| = 2|M|（每条边贡献 2 个顶点）
3. 最优覆盖 OPT 必须覆盖 M 中的每条边
4. M 中的边两两不相邻，所以覆盖每条边至少需要一个顶点
5. 因此 OPT ≥ |M|
6. 所以 |C| = 2|M| ≤ 2·OPT

**近似比 ρ = 2** ∎

#### 复杂度
- **时间复杂度**：O(V + E)
- **空间复杂度**：O(V + E)

---

### 4.2 旅行商问题（TSP）的近似算法⭐⭐

#### 4.2.1 度量 TSP（满足三角不等式）

**条件**：距离满足三角不等式 d(u, w) ≤ d(u, v) + d(v, w)

#### 2-近似算法（基于 MST）

**思想**：最小生成树的权重是 TSP 最优解的下界

```pseudo
function ApproxTSP_MST(G)
    // Step 1: 构建最小生成树
    T = MST(G)
    
    // Step 2: DFS 遍历 MST，得到顶点序列
    path = DFS_Preorder(T)
    
    // Step 3: 按序列顺序访问，跳过重复顶点
    tour = RemoveDuplicates(path)
    tour.append(tour[0])  // 回到起点
    
    return tour
end function
```

#### 近似比证明

1. 设最优 TSP 路径为 OPT
2. 删除 OPT 中的一条边得到生成树，所以 MST ≤ OPT
3. DFS 遍历 MST，每条边走两次，总长度 = 2·MST ≤ 2·OPT
4. 由三角不等式，跳过重复顶点不会增加距离
5. 所以 ALG ≤ 2·OPT

**近似比 ρ = 2** ∎

#### 1.5-近似算法（Christofides 算法）

**更好的算法**：
1. 构建 MST
2. 找出 MST 中度数为奇数的顶点集 O
3. 在 O 上求最小权完美匹配 M
4. 将 M 加入 MST 得到欧拉图
5. 找欧拉回路，然后跳过重复顶点

**近似比 ρ = 1.5**

#### 4.2.2 一般 TSP

**定理**：除非 P = NP，一般 TSP 不存在常数近似算法。

---

### 4.3 集合覆盖问题的贪心近似⭐⭐

#### 问题描述

给定全集 U = {1, 2, ..., n} 和 m 个子集 S₁, S₂, ..., Sₘ，每个子集有代价 cᵢ。选择若干子集，使其并集等于 U，且总代价最小。

#### 贪心算法

**策略**：每次选择**性价比最高**的子集（覆盖新元素最多/代价）

```pseudo
function GreedySetCover(U, S, c)
    covered = ∅
    selected = []
    
    while covered ≠ U do
        // 选择性价比最高的子集
        best = argmin_{i: S_i ∩ (U - covered) ≠ ∅} c_i / |S_i ∩ (U - covered)|
        
        selected.append(best)
        covered = covered ∪ S_best
    end while
    
    return selected
end function
```

#### 近似比

**定理**：贪心算法是 H(n)-近似算法，其中 H(n) = 1 + 1/2 + ... + 1/n ≈ ln n。

**证明思路**：
- 将每个子集的代价分摊到它覆盖的新元素上
- 第 k 个被覆盖的元素分摊的代价 ≤ OPT / (n - k + 1)
- 总代价 ≤ OPT · H(n)

**这是最优的**：除非 P = NP，集合覆盖不存在 (1-ε)ln n 近似算法。

---

### 4.4 装箱问题（Bin Packing）⭐⭐

#### 问题描述

有 n 个物品，大小为 s₁, s₂, ..., sₙ（0 < sᵢ ≤ 1）。有无限多个容量为 1 的箱子。求最少需要多少个箱子装下所有物品。

#### 4.4.1 首次适应算法（First Fit, FF）

**策略**：按顺序考虑物品，放入第一个能容纳它的箱子

```pseudo
function FirstFit(items)
    bins = []
    
    for each item s in items do
        placed = false
        for each bin b in bins do
            if b.remaining >= s then
                放入 item 到 bin b
                placed = true
                break
            end if
        end for
        
        if not placed then
            创建新箱子，放入 item
        end if
    end for
    
    return |bins|
end function
```

**近似比**：FF(I) ≤ ⌈1.7·OPT(I)⌉ + 1

#### 4.4.2 首次适应递减算法（First Fit Decreasing, FFD）

**策略**：先将物品按大小**降序排序**，再用首次适应

```pseudo
function FirstFitDecreasing(items)
    Sort items in decreasing order
    return FirstFit(items)
end function
```

**近似比**：FFD(I) ≤ (11/9)·OPT(I) + 6/9 ≈ 1.22·OPT + 0.67

#### 示例

物品：0.5, 0.7, 0.5, 0.2, 0.4, 0.2, 0.5, 0.1, 0.6, 0.1

**FF**：
```
箱1: 0.5, 0.2, 0.2, 0.1 = 1.0
箱2: 0.7, 0.1 = 0.8
箱3: 0.5, 0.4 = 0.9
箱4: 0.5 = 0.5
箱5: 0.6 = 0.6
共 5 个箱子
```

**FFD**（排序后：0.7, 0.6, 0.5, 0.5, 0.5, 0.4, 0.2, 0.2, 0.1, 0.1）：
```
箱1: 0.7, 0.2 = 0.9
箱2: 0.6, 0.4 = 1.0
箱3: 0.5, 0.5 = 1.0
箱4: 0.5, 0.2, 0.1, 0.1 = 0.9
共 4 个箱子
```

---

### 4.5 背包问题的 FPTAS⭐⭐

#### 问题描述

0-1 背包问题：n 个物品，重量 wᵢ，价值 vᵢ，容量 W，求最大价值。

#### FPTAS 算法思想

**核心**：对价值进行**缩放和取整**，减少状态数

```pseudo
function KnapsackFPTAS(w, v, n, W, ε)
    // Step 1: 找最大价值
    v_max = max(v)
    
    // Step 2: 计算缩放因子
    K = ε · v_max / n
    
    // Step 3: 缩放价值
    for i = 1 to n do
        v'[i] = floor(v[i] / K)
    end for
    
    // Step 4: 用动态规划求解缩放后的问题
    // dp[j] = 达到价值 j 所需的最小重量
    max_value = n · floor(v_max / K)
    dp[0..max_value] = ∞
    dp[0] = 0
    
    for i = 1 to n do
        for j = max_value downto v'[i] do
            dp[j] = min(dp[j], dp[j - v'[i]] + w[i])
        end for
    end for
    
    // Step 5: 找最大可行价值
    result = 0
    for j = max_value downto 0 do
        if dp[j] <= W then
            result = j
            break
        end if
    end for
    
    // Step 6: 恢复原始价值
    return result · K
end function
```

#### 复杂度分析

- **状态数**：O(n · v_max / K) = O(n · v_max / (ε · v_max / n)) = O(n² / ε)
- **时间复杂度**：O(n³ / ε)
- **空间复杂度**：O(n² / ε)

#### 近似比证明

**定理**：算法是 (1+ε)-近似算法。

**证明思路**：
1. 缩放误差：每个物品价值误差 ≤ K
2. 总误差 ≤ n · K = ε · v_max
3. OPT ≥ v_max（至少选一个最大价值物品）
4. ALG ≥ OPT - ε · v_max ≥ OPT - ε · OPT = (1-ε) · OPT
5. 所以 ALG ≥ OPT / (1+ε')，其中 ε' ≈ ε

---

### 4.6 调度问题的近似算法⭐

#### 问题描述

m 台相同的机器，n 个任务，任务 j 的处理时间为 pⱼ。目标：最小化**完工时间**（makespan），即所有机器完成时间的最大值。

#### 贪心算法（List Scheduling）

**策略**：按任务顺序，每次将任务分配给**当前负载最小**的机器

```pseudo
function ListScheduling(p, n, m)
    load[1..m] = 0  // 每台机器的当前负载
    
    for j = 1 to n do
        // 找负载最小的机器
        i = argmin(load)
        assign job j to machine i
        load[i] = load[i] + p[j]
    end for
    
    return max(load)
end function
```

**近似比**：ρ = 2 - 1/m

#### LPT 算法（Longest Processing Time）

**策略**：先将任务按处理时间**降序排序**，再用 List Scheduling

**近似比**：ρ = 4/3 - 1/(3m)

---

## 五、近似算法设计技术

### 5.1 贪心法

- **思想**：每步选择局部最优
- **例子**：集合覆盖、调度问题
- **优点**：简单高效
- **缺点**：近似比可能较大

### 5.2 局部搜索

- **思想**：从初始解出发，不断改进
- **例子**：MAX-CUT 的 2-近似
- **优点**：解质量较好
- **缺点**：可能陷入局部最优

### 5.3 线性规划松弛

- **思想**：将整数规划松弛为线性规划，再舍入
- **例子**：顶点覆盖、集合覆盖
- **优点**：有理论保证
- **缺点**：需要 LP 求解器

### 5.4 原始-对偶方法

- **思想**：利用线性规划的对偶性
- **例子**：集合覆盖、设施选址
- **优点**：近似比分析自然
- **缺点**：设计较复杂

---

## 六、近似算法总结

### 6.1 经典问题近似比

| 问题 | 最佳近似比 | 不可近似性 |
|------|------------|------------|
| 顶点覆盖 | 2 | < 1.36（除非 P=NP） |
| 集合覆盖 | H(n) ≈ ln n | < (1-ε)ln n |
| 度量 TSP | 1.5 | - |
| 一般 TSP | 无常数近似 | 任意常数 |
| 装箱 | 1.22 (FFD) | - |
| 0-1 背包 | FPTAS | - |
| MAX-CUT | 0.878 | < 0.942（UGC） |
| 调度（makespan） | 4/3 - 1/(3m) | - |

### 6.2 问题分类

```
┌─────────────────────────────────────────────────────────┐
│                    NP 难问题                             │
├───────────────┬───────────────┬─────────────────────────┤
│    FPTAS      │    PTAS       │    常数近似              │
│  (背包)       │  (调度)       │  (顶点覆盖、TSP)         │
├───────────────┴───────────────┴─────────────────────────┤
│                    对数近似                              │
│                  (集合覆盖)                              │
├─────────────────────────────────────────────────────────┤
│                  无常数近似                              │
│                  (一般 TSP)                              │
└─────────────────────────────────────────────────────────┘
```

---

## 七、期末考试重点

### 7.1 必考内容

1. **近似比的定义**：最小化和最大化问题
2. **顶点覆盖的 2-近似**：算法和证明
3. **TSP 的近似算法**：基于 MST 的 2-近似
4. **PTAS 和 FPTAS 的概念**

### 7.2 常见题型

| 题型 | 内容 |
|------|------|
| 概念题 | 近似比、PTAS、FPTAS 的定义 |
| 证明题 | 证明某算法的近似比 |
| 设计题 | 为给定问题设计近似算法 |
| 分析题 | 分析给定算法的近似比 |

### 7.3 易错点

1. **近似比方向**：最小化是 ALG/OPT，最大化是 OPT/ALG
2. **证明结构**：需要证明 ALG 与 OPT 的关系，通常需要找中间量
3. **三角不等式**：度量 TSP 需要这个条件
4. **PTAS vs FPTAS**：时间复杂度对 1/ε 的依赖不同

### 7.4 近似比证明模板

```
证明算法 A 是 ρ-近似算法：

1. 找下界/上界
   - 最小化问题：找 OPT 的下界 LB
   - 最大化问题：找 OPT 的上界 UB

2. 分析算法输出
   - 证明 ALG ≤ ρ · LB（最小化）
   - 或 ALG ≥ UB / ρ（最大化）

3. 得出结论
   - ALG ≤ ρ · LB ≤ ρ · OPT（最小化）
   - ALG ≥ UB / ρ ≥ OPT / ρ（最大化）
```

---

## 八、本讲核心公式速查

### 近似比定义

| 问题类型 | 近似比 | 含义 |
|----------|--------|------|
| 最小化 | ρ = ALG / OPT | ALG ≤ ρ · OPT |
| 最大化 | ρ = OPT / ALG | ALG ≥ OPT / ρ |

### 经典算法近似比

| 算法 | 问题 | 近似比 |
|------|------|--------|
| 边选择法 | 顶点覆盖 | 2 |
| MST-based | 度量 TSP | 2 |
| Christofides | 度量 TSP | 1.5 |
| 贪心 | 集合覆盖 | H(n) ≈ ln n |
| FFD | 装箱 | 11/9 ≈ 1.22 |
| FPTAS | 背包 | 1 + ε |
| LPT | 调度 | 4/3 - 1/(3m) |

### 近似算法层次

```
精确算法 ⊂ FPTAS ⊂ PTAS ⊂ 常数近似 ⊂ 对数近似 ⊂ 多项式近似
```

---

> 📝 **下一讲预告**：第十一讲 - 随机算法
> 
> 如需继续生成其他讲次内容，请告诉我！


