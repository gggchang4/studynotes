# Chapter1 滤波
对图像中每个像素，用它周围邻域像素按照某种“规则”（或“权重”）进行组合，从而得到一个新的像素值
从本质上讲，滤波就是一种 **局部加权变换（local weighted transformation）**，用于突出或抑制图像中的某些信息

## 滤波的本质
$I^′(x,y)=u,v∑​K(u,v)I(x−u,y−v)$

## 卷积核Kernel
滤波的作用取决于卷积核的类型

卷积核是一个小型的矩阵（通常是 3×3、5×5、7×7），用于对图像进行局部加权计算

它定义了滤波操作的规则，决定了你要从图像中“提取什么信息”

卷积核作用于图像时，会执行“滑动 × 点乘 × 求和”：
1. 将核的中心对齐到输入图像像素 (x,y)
2. 将核的每个位置 (u,v) 与图像对应位置 (x−u, y−v) 的像素相乘
3. 把所有乘积求和，作为输出像素 I'(x,y)
### 卷积核的类型：
1. 平滑核：去噪，模糊$$
		
\frac{1}{9}
\begin{bmatrix}
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1
\end{bmatrix}


$$
2. Gaussian核：更高级的平滑$$\frac{1}{16}
\begin{bmatrix}
1 & 2 & 1 \\
2 & 4 & 2 \\
1 & 2 & 1
\end{bmatrix}
   $$
3. 锐化核：强调边缘$$
\begin{bmatrix}
0 & -1 & 0 \\
-1 & 5 & -1 \\
0 & -1 & 0
\end{bmatrix}
$$
4. 边缘检测核：提取高频细节
	以sobel为例
$$
\begin{bmatrix}
-1 & -2 & -1 \\
0 & 0 & 0 \\
1 & 2 & 1
\end{bmatrix}
$$
5. CNN中的卷积核：自动学习特征

## 卷积与互相关
###  基本直觉：二者都是“滑动 × 加权求和”

无论是互相关还是卷积，它们都对图像执行如下步骤：
1. 使用一个小窗口（卷积核 / 滤波核）
2. 在图像上滑动
3. 对窗口内的像素与核权重逐点相乘
4. 求和得到输出像素

**核心区别：**
> **卷积需要将卷积核旋转 180°；互相关不旋转。**

### 互相关（Cross-correlation）

$I′(x,y)=\sum_{u,v} K(u,v) \, I(x+u,\; y+v)$
$I^′=K\otimes I$

- 核 **不翻转**。
- 直接按原样与图像进行加权求和。

### **卷积（Convolution）**
图像处理中常用定义：

$I^′(x,y)=\sum_{u,v} K(u,v) \, I(x-u,\; y-v)$  
$I^′=K*I$

等价于：
1. 将核旋转 **180°**（水平和垂直）：

$K^∗(u,v)=K(−u,−v)$  

2. 再做互相关。

### 直观示例：核的旋转对比
给定原核：
$$
K\begin{bmatrix} a & b & c \\ d & e & f \\ g & h & i \end{bmatrix}​​  
$$
### 互相关使用核的原样：
$$
\begin{bmatrix} a & b & c \\ d & e & f \\ g & h & i \end{bmatrix}
$$
### 卷积使用核旋转 180° 后：
$$
K^*\begin{bmatrix} i & h & g \\ f & e & d \\ c & b & a \end{bmatrix}​​  
$$
所谓两个函数的卷积，本质上就是先将一个函数翻转，然后进行滑动叠加
- 卷积的“卷”，指的的函数的翻转；同时，“卷”还有滑动的意味在里面
- 卷积的“积”，指的是积分/加权求和

## 平滑
### 均值滤波
$$
\frac{1}{9}
\begin{bmatrix}
1 & 1 & 1 \\
1 & 1 & 1 \\
1 & 1 & 1
\end{bmatrix}
$$
### **高斯滤波**

![[Pasted image 20251208200715.png|200]]
#### 1. 什么是高斯滤波？

高斯滤波是一种使用 **高斯分布作为加权窗口** 的平滑滤波方式，用于：
- 降低图像噪声
- 消除高频细节
- 生成更自然、更平滑的图像
核心思想：
> 距离中心越近的像素权重越大，越远权重越小。

因此，它比均值滤波平滑得自然，不容易破坏边缘。
#### 2. 为什么使用高斯函数？

##### 卷积可分离（高效）

2D 高斯核可以分解为两个 1D 核：

$G(x,y)=G(x) G(y)$

计算复杂度从$O(n2)$ 降为$O(2n)$。

大部分 CV 库（OpenCV 等）实际都是用 **两次 1D 卷积** 来实现高斯滤波。

##### 平滑效果自然

均值滤波权重一致 → 模糊明显  
高斯权重指数衰减 → 平滑自然，不生硬
##### 数学性质优秀

在“最小均方误差”意义下，高斯是 **最佳平滑核**。

#### 3. **高斯函数（2D）**

$G(x,y) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2 + y^2}{2\sigma^2}}​$

- $σ$：控制模糊程度
- 越远的像素权重越低

#### 4. 高斯滤波的卷积操作

对图像$I$使用高斯核$G$：

$I'(x,y)=\sum_{u}\sum_{v}G(u,v)\,I(x-u,y-v)$

注意：  
深度学习框架通常执行的是互相关，但由于高斯核对称，效果相同。

#### 5. 常见高斯核示例

最经典的 3×3 高斯核（σ≈1）：
$$
\frac{1}{16} \begin{bmatrix} 1 & 2 & 1\\ 2 & 4 & 2\\ 1 & 2 & 1 \end{bmatrix}​​
$$
特点：

- 中心权重最大（4）
- 邻近较大（2）
- 四角最小（1）
#### 6. 高斯滤波的作用

| 作用      | 说明                 |
| ------- | ------------------ |
| 去噪      | 对随机噪声特别有效          |
| 平滑图像    | 比均值滤波自然得多          |
| 边缘检测前处理 | Canny、Sobel 等都依赖它  |
| 多尺度分析   | SIFT、DoG、LoG 都基于高斯 |

##### **高斯的自卷积**

与自身的卷积是另一种高斯函数
用宽度为$\sigma$的高斯卷积两次=用宽度为$\sqrt{ 2 }\sigma$的高斯卷积一次
两个高斯函数的卷积为一新的高斯函数，新高斯函数的方差为原来两个高斯函数方差的和

# Chapter2 边缘检测
边缘是图像强度函数中变化迅速的地方

## 图像导数 Image Derivitatives
图像是离散的，不能对图像直接连续求导，所以用差分近似

### **梯度 Gradiant**
梯度是最常用的图像一阶导数
$∇f=[\frac{∂f}{∂x}, \frac{∂f}{∂y}​]$
- $\frac{\partial I}{\partial x}$​：水平亮度变化
- $\frac{\partial I}{\partial y}$：垂直亮度变化
梯度指向强度增加最快的方向

边缘强度由梯度大小给出：
$∣∣∇f∣∣=\sqrt{ (\frac{∂f}{∂x})^2+(\frac{∂f}{∂y})^2 }$

梯度方向：
$\theta = \tan^{-1}\left(\frac{\partial I / \partial y}{\partial I / \partial x}\right)$

- 梯度最大处就是边缘
- 梯度方向与边缘垂直

## 噪声的影响
喊噪图像会使求导之后看不出导数最大值，即边缘在哪儿
因此需要先进行平滑处理，再求导

通常是使用高斯平滑

## 一维高斯及其导数
![[Pasted image 20251209141511.png|350]]
一维高斯函数：

$G_{\sigma}(x) = \frac{1}{\sqrt{2\pi}\sigma} e^{-\frac{x^2}{2\sigma^2}}$

$\sigma$：标准差，控制曲线宽度
$x$：一维空间位置
**性质**：
- 归一化：$\int_{-\infty}^{\infty} G(x) dx = 1$
- 平滑作用：卷积可抑制噪声
- 低通滤波器：保留低频，抑制高频

导数：

$G_{\sigma}'(x) = -\frac{x}{\sigma^3 \sqrt{2\pi}} e^{-x^2/(2\sigma^2)}$
$G_{\sigma}^{\prime}(x)=\frac{d}{dx}G_{\sigma}(x)=-\frac{1}{\sigma}\left(\frac{x}{\sigma}\right) G_{\sigma}(x)$

**作用与特点**：
- 用于边缘检测：梯度最大处即边缘
- 梯度滤波器：平滑后计算灰度变化
- 零点在 x=0
- 左右正负对称，积分为 0（高通性质）
- 卷积 `I * G'` 在灰度变化处产生峰值，标记边缘
## 二维高斯及其导数
![[Pasted image 20251209141631.png|200]]
二维高斯函数：

$G_{\sigma}(x, y) = \frac{1}{2\pi \sigma^2} e^{-\frac{x^2 + y^2}{2\sigma^2}}$

$x, y$：二维空间坐标    
$σ$：标准差，控制高斯曲面宽度
**性质**：
- 归一化：$\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} G(x, y) \, dx \, dy = 1$
- 平滑作用：卷积可抑制图像噪声
- 低通滤波器：保留低频信息，抑制高频信息
- 对称性：关于中心点 (0,0) 对称

二维高斯的导数：
![[Pasted image 20251209142720.png|300]]
$\frac{\partial}{\partial x}G_{\sigma}(x, y)$

**作用与特点**：
- 用于边缘检测和梯度计算
- 对应图像在 x 或 y 方向的灰度变化
- 零点在 x=0 或 y=0，左右/上下正负对称
- 积分为 0，属于高通性质
- 卷积 `I * G_x` 和 `I * G_y` 可以得到图像在 x、y 方向的梯度，用于边缘检测

## Sobel算子
### 算子的概念

算子是一种**从一个函数映射到另一个函数的映射规则**
在图像处理里，图像被视为 **二维函数** $I(x,y)$  
所以算子是：
> 对图像进行某种计算、变换、过滤、增强的“操作规则”

如kernel就是一种算子

### Sobel算子

Sobel 是一种经典的 **一阶梯度边缘检测算子**，本质是：  
**一阶导数 + 平滑（弱平滑）叠加的卷积核**

其目标：估计图像的 x 与 y 方向梯度

### 水平方向（检测垂直边缘）：
$$
S_{x}=\frac{1}{8}\begin{bmatrix}
-1 & 0 & 1 \\
-2 & 0 & 2 \\
-1 & 0 & 1
\end{bmatrix}
$$
### 垂直方向（检测水平边缘）：
$$
S_{y}=\frac{1}{8}\begin{bmatrix}
-1 & -2 & -1 \\
0 & 0 & 0 \\
1 & 2 & 1
\end{bmatrix}
$$
### 梯度计算

$I_{x}​=I∗G_{x}​,I_{y}​=I∗G_{y}$​

梯度幅值：

$M= \sqrt{I_x^2 + I_y^2}​​$

梯度方向：

$θ= \tan^{-1}\left(\frac{I_y}{I_x}\right)$

### 优点
- 简单、快速
- 对噪声有微弱平滑效果（因为核包含权重 1-2-1）
- 适合实时应用
### 缺点
- 只能检测一阶边缘，易受噪声影响（比 Canny 差）
- 边缘定位不够精准
- 3×3 核无法捕捉大尺度结构
## Canny算子
Canny 被称为 **最优边缘检测算子**，包含多个步骤，是一种完整的边缘检测流程，而非单一卷积核

Canny 的目的：  
**检测到尽量多的真边缘、边缘定位准确、响应唯一（抑制伪边缘）**

### **Canny算子的四个步骤**

**step1:用高斯函数过滤图像(高斯平滑)**
$Is​=I∗Gσ​$
用于抑制噪声，关键参数为标准差 $\sigma$
**step2:找到梯度的大小和方向**
计算图像中每个像素点的梯度和方向

通常采用 Sobel 近似导数：
$I_x, I_y$​
得到梯度幅值与方向：

$M = \sqrt{I_x^2 + I_y^2},\qquad \theta = \tan^{-1}\left(\frac{I_y}{I_x}\right)$

**step3:非极大值抑制**
沿着梯度方向，只保留局部最大值，去掉非边缘点，使边缘变细
**step4:连接和阈值化**
设两个阈值：
- 高阈值$T_H$：强边缘
- 低阈值$T_L$​：弱边缘（但可能是真的）

分类像素：
- $M > T_H$​：强边缘
- $T_L < M < T_H$​：弱边缘
- $M < T_L​$：非边缘

弱边缘只有在与强边缘相连时才保留，其他被抛弃
确保边缘连续性，减少噪声伪边缘的出现

### 优点
- 对噪声鲁棒（高斯滤波）
- 边缘定位精确（梯度 + NMS）
- 边缘连续性好（双阈值 + 滞后）
- 综合性能最佳
### 缺点
- 计算量比 Sobel 高
- 参数敏感（σ, 两个阈值）
- 不适合需要极快实时响应的场景

# Chapter3 重采样与插值
## 重采样 Resampling
重采样是指当图像发生缩放、旋转、透视等几何变化后，为新的像素网格重新计算像素值的过程

重采样分为两步：
1. **坐标映射**
2. **像素插值**
## 下采样 Downsampling
为了把图像缩小，需要选择性的丢弃一些像素
下采样的本质是**从原始像素网格中 “挑选” 或 “计算” 出更少的像素，组成新图像**

设原图大小为$H \times W$，下采样后我们希望得到：

$H' = \frac{H}{s},\quad W' = \frac{W}{s}$

其中$s > 1$为下采样因子

### 下采样的核心问题：**混叠alias**
如果不先低通滤波，缩小可能出现摩尔纹：
> 高频内容被错误映射到低频
> 原始图像的高频信息（细节）的频率超过了下采样后图像的 “奈奎斯特频率”（即目标分辨率能承载的最高频率），这些高频信息会被错误地折叠成低频噪声

解决方法：**先滤波，后采样**
低通滤波是抗混叠的唯一有效手段，一般使用高斯预滤波，先模糊掉高频信息，再下采样

### 下采样的典型应用
1. 图像金字塔构建：如高斯金字塔，每一层都是上一层的下采样结果，用于多尺度特征提取（如 SIFT、SURF 算法）。
2. 降低计算成本：在目标检测、图像分割等任务中，先对图像下采样，再进行特征计算，大幅提升处理速度。
3. 图像压缩：通过减少像素数量，降低图像的存储和传输体积（如网络图片的缩略图生成）。
4. 噪声去除：结合滤波的下采样，在缩小图像的同时平滑噪声。

### 走样

**奈奎斯特采样定理**：要无失真地还原一个信号，采样频率必须至少是信号最高频率的 **2 倍**

- 发生在当采样率不足以捕捉图像大量细节的时候。
- 一次走样可能给你错误的图像或者信号
为了防止走样:
- 采样率 ≥ 2 * 图像的最高频率
- 另一种说法是: ≥ 每周期两次采样
该最小采样率为奈奎斯特采样率

## 上采样 Upsampling
上采样就是把图像放大，让它分辨率变高，但图像本身没有新增真实细节，主要依靠插值算法
设原图大小为$H \times W$，上采样后我们希望得到：

$H' = \frac{H}{s},\quad W' = \frac{W}{s}$

其中$s < 1$为下采样因子

### 插值的几种方法
1. **最近邻插值**
	规则：最靠近哪个像素，就用哪个像素填
	
	 特点：
	 - 快
    - 锯齿严重
	- 用于像素风格图像（比如 Minecraft、像素画）
	
2. **线性插值**
	- 双线性插值
		规则：新像素取周围 4 个像素的加权平均
		
		特点：
		- 平滑
	    - 比较自然
	    - 用于一般放大
	    - 计算消耗适中
	- 双三次插值
		规则：考虑周围 16 个像素的加权平均
		
		特点：
		- 更锐利，更自然
	    - 图像缩放软件（PS）常用
	    - 计算消耗大
3. **高斯重构**
	高斯重构是一种高斯滤波的插值方法
	核心用于高斯图像金字塔的上采样还原
	目的是在放大图像的同时保持高斯金字塔的尺度一致性，避免引入额外噪声
4. **深度学习插值**
	基于深度学习模型（如 SRCNN、ESRGAN），从大量图像数据中学习 “低分辨率→高分辨率” 的映射规律，生成逼真的细节
![[c39f2a46-0c8f-4729-89af-2058b1c72379.png|450]]

# Chapter4 局部特征与Harris角点检测
## 局部特征
局部特征是图像中**局部区域内的显著结构**，这些结构不受图像整体变换（如平移、旋转、缩放、光照变化）的影响，能够作为区分不同图像或同一图像不同位置的 “指纹

例如：
- 角点（corners）
- 边缘（edges）
- 斑点（blob）
- 关键点（keypoints）
- 特征描述子（SIFT、ORB 等）

局部特征的作用是：
- 让计算机辨认图像中的重要部分
- 在不同图像之间建立匹配关系
- 用于目标检测、SLAM、三维重建、图像拼接等

局部特征的特点

局部性
- 特征是局部的，因此对遮挡和杂乱场景具有鲁棒性
数量大
- 一张图中有成百上千的局部特征
判别性
- 可以区分大量的目标
效率
- 可以获得实时效果

## Harris角点
核心思想是：**角点是局部窗口内，向任意方向移动都会导致灰度值发生剧烈变化的区域**
### 核心假设与直观理解
- 对于**平坦区域**：窗口向任意方向移动，灰度值变化很小，不是特征
- 对于**边缘区域**：窗口沿边缘方向移动，灰度值变化小；垂直边缘方向移动，灰度值变化大，是半特征
- 对于**角点区域**：窗口向任意方向移动，灰度值都会发生剧烈变化，是好特征

Harris 量化了“任意方向上的强度变化”，来判断角点

### **数学推导**
![[Pasted image 20251209195742.png|200]]
假设以$(u,v)$移动窗口$W$
通过平方差之和(SSD)来比较变化前后的每个像素
SSD 误差E(u,v)定义如下:

$E(u,v)=\sum_{x,y} w(x,y)\,\bigl[I(x+u,y+v)-I(x,y)\bigr]^2$

- $I(x,y)$是原始图像在 $(x,y)$处的灰度值；
- $(I(x+u,y+v)$) 是窗口移动后在 $(x+u,y+v)$处的灰度值；
- $W(x,y)$是高斯权重，作用是让窗口中心像素的贡献更大，边缘像素的贡献更小，提升鲁棒性

对小位移，泰勒展开：
$$
I(x+u, y+v) \approx I(x,y) + I_x u + I_y v
$$
$$
\begin{aligned}
I(x+u, y+v) &\approx I(x, y) + \frac{\partial I}{\partial x}u + \frac{\partial I}{\partial y}v \\
&\approx I(x, y) + \left[I_{x} \quad I_{y}\right] \begin{bmatrix} u \\ v \end{bmatrix}
\end{aligned}
$$

其中简写：$I_{x} = \frac{\partial I}{\partial x}，I_{y} = \frac{\partial I}{\partial y}$
再将上式代入$E(u,v)=\sum_{x,y} w(x,y)\,\bigl[I(x+u,y+v)-I(x,y)\bigr]^2$

$$
\begin{aligned}
E(u, v) &= \sum_{(x, y)\in W} \left[I(x+u,y+v)-I(x,y)\right]^{2} \\
&\approx \sum_{(x, y)\in W} \left[I(x, y)+I_{x}u+I_{y}v-I(x,y)\right]^{2} \\
&\approx \sum_{(x, y)\in W} \left[I_{x} u+I_{y}v\right]^{2}
\end{aligned}
$$
$$
\begin{aligned}
E(u, v) &\approx \sum_{(x, y)\in W}\left[I_{x} u+I_{y}v\right]^{2}\\
&\approx A u^{2}+2B u v+C v^{2}
\end{aligned}
$$
$$
A=\sum_{(x, y)\in W}I_{x}^{2}\quad B=\sum_{(x, y)\in W}I_{x}I_{y}\quad C=\sum_{(x, y)\in W}I_{y}^{2}
$$
因此, E(u,v) 可以局部近似为一个平方误差函数
E(u,v) 可以通过一个二次型进行局部近似
$$
\begin{aligned}
E(u, v) &\approx A u^{2} + 2B u v + C v^{2} \\
&\approx \begin{bmatrix} u & v \end{bmatrix}
        \begin{bmatrix} A & B \\ B & C \end{bmatrix}
        \begin{bmatrix} u \\ v \end{bmatrix}
\end{aligned}
$$
$$
A = \sum_{(x, y)\in W} I_{x}^{2}\quad B = \sum_{(x, y)\in W} I_{x} I_{y}\quad C = \sum_{(x, y)\in W} I_{y}^{2}
$$
其中
$$
M = \sum_{(x,y) \in W} 
\begin{bmatrix}
I_x^2 & I_x I_y \\
I_x I_y & I_y^2
\end{bmatrix}
=
\begin{bmatrix}
A & B \\
B & C
\end{bmatrix}
$$
$M$叫做结构张量或者二阶矩矩阵

我们可以将$M$可视化为一个椭圆。二维空间中椭圆最基本的形式是
$$
\frac{x^{2}}{a^{2}}+\frac{y^{2}}{b^{2}}=1
$$
将上面的方程写成矩阵的形式：
$$
\left[\begin{array}{l}
x \\
y
\end{array}\right]^{T}
\left[\begin{array}{cc}
1 / a^{2} & 0 \\
0 & 1 / b^{2}
\end{array}\right]
\left[\begin{array}{l}
x \\
y
\end{array}\right] = x^{T} A x = 1
$$
#### 矩阵特征值特征向量回顾
一个矩阵 A 的特征向量是一个满足下式的向量 x
$$Ax=\lambda x$$
其中标量 λ是 x 对应的特征值
特征值可以通过求解下式得到：
$$ \det(A-\lambda I)=0 $$
在Harris角点的计算中$A=W$是一个2×2的矩阵
$$ \det\left[\begin{array}{cc}h_{11}-\lambda &h_{12}\\h_{21} &h_{22}-\lambda\end{array}\right]=0 $$
解如下：
$$ \lambda_{\pm}=\frac{1}{2}\left[\left(h_{11}+h_{22}\right)\pm\sqrt{4h_{12}h_{21}+\left(h_{11}-h_{22}\right)^{2}}\right] $$
只要知道$\lambda$，就可以通过求解下式得到x,y
$$ \left[\begin{array}{cc}h_{11}-\lambda &h_{12}\\h_{21} &h_{22}-\lambda\end{array}\right]\left[\begin{array}{c}x\\y\end{array}\right]=0 $$

椭圆的两轴分别是 $x$ 轴及 $y$ 轴，轴长分别是 $2a$ 以及 $2b$。其方程为：

$$
\frac{x^2}{a^2} + \frac{y^2}{b^2} = 1
$$

上面这个方程写成矩阵的形式是这样子的：

$$
\begin{bmatrix} x \\ y \end{bmatrix} ^{T} 
\begin{bmatrix} 1 / a^{2} & 0 \\ 0 & 1 / b^{2} \end{bmatrix}
\begin{bmatrix} x \\ y \end{bmatrix} = x^{T} A x = 1
$$

| 特征值 | 归一化特征向量 |
| :--- | :--- |
| $\displaystyle \lambda_{1}=1 / a^{2}$ | $\displaystyle \mu_{1} = \begin{bmatrix} 1 \\ 0 \end{bmatrix}$ |
| $\displaystyle \lambda_{2}=1 / b^{2}$ | $\displaystyle \mu_{2} = \begin{bmatrix} 0 \\ 1 \end{bmatrix}$ |

**几何意义**：矩阵的特征值是半轴长度的平方倒数，特征向量方向对应长短轴的方向

更一般的椭圆方程：

$$
a x^{2}+2 b x y+c y^{2}=1
$$

对应矩阵形式：

$$
\left[\begin{array}{l}
x \\
y
\end{array}\right]^{T}
\left[\begin{array}{ll}
a & b \\
b & c
\end{array}\right]
\left[\begin{array}{l}
x \\
y
\end{array}\right]=x^{T} A x=1
$$

具体示例：

$$
5 x^{2}+8 x y+5 y^{2}=1
$$

$$
\left[\begin{array}{l}
x \\
y
\end{array}\right]^{T}
\left[\begin{array}{ll}
5 & 4 \\
4 & 5
\end{array}\right]
\left[\begin{array}{l}
x \\
y
\end{array}\right]=x^{T} A x=1
$$
特征值：

$$ \lambda_{1}=1, \quad \lambda_{2}=9 $$

归一化特征向量：

$$ \mu_{1}=\left[\begin{array}{c}1 / \sqrt{2} \\ -1 / \sqrt{2}\end{array}\right], \quad \mu_{2}=\left[\begin{array}{c}1 / \sqrt{2} \\ 1 / \sqrt{2}\end{array}\right] $$


根据特征值法将矩阵正交分解对角化：

$$
A = Q \Lambda Q^{-1} = Q \Lambda Q^{T} =
\left[\begin{array}{cc}
1/\sqrt{2} & 1/\sqrt{2} \\
-1/\sqrt{2} & 1/\sqrt{2}
\end{array}\right]
\left[\begin{array}{cc}
1 & 0 \\
0 & 9
\end{array}\right]
\left[\begin{array}{cc}
1 / \sqrt{2} & -1 / \sqrt{2} \\
1 / \sqrt{2} & 1 / \sqrt{2}
\end{array}\right]
$$

二次型：

$$
\begin{aligned}
P(f) &= x^{T} A x \\
     &= x^{T} Q \Lambda Q^{T} x \\
     &= (Q^{T} x)^{T} \Lambda (Q^{T} x) \\
     &= 1 \left( \frac{x-y}{\sqrt{2}} \right)^{2} + 9 \left( \frac{x+y}{\sqrt{2}} \right)^{2}
\end{aligned}
$$
我们可以将$W$可视化为一个椭圆，椭圆的轴的长度由$W$的特征值决定，轴的方向由 H 的特征向量决定
![[Pasted image 20251209213526.png|300]]

## Harris角点检测的数学公式

$\begin{aligned}E(u, v) &\approx \begin{bmatrix} u & v \end{bmatrix}\begin{bmatrix} A & B \\ B & C \end{bmatrix}\begin{bmatrix} u \\ v\end{bmatrix}\end{aligned}$

记$\begin{bmatrix} A & B \\ B & C \end{bmatrix}$为$H$

![[Pasted image 20251209214039.png|200]]

$\begin{aligned}H x_{\max} &= \lambda_{\max} x_{\max} \\H x_{\min} &= \lambda_{\min} x_{\min}\end{aligned}$

H 的特征值和特征向量
• 定义具有最小和最大误差变化的移动方向
• $x_{\max}$= E 的最大变化方向
• $\lambda_{\max}$ =  $x_{\max}$方向上的变化量
• $x_{\min}$ = E 的最小变化方向
• $\lambda_{\min}$ = $x_{\min}$ 方向上的变化量

Harris 矩阵 H 的特征向量对应 “窗口变化的方向”，特征值对应 “变化的幅度”—— 通过这两个量的大小，就能区分角点、边缘和平坦区域

为了判断角点，**我们希望所有方向上的较小移动都能够让E(u,v) 的值较大**
对于所有的单位向量$[u,v]$，$E(u,v)$ 的最小值都应该大最小值就是 H 小一些的那个特征值$\lambda_{\min}$
也就是我们希望找到$\lambda_{\min}$比较大的点，即角点

- 若$\lambda_{\text{min}}$很大（意味着 “所有方向的移动，灰度变化都不小”）→ 是**角点**
- 若$\lambda_{\text{min}}$很小、$\lambda_{\text{max}}$很大→ 是**边缘**（只有一个方向变化大）
- 若$\lambda_{\text{max}}$和$\lambda_{\text{min}}$都很小→ 是**平坦区域**

**角点检测总结**
• 计算图像中每个点的梯度
• 生成梯度矩阵H
• 计算特征值.
• 寻找具有较大响应的点($\lambda_{min}$ > 阈值)
• 选择$\lambda_{min}$是局部最大值的点作为特征

## Harris算子
$\lambda_{\min}$ 是用于角点检测的“Harris算子”的变量

$f = \frac{\lambda_1 \lambda_2}{\lambda_1 + \lambda_2} = \frac{\text{determinant}(H)}{\text{trace}(H)}$

- $\text{determinant}(H)$：是 Harris 矩阵H的**行列式**，等于特征值的乘积$\det(H) = \lambda_1 \lambda_2$
- **trace 是对角线之和**，即 $\text{trace}(H) = h_{11} + h_{22} = \lambda_1+ \lambda_2$
- 该式与 $\lambda_{\min}$ 非常近似但是计算更简单（没有平方根）

$\lambda_{\pm} = \frac{1}{2} \left[ (h_{11} + h_{22}) \pm \sqrt{4h_{12}h_{21} + (h_{11} - h_{22})^2} \right]$(上面推到里有平方根的形式)

该式被称作“**Harris角点检测器**”或者“**Harris算子**

### Harris算子的响应函数
$$
\begin{aligned}
C &= \det(H) - k \cdot [\operatorname{trace}(H)]^{2} \\
  &= \lambda_{1} \lambda_{2} - k \left( \lambda_{1} + \lambda_{2} \right)^{2}, \quad k=0.04
\end{aligned}
$$
- $\det(H)$和$\operatorname{trace}(H)$上面已经讲过
- k为经验常数，通常在0.04~0.06，用来平衡行列式和迹的权重

这个响应函数的目的是**区分 “角点、边缘、平坦区域”**：
- 对于**角点**：$\lambda_1$和$\lambda_2$都很大→ 行列式$\lambda_1\lambda_2$会远大于$k(\lambda_1+\lambda_2)^2$→ 响应函数值 C 很大且为正
- 对于**边缘**：一个特征值大、一个特征值小→ 行列式$\lambda_1\lambda_2$较小→ 响应函数值 C 为负
- 对于**平坦区域**：$\lambda_1$和$\lambda_2$都很小→ 行列式和迹都接近 0→ 响应函数值 C 接近 0

**注意**:
- **k的值越小，检测子越敏感**
- **只有当$\lambda_1$和$\lambda_2$同时取得最大值时，C才能取得较大值**

## 导数加权
在实际应用中，简单窗口$W$效果并不好
$H=\sum_{(x, y)\in W}\left[\begin{array}{cc}I_{x}^{2} & I_{x}I_{y} \\I_{x}I_{y} & I_{y}^{2}\end{array}\right]$
我们会根据距离中心像素的的距离对导数进行加权（一般是高斯加权）
$H=\sum_{(x, y)\in W} w_{x,y} \left[\begin{array}{cc}I_{x}^{2} & I_{x}I_{y} \\I_{x}I_{y} & I_{y}^{2}\end{array}\right]$

## Harris检测器
二阶矩矩阵
$\mu\left(\sigma_{I},\sigma_{D}\right)=g\left(\sigma_{I}\right) *\left[\begin{array}{cc}I_{x}^{2}\left(\sigma_{D}\right) &I_{x}I_{y}\left(\sigma_{D}\right)\\I_{x} I_{y}\left(\sigma_{D}\right) &I_{y}^{2}\left(\sigma_{D}\right)\end{array}\right]$
- $μ(σ_{I},σ_{D}​)$表示尺度空间**平滑结构张量**
- $g(σ_{I})$是尺度为$σ_{I}$的高斯平滑核
- ∗表示卷积运算
- 矩阵是结构张量的基本形式：
    - $I_{X}​(σ_{D})$和 $I_{y}(σ_{D})$是在尺度 $σ_{D}​$下计算的图像梯度    
    - 矩阵元素为梯度平方和交叉乘积

检测步骤
1. 图像导数
2. 导数平方
3. 高斯滤波
4. 角点函数-特征值都很强
5. 非极大值抑制

# Chapter5 特征不变性
Feature Invariance
## 不变性与等变性
### 图像变换的两类场景
- 几何变换
	- 旋转
	- 缩放
- 光学变换
	- 亮度变化
### 不变性与等变性
- **不变性**：图像变换但角点位置不变
		图像变换后，特征（如角点）的**位置 / 属性保持不变**（适用于光学变换）
- **等变性**：如果我们有同一张图像的两个变换版本，特征应该能在对应的位置上被检测到
		图像变换后，特征能在**对应位置**被检测到（适用于几何变换，比如图像旋转后，角点仍在旋转后的对应位置）

## Harris检测器的不变性分析

### 表现好的场景：

#### **平移变换（图像平移）**

**对于平移：角点位置是等变的**
原因：Harris 算法的核心是 “导数 + 窗口函数”，平移不改变像素的相对变化（导数）和窗口覆盖的区域特征，所以角点能在对应位置被检测到，导数和窗口函数是等变的

#### **旋转变换（图像旋转）**

**对于旋转，角点位置是等变的**
原因：Harris 算法依赖图像的二阶矩矩阵，旋转时二阶矩椭圆会跟着旋转，但椭圆的形状（由特征值决定）不变 —— 特征值是判断 “角点 / 边缘 / 平坦区域” 的核心，所以旋转后仍能正确识别角点

#### **亮度仿射变换**

**对于亮度仿射变化，角点的位置是部分不变的**
对于亮度仿射变化：$I=aI+b$
拆解：
- 亮度偏移（$I→I+b$）：完全不变。因为导数计算的是 “像素差值”，加常数 b 不改变差值（比如原像素 10 和 20，加 b 后 10+b 和 20+b，差值仍为 10）；
- 亮度缩放（$I→aI$）：导数会跟着缩放（差值变为 a× 原差值），但 Harris 算法的核心指标（R 值）是特征值的组合（R=det (M)-k (trace (M))²），缩放后 R 值的相对大小不变，仍能通过阈值筛选角点，所以整体可认为 “部分不变”
![[Pasted image 20251210184205.png|250]]![[Pasted image 20251210184231.png|200]]
### 表现不好的场景
#### **缩放变换**
**对于缩放变换，角点的位置既不是不变的，也不是等变的**

直观例子：一张图中的 “小角点”，放大后可能变成 “平坦区域”（因为窗口尺寸固定，放大后窗口内的像素变化变小）；反之，放大后的 “角点”，缩小后可能被窗口覆盖，无法检测
核心问题：Harris 算法没有 “尺度自适应” 能力 —— 窗口尺寸固定，无法匹配不同大小的特征

## 尺度不变性检测
针对Harris检测无法很好应对缩放的情况，因为尺度不变性检测

**寻找使特征响应最大的尺度**（即 “特征尺度”），让算法能自动匹配不同大小的特征（角点、Blob 团块等）

### **LoG 高斯拉普拉斯**
![[Pasted image 20251210192626.png|200]]
公式：
$LoG=\nabla^{2} g=\frac{\partial^{2} g}{\partial x^{2}}+\frac{\partial^{2} g}{\partial y^{2}}$

LoG = 高斯滤波（G）的二阶导数（∇²G）

推导：
高斯函数：$G(x,y)=\frac{1}{2\pi\sigma^2}e^{-\frac{x^2+y^2}{2\sigma^2}}$

$\frac{\partial G}{\partial x}=\left(-\frac{1}{2 \pi \sigma^{4}}\right) x e^{-\frac{x^{2}+y^{2}}{2 \sigma^{2}}}$

$\frac{\partial G}{\partial y}=\left(-\frac{1}{2 \pi \sigma^{4}}\right) y e^{-\frac{x^{2}+y^{2}}{2 \sigma^{2}}}$

$\frac{\partial^{2} G}{\partial y^{2}}=\left(-\frac{1}{2 \pi \sigma^{4}}\right)\left(1-\frac{x^{2}}{\sigma^{2}}\right) e^{-\frac{x^{2}+y^{2}}{2 \sigma^{2}}}$

$\frac{\partial^{2} G}{\partial y^{2}}=\left(-\frac{1}{2 \pi \sigma^{4}}\right)\left(1-\frac{y^{2}}{\sigma^{2}}\right) e^{-\frac{x^{2}+y^{2}}{2 \sigma^{2}}}$

最终：

$\text{LoG} = \frac{1}{\sigma^{4}} \cdot \frac{x^{2}+y^{2}-2\sigma^{2}}{2\pi\sigma^2} e^{-\frac{x^{2}+y^{2}}{2\sigma^{2}}}=\nabla^{2} g=\frac{\partial^{2} g}{\partial x^{2}}+\frac{\partial^{2} g}{\partial y^{2}}$

**核心原理**：
1. 高斯滤波的 σ（标准差）决定 “尺度”：σ 越小，滤波越精细（对应小尺度特征）；σ 越大，滤波越粗糙（对应大尺度特征）；
2. LoG 的 “过零点”（二阶导数由正变负或反之的点）对应图像边缘；
3. 响应峰值匹配特征尺度：对于一个尺寸固定的特征（如半径 r 的圆），当 LoG 的 σ 与特征尺寸匹配时（理论推导：$σ=r/\sqrt{ 2 }$），LoG 的响应（输出值）最大 —— 这就是 “自动选择尺度” 的核心：遍历不同 σ，找到响应最大的 σ，即为该特征的 “特征尺度”。

**LoG的尺度归一化**
归一化的原因：LoG 的响应幅值会随 σ 增大而减小（因为 σ 越大，高斯滤波越平滑，二阶导数的差值越小）（对于稳定信号，响应的最大幅值是和标准差成反比的），如果不修正，大尺度特征的响应会被低估，无法正确找到峰值

尺度归一化：在G的二阶导上乘以$\sigma^2$：

$L o G_{n o r m}=\sigma^{2}\left(\frac{\partial^{2} G}{\partial x^{2}}+\frac{\partial^{2} G}{\partial y^{2}}\right)$

归一化后，不同尺度特征的响应幅值不受 σ 影响，仅由特征本身和 σ 的匹配度决定，确保能正确找到每个特征的最优尺度
不同尺度响应不同，当高斯函数尺度与Blob直径一致时，响应最大
### **DoG 高斯差分**
LoG 的问题是 “计算复杂度高”（二阶导数计算繁琐），我们可以用DoG高斯差分近似代替LoG，核心是 “用近似替代精确，降低计算量，不影响极值检测”

通过对两个相邻高斯尺度空间的图像相减，得到DOG的响应值图像
![[Pasted image 20251210194830.png|200]]

公式：

$D o G=G_{\sigma_{1}}-G_{\sigma_{2}}$

$\begin{array} {r}{\frac {\partial G}{\partial \sigma }\approx \frac {G(x,y,k\sigma )-G(x,y,\sigma )}{k\sigma -\sigma }}\end{array}$

$L_{norm }=\sigma^{2}\left(G_{x x}(x, y, \sigma)+G_{y y}(x, y, \sigma)\right)=\sigma \frac{\partial G}{\partial \sigma}$

理论推导表明，DoG 是 LoG 的近似：$\frac{\partial G}{\partial \sigma} \approx \frac{G(k\sigma) - G(\sigma)}{k\sigma - \sigma}$，而归一化 LoG 与 G 对 σ 的偏导数成正比$LoG_{norm} = \sigma \cdot \frac{\partial G}{\partial \sigma}$。

因此，DoG 和 LoG 的波形相似，仅幅值不同 —— 而极值点（响应峰值）的位置完全一致，不影响尺度选择和特征检测

因为 k−1 是常量，不影响函数的极值点。DoG算子和LoG算子具有类似的波形，仅仅是幅 度不同，不影响极值点的检测，而DoG算子计算复杂度更低，一般使用DoG代替LoG算子

优点：高斯差分计算量小，仅需要两次求两次高斯再相减

# Chapter6 特征描述子与匹配

## 局部特征：主要因素
1. 检测：确认特征点
		从图像中找到稳定、独特的特征点（如 Harris 角点、DoG 尺度不变特征点）
2. 描述：围绕每个特征点提取特征向量特征描述
		为每个特征点生成一个 “特征向量”（描述子），用数值形式刻画特征点周围的图像信息（比如梯度、纹理）
3. 匹配：确定两个视角特征描述的对应
		计算不同图像中特征描述子的相似度，找到同一物理点在不同视角下的对应特征点

**检测是基础，描述是核心，匹配是目标**—— 只有描述子具备 “不变性”（抗图像变换）和 “可判别性”（区分不同特征），才能实现精准匹配

## 特征描述子
### **不变性**
即使图像变换，描述子也不应当改变

图像经过变换（几何变换：平移、旋转、缩放；光学变换：亮度 / 对比度变化）后，同一特征点的描述子应保持一致（或差异极小）
###  **可判别性**
对于每一个特征点，描述子应当具有唯一性

不同特征点的描述子应差异显著，避免 “张冠李戴”。比如：A 角点和 B 角点的描述子向量应距离足够远，确保匹配时不会混淆

| 变换类型               | 核心要求                          |
| ------------------ | ----------------------------- |
| 几何变换（平移 / 旋转 / 缩放） | 完全不变性（最基础要求）                  |
| 3D 旋转 / 仿射变换       | 部分不变性（如 SIFT 可抗 60° 左右 3D 旋转） |
| 亮度 / 对比度变化         | 鲁棒性（允许描述子小幅波动，但不影响匹配）         |
## 经典特征描述子
### **MOPS描述子**
MOPS 是 “直观且易理解” 的描述子，核心思路是 “通过预处理消除变换影响，再提取简单特征”，步骤清晰：
1. 围绕特征点取 40×40 像素的方形窗口（覆盖特征点周围的局部信息）
2. **缩放归一化**：将窗口缩放到 8×8（1/5 尺寸），消除缩放变换的影响（预滤波避免缩放时失真）
3. **旋转归一化**：找到窗口的主导方向（由 Harris 检测器的二阶矩矩阵特征向量，或梯度方向决定），将窗口旋转到水平方向，消除旋转变换的影响
4. **亮度归一化**：减去窗口内像素的均值（消除亮度偏移），除以标准差（消除对比度缩放）—— 这就是 MOPS 能抗亮度 / 对比度变化的关键

最终生成 8×8=64 维的特征向量，优点是简单、计算快，缺点是鲁棒性有限（对复杂变换如仿射变形、大角度 3D 旋转适应性差）

### **SIFT描述子**
SIFT 是 David Lowe 提出的工业级描述子，至今仍是特征匹配的 “黄金标准” 之一，核心是 “用梯度方向直方图刻画局部特征”，鲁棒性极强：

核心思想：
1. 围绕检测的特征点取$n×n$方形窗
2. 对每个像素计算边缘方向（梯度角度）
3. 扔掉较弱的边缘（对梯度幅值进行阈值判断）
4. 生成保留边缘方向的直方图

**步骤**：
1. 计算梯度值和角度
		对特征点周围的图像块（如 16×16 窗口），每个像素计算梯度：
		梯度幅值（强度）：$G = \sqrt{G_x^2 + G_y^2}$，$G_x$是 x 方向导数，$G_y$是 y 方向导数；
		梯度方向：$\theta = tan^{-1}(\frac{G_{y}}{G_{x}})$（范围 0~2π）
2. 将角度值进行等分
		将 0~2π 的方向划分为 8 个区间（如 0~45°、45°~90° 等），便于统计直方图
3. 利用高斯核对梯度进行权重计算
		也就是说该像素周围像素的权重由两个值决定：一个是本身梯度大小、  第二个是离考察像素点的距离
		用高斯核函数给每个像素的梯度幅值加权 —— 距离特征点越近的像素，权重越大，突出核心区域的影响（减少边缘像素的干扰）
4. 建立一个梯度方向直方图，每次累加的值就是它的权重
		选择梯度值最大的那个角度分量作为主方向，获得更具有旋转鲁棒性的描述方法
		将 16×16 窗口划分为 4×4=16 个小窗口（每个 4×4 像素），每个小窗口统计 8 个方向的梯度直方图，得到 16×8=128 维特征向量（这是 SIFT 的标准维度）
5. 主方向校准
		在全局梯度直方图中，找到峰值对应的方向作为 “主方向”，将所有梯度方向相对于主方向旋转（比如主方向是 30°，则每个像素的梯度方向减去 30°）—— 这样无论图像如何旋转，主方向始终作为参考，描述子保持不变
6. 亮度归一化
		将 128 维向量归一化（每个元素除以向量的 L2 范数），进一步增强对亮度和对比度变化的抵抗能力

SIFT的特点：
非常鲁棒的匹配技术  
- 能够处理视角的变化  
- 能够处理光照的显著变化  
- 相对快速——虽然很难达到实时, 但对中等图像尺寸的处理时间小于1s

## 特征匹配
有了描述子后，匹配的核心是 “定义相似度度量”，并筛选出可靠的匹配对

### 特征距离
距离越小，说明两个描述子越相似，对应特征点越可能是同一物理点

#### 简单方法：**L2距离**
$\|f_1 - f_2\| = \sqrt{\sum_{i=1}^{n} (f_{1i} - f_{2i})^2}$

缺点：容易出现 “歧义匹配”—— 比如 f1 的最优匹配 f2 和次优匹配 f2' 的距离都很小，无法区分真假，即对歧义匹配会给出小的距离值

#### 优化方法:**比值距离**

$\text{比值距离}=\frac{\|f_1 - f_2\|}{\|f_1 - f_2'\|}$

f2 是最优匹配，f2' 是次优匹配

优势：解决歧义匹配 —— 如果是真实匹配，最优匹配距离会远小于次优匹配距离（比值小，通常阈值设为 0.5）；如果是虚假匹配，最优和次优距离接近（比值大），可直接过滤

# Chapter7 几何变换

图像滤波：改变像素取值
图像形变：改变像素的空间坐标
## 旋转 Rotation
![[Pasted image 20251211191408.png|200]]
$R = \begin{bmatrix}\cos\theta & -\sin\theta \\\sin\theta & \cos\theta\end{bmatrix}$


$\begin{bmatrix}x' \\ y'\end{bmatrix}= R\begin{bmatrix}x \\ y\end{bmatrix}=\begin{bmatrix}\cos\theta \cdot x - \sin\theta \cdot y \\\sin\theta \cdot x + \cos\theta \cdot y\end{bmatrix}$

具体推导如下:

![[Pasted image 20251211191941.png|200]]
$OP = OP' = \sqrt{x^2 + y^2} = d$
$\sin\alpha = \frac{y}{d}, \quad \cos\alpha = \frac{x}{d}$
$\begin{aligned}\sin(\alpha + \theta) &= \frac{y'}{d} \\\cos(\alpha + \theta) &= \frac{x'}{d}\end{aligned}$
$\begin{aligned}x' &= x \cos\theta - y \sin\theta \\y' &= x \sin\theta + y \cos\theta\end{aligned}$

$\begin{bmatrix}x' \\y'\end{bmatrix}=\begin{bmatrix}\cos\theta & -\sin\theta \\\sin\theta & \cos\theta\end{bmatrix}\begin{bmatrix}x \\y\end{bmatrix}$
## 平移 Translation
![[Pasted image 20251211192143.png|200]]

$\left( \begin{array}{c}x' \\y' \\1\end{array} \right)=\left[ \begin{array}{ccc}1 & 0 & t_{x} \\0 & 1 & t_{y} \\0 & 0 & 1\end{array} \right]\left( \begin{array}{c}x \\y \\1\end{array} \right)=\left[ \begin{array}{cc}I_{2 \times 2} & T_{2 \times 1} \\0^{T} & 1\end{array} \right]\left( \begin{array}{c}x \\y \\1\end{array} \right)$

其中 $I_{2 \times 2} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$ 表示单位矩阵，而 $T_{2 \times 1} = \begin{bmatrix} t_x \\ t_y \end{bmatrix}$ 表示平移向量
## 刚体变换 Euclidean
![[Pasted image 20251211193130.png|200]]
$\left( \begin{array}{c}x' \\y' \\1\end{array} \right)=\left[ \begin{array}{ccc}\cos\theta & -\sin\theta & t_x \\\sin\theta & \cos\theta & t_y \\0 & 0 & 1\end{array} \right]\left( \begin{array}{c}x \\y \\1\end{array} \right)=\left[ \begin{array}{cc}R_{2\times 2} & T_{2\times 1} \\0^{T} & 1\end{array} \right]\left( \begin{array}{c}x \\y \\1\end{array} \right)$
旋转矩阵 $R_{2\times 2}$ 是正交矩阵（$RR^{T}=R^{T}R=I$）
**刚体变换增加均匀缩放，称为相似变换**

## 仿射变换 Affine
![[Pasted image 20251211193427.png|200]]

**相比刚体变换（旋转和平移），仿射变换除了改变目标位置，还改变目标的形状，但是会保持物体的“平直性（如图形中平行的两条线变换后依然平行）”**
$\left( \begin{array}{c}x' \\y' \\1\end{array} \right)=\left[ \begin{array}{cc}A_{2\times 2} & T_{2\times 1} \\0^{T} & 1\end{array} \right]\left( \begin{array}{c}x \\y \\1\end{array} \right)$
$A_{2\times 2} = \begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22}\end{bmatrix}$

## 投影变换（单应性变换）Projection
![[Pasted image 20251211193749.png|200]]
$\left( \begin{array}{c}x' \\y' \\1\end{array} \right)=\left[ \begin{array}{cc}A_{2\times 2} & T_{2\times 1} \\V^{T} & s\end{array} \right]\left( \begin{array}{c}x \\y \\1\end{array} \right)=H_{3\times 3}\left( \begin{array}{c}x \\y \\1\end{array} \right)$
$A_{2\times 2}$ 代表仿射变换参数，$T_{2\times 1}$ 代表平移变换参数
$V^{T}=[v_{1},v_{2}]$ 表示一种“变换后边缘交点”关系
$s$ 则是一个与 $V^{T}=[v_{1},v_{2}]$ 相关的缩放因子

单应性的直观含义：用 $[无镜头畸变]$的相机从不同位置拍摄 $[同一平面物体]$ 的图像之间存在单应性，可以用 $[投影变换]$表示

- 特点：适应不同视角的拍摄场景，比如用相机拍桌面（平面），移动相机角度后，桌面的平行线会看起来 “相交”（这就是透视效果）。
- 关键：八个参数（3×3 矩阵，去掉一个缩放冗余），是最灵活的 2D 几何变换。
- 保持特性：只保 “直线性”（直线变换后还是直线），平行线可以相交。
- 适用场景：图像拼接（比如拼接建筑、风景照片）、不同视角的平面物体匹配。

## 总结
![[Pasted image 20251211194757.png|400]]
![[Pasted image 20251211194932.png|400]]
符号与说明
- $I$：$2\times 2$ 单位矩阵
- $R$：$2\times 2$ 旋转矩阵（正交矩阵，$R^T R = I$，$\det(R) = 1$）
- $t$：$2\times 1$ 平移向量
- $s$：缩放因子（$s>0$）
- $A$：任意可逆的 $2\times 2$ 矩阵
- $\tilde{H}$：$3\times 3$ 单应性矩阵（在齐次坐标下定义，可相差一个非零比例因子）

关键点
1. 自由度从 2 到 8 递增，变换越来越一般化
2. 平移是刚体变换的特例（$R=I$）
3. 刚体是相似变换的特例（$s=1$）
4. 相似变换是仿射变换的特例（$A=sR$）
5. 仿射是投影变换的特例（最后一行 $V^T = [0,0]$，$s=1$）
6. 表格中的 "+ …" 表示保留该行及以上行的所有性质
7. 通常使用齐次坐标（$3\times 3$ 矩阵）统一表示所有变换

### 镜头畸变
实际拍照时，广角镜头会让图像边缘 “变形”（比如拍风景时，地平线变弯），这叫 “径向畸变”—— 光学中心附近不变形，越往边缘越严重。
校正方法：用泰勒级数公式，根据畸变系数（κ₁、κ₂）把变形的坐标修正回正常位置。

## 求解变换矩阵-以投影变换为例

### 传统方法
**步骤**：
1. 提取每张图的SIFT等特征点
2. 提取每个特征点对应的描述子
3. 通过匹配特征点描述子，找到两张图中匹配的特征点对（这里可能存在错误匹配，一般情况计算出的匹配的特征点对数量远大于4，此时需要解超定方程组，类似于求解线性回归时数据点的数量远多余未知数）
4. 使用RANSAC算法剔除错误匹配
5. 求解方程组，计算Homograph单应性变换矩阵

#### 求解原理：用匹配的特征点列方程
我们之前已经找到了两张图的匹配特征点（比如 A 图的 (x₁,y₁) 对应 B 图的 (x₁',y₁')），每组匹配点能列出 2 个方程。投影变换需要 8 个参数，所以**至少需要 4 组不共线的匹配点**（4×2=8 个方程，刚好解 8 个参数）

### RANSAC：随机抽样一致算法
原理：
RANSAC算法是一种迭代方法，它的基本思想是从观测数据中随机选择一部分数据作为“内点”（即符合模型的数据），然后用这些数据来估计模型的参数。接着，用估计出的模型去测试所有的数据，看看哪些数据符合模型（即也是内点）。最后，选择那些使得最多数据成为内点的模型参数作为最终的结果
由于RANSAC算法在每次迭代中都会随机选择数据，因此它有一定的概率能够排除异常值的影响，从而得到更准确的模型参数估计

- 核心思想：随机抽少量点（比如 4 个）算一个临时矩阵，然后看所有匹配点里，多少个点符合这个矩阵（这些是 “正确匹配点”，叫内点）；
- 迭代多次，选 “内点最多” 的那个矩阵作为最终结果 —— 这样就能排除错配的干扰。
- 迭代次数有规律：比如错配点占 50%，要保证 99% 的正确率，至少需要迭代 72 次（PPT 里的表格就是查这个的）

**步骤**：
1. 随机选择一组观测数据作为初始的“内点”。
2. 使用这些内点来估计模型的参数。
3. 用估计出的模型去测试所有的观测数据，计算每个数据点到模型的距离或误差。
4. 如果一个数据点到模型的距离或误差小于某个阈值，就认为这个数据点是内点。
5. 统计所有被认为是内点的数据点的数量。
6. 如果当前模型使得最多的数据点成为内点，那么就更新模型参数。
7. 重复以上步骤，直到达到预设的迭代次数或者找到了足够好的模型为止。

### 深度学习方法 HomographyNet

传统方法要先匹配特征点，再算矩阵；深度学习可以跳过匹配步骤：

- 输入：两张图的对应小块（Patch A 和 Patch B）；
- 输出：投影变换矩阵的 8 个参数；
- 两种训练方式：
    1. 回归型：直接输出参数，速度快，但不知道结果靠谱不靠谱；
	    ![[Pasted image 20251211200305.png|200]]
    2. 分类型：把参数分成区间，输出每个参数的区间和置信度（比如 “x 方向偏移大概率在 0-5 之间”），更实用。
	    ![[Pasted image 20251211200323.png|200]]

## 几何形变的实现
### 正向形变
- 逻辑：遍历原图像的每个像素，算它在目标图里的位置，然后把像素值挪过去。
- 问题：目标图的位置可能不是整数（比如算出来在 (10.3,20.5)），四舍五入后，有的位置没像素（空洞），有的位置多个像素叠在一起（重叠），结果会有波纹、漏洞。
### 反向形变
- 逻辑：反过来，遍历目标图的每个像素，算它在原图像里的对应位置，然后从原图像拿像素值（如果位置不是整数，用 “插值” 估算）。
- 优势：目标图每个位置都有对应的像素值，没有空洞和重叠，结果平滑清晰。
- 将g中的坐标映射到f，如果反向变形后映射到f的坐标不是整数，  则采用插值逼近的方法进行近似，因此不会产生的正向变形中的空  洞或波纹问题

# Chapter8 图像分类识别：导论

## 什么是图像识别
图像识别不是单一任务，而是一系列相关任务的总称
1. **单目标分类**：判断 “这是什么”（如 “那是一盏灯吗？”“这是鸭子吗？”）；
2. **目标检测**：判断 “什么东西在哪个位置”（如 “哪里有人？”）；
3. **目标验证**：判断 “这是不是特定对象”（如 “那是布达拉宫吗？”）；
4. **多目标分类**：一张图里识别多个不同对象（如同时识别山、树、建筑、行人）；
5. **场景分类**：判断图像的场景类型（如 “这是户外城市场景吗？”）；
6. **事件理解**：更高级的识别，判断 “图中对象在做什么”（如 “这些人在跑步吗？”）。

## 特征表示
- **人工设计特征**（传统方法）：
    - 色彩直方图：统计图像中红、绿、蓝（RGB）等颜色的分布，比如 “红色占比 30%、绿色占比 50%”，适合色彩区分明显的场景（如水果识别）；
    - HOG 特征（方向梯度直方图）：统计图像中边缘的方向和强度，比如 “水平边缘占比高”，适合检测有明显轮廓的对象（如行人、车辆）；
    - 光流特征：描述图像中像素的运动趋势，适合视频中的动态识别（如判断物体移动方向）；
    - 之前学的 SIFT 特征：尺度不变的局部特征，适合不同视角、缩放后的对象匹配。
- **机器学习特征**（现代方法）：通过深度学习自动提取 “深度特征”，不用人工设计，能捕捉更复杂的图像规律（如物体的纹理、形状、语义信息）。
## 相似度度量
有了特征向量后，需要量化它们的相似程度 —— 距离越小，越相似；距离越大，越不同。
- 欧式距离：最常用，计算向量间的 “直线距离”（如两点间距离公式）；
		$D(x,y)=\sqrt{\sum_{i=1}^{n}\left(x_{i}-y_{i}\right)^{2}}$
- 曼哈顿距离：计算向量间 “水平 + 垂直” 的距离（如城市街区走路的距离）；
		$D(x,y)=\sum_{i=1}^{k}\left|x_{i}-y_{i}\right|$
- 切比雪夫距离：取向量各维度差值的最大值（如 “最不同的那个维度决定相似度”）；
		$D(x,y)=\max _{i}\left(\left|x_{i}-y_{i}\right|\right)$

![[Pasted image 20251211204338.png|140]]![[Pasted image 20251211204353.png|140]]![[Pasted image 20251211204406.png|140]]
- 闵氏距离：欧式、曼哈顿的通用形式（p=2 是欧式，p=1 是曼哈顿）；
		$D(x,y)=\left(\sum_{i=1}^{n}\left|x_{i}-y_{i}\right|^{p}\right)^{\frac{1}{p}}$
- 余弦相似度：计算向量的夹角，适合高维特征（如深度特征）；
		$D(x,y)=\cos (\theta)=\frac{x\cdot y}{\|x\|\|y\|}$
- 汉明距离：统计两个二进制向量中 “不同位的个数”，适合简单的二进制特征。

![[Pasted image 20251211204646.png|140]]![[Pasted image 20251211204657.png|140]]![[Pasted image 20251211204708.png|140]]

理论上有 “特征 + 距离” 就能识别，但实际场景中会遇到很多干扰：
1. **类内差异大**：同一类对象的样子可能差别很大（如不同品种的鸟、不同款式的汽车）
2. **类别数量多**：现实中要识别的对象类别可能有 1 万～3 万种，很难全覆盖
3. **视角 / 姿态变化**：同一对象从正面、侧面、俯视等不同角度拍，样子差异大（如米开朗基罗的雕塑不同角度拍摄）
4. **光照变化**：强光、弱光、逆光等不同光照条件，会改变图像的亮度和色彩（如白天和夜晚拍同一栋楼）
5. **尺度变化**：对象的大小可能相差很大（如远处的人和近处的人）
6. **形变**：对象本身可能变形（如不同姿势的运动员、褶皱的布料）
7. **遮挡**：对象被其他东西挡住（如人被树挡住、杯子被书本挡住）
8. **背景干扰**：对象和背景颜色、纹理相似，难以区分（如白色的猫在雪地里）
9. **细粒度分类**：要区分非常相似的子类别（如区分三种不同的黄鹂鸟）
10. **少样本学习**：只有少量样本（如 1~2 张图），却要识别该类别

这些难题的核心是：**现实中的 “干扰因素” 会让同一对象的特征变化很大，不同对象的特征可能反而相似**，导致识别出错

### 行人重识别案例
- 任务定义：在多个不重叠的摄像头画面中，匹配出同一个行人（如摄像头 A 拍到的人，和摄像头 B 拍到的是不是同一个人）；
- 核心难点：跨摄像头的视角、光照、尺度变化大，且不同摄像头的设备差异会导致特征分布不一致（同一人的特征在不同摄像头下可能差别很大）；
- 三大关键技术（针对性解决难点）：
    1. 特征变换：通过投影矩阵，把不同摄像头下的行人特征 “拉到同一分布”，消除设备差异
    2. 距离度量：针对不同行人的外貌差异程度，设计多个距离函数（而非统一函数），提高匹配精度
    3. 排序优化：通过 “双向查询”（用 A 查 B，再用 B 查 A）验证结果，对初始匹配结果重排，减少错误

## 分类器
识别的最终落地需要 “分类器”—— 即根据 “特征 + 距离” 给出最终判断
### **最近邻分类器**
Nearest Neighbor(NN)

训练：记忆所有的训练图像和他们的标记
推测：
- 查找最接近的训练图像
- 将其标签推断为真实标签

记住所有训练图像的特征和标签，测试时找 “最相似的训练图像”，直接套用其标签

特点：简单、不用训练，但存储量大、测试慢
### **K-最近邻**
k-Nearest Neighbors(kNN)

找 “最相似的 k 个训练图像”，用投票法确定标签（如 k=5，3 个是 “猫”，则判为猫）

特点：比 NN 更稳定，适合小数据集
### **线性分类器**
Linear Classifier

用超平面把不同类别的特征分开，本质是 “给每个类设计一个线性评分函数”（f (x)=Wx+b）

特点：速度快、参数少，适合大数据集

理解线性分类器的三种视角：
- 代数视角：把图像特征（如 32×32×3 的图像展成 3072 维向量）和权重矩阵 W 相乘，再加偏置 b，得到每个类的评分；
- 可视化视角：权重矩阵 W 的每一行，就是对应类别的 “模板”（如 “猫” 类的模板行，和输入图像特征匹配度高，评分就高）；
- 几何视角：每个类的评分对应 “输入特征到超平面的距离”，距离越远，属于该类的概率越高。
### **神经网络&深度神经网络**
Neural NetWork & Deep Neural Network
 
用多层网络自动学习特征和分类规则，端到端完成 “输入图像→输出标签”

特点：精度高，适合复杂识别任务（如细粒度分类）

### **SVM 支持向量机**

找到 “最大间隙” 的超平面分开不同类别，还能通过 “核函数” 处理非线性问题（如无法用直线分开的情况）

特点：小数据集上精度高，适合特征维度高的场景
## 损失函数
分类器需要通过 “学习” 优化参数，损失函数就是 “判断分类器错得有多离谱” 的指标
### **交叉熵损失函数**
- 核心逻辑：先通过 Softmax 函数，把分类器的 “评分” 转化为 “概率”（如评分 [2.0,1.8,0]→概率 [0.7,0.2,0.1]）；
- 计算方式：如果真实标签是 “猫”（概率分布 [1,0,0]），则损失 = -log (猫的预测概率)—— 预测概率越接近 1，损失越小（错得越少）
- 多标签场景：如果图像有多个标签（如同时是 “青蛙” 和 “老鼠”），则损失为每个标签的交叉熵之和。
#### Softmax分类器

将分数解释为类的非归一化对数概率
$f(x_i, W) = W x_i \quad \text{score function}$
线性评分函数 $f(x_i, W) = W x_i$，将输入特征 $x_i$ 通过权重矩阵 $W$ 映射为各类别的得分
$\frac{e^{f_{y_i}}}{\sum_j e^{f_j}} \quad \textcolor{red}{\text{softmax function}}$
Softmax 函数，将得分转换为概率分布

# Chapter9 图像识别：神经网络




# Chapter10 图像分割
